{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import random \n",
    "import gc\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder,minmax_scale\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from contextlib import contextmanager\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "root = './主表数据/'\n",
    "result = './result/'\n",
    "new = '../B榜数据/其他表/'\n",
    "\n",
    "def seed_everything(seed=2020):\n",
    "    seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f'[{name}] {elapsed: .3f}sec')\n",
    "\n",
    "seed_everything(seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要特征穿越\n",
    "# 一定要滑动窗口保证你每个做的特征可比性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, df, feature_columns, test_id=None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.feature_columns = feature_columns\n",
    "        self.test_id = test_id\n",
    "        self.preprocess()\n",
    "        self.sample = 0\n",
    "\n",
    "    def setSample(self, sample):\n",
    "        self.sample = sample\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.trn = self.df[self.df['a3']!=20211201]\n",
    "        self.tst = self.df[self.df['a3']==20211201]\n",
    "        del self.df\n",
    "        gc.collect()\n",
    "        self.y = self.trn[['id', 'y']]\n",
    "        self.theta = self.y['y'].mean()\n",
    "        print('tst before: ', len(self.tst), end=' ')\n",
    "        self.tst = self.tst.drop_duplicates(['id'])\n",
    "        print('test end: ', len(self.tst))\n",
    "        self.rs = pd.DataFrame()\n",
    "        self.rs['id'] = self.tst['id'] if self.test_id is None else self.test_id\n",
    "        self.rs['a2'] = self.tst['a2']\n",
    "        self.rs['y'] = 0\n",
    "        self.rs['prediction'] = 0\n",
    "        \n",
    "        print('feature numbers: ', len(self.feature_columns), 'x/y: ', len(self.trn), len(self.y), 'y_mean: ', self.y['y'].mean())\n",
    "        \n",
    "    \n",
    "    def set_pre(self, y_pre, weight=None, k=1):\n",
    "        y_pre = np.array(y_pre).squeeze()\n",
    "        if weight is not None:\n",
    "            weight = np.array(weight)\n",
    "        else:\n",
    "            weight = np.ones_like(y_pre)\n",
    "        self.rs['prediction'] += (y_pre * weight) / k\n",
    "        \n",
    "    \n",
    "    def reset_pre(self):\n",
    "        self.rs['y'] = 0\n",
    "        self.rs['prediction'] = 0\n",
    "    \n",
    "    def save_res(self, model='lgb', theta=None, rate=None,result = './result/'):\n",
    "        v = self.theta\n",
    "        if theta is not None:\n",
    "            v = theta\n",
    "        if rate is None:\n",
    "            t = self.rs['y'].sort_values(ascending=False).iloc[int(len(self.rs)*v)]\n",
    "        else:\n",
    "            t = rate\n",
    "        self.rs['y'] = [1 if i >=t else 0 for i in self.rs['prediction']]\n",
    "        # self.rs = self.save_process(self.rs, theta)\n",
    "        print(self.rs.groupby('a2')['y'].agg(['count', 'mean', 'sum']))\n",
    "        name = model + '_' + str(datetime.now()).split(' ')[0]\n",
    "        self.rs[['id', 'y']].to_csv(result+name+'.csv', index=None)\n",
    "        print(self.rs['y'].mean())\n",
    "        print('save to ', result + name + '.csv')\n",
    "    \n",
    "    def save_process(self, rs, v):\n",
    "        \n",
    "        c2 = rs[rs['a2']==2]\n",
    "        other = rs[rs['a2']!=2]\n",
    "        t = other['y'].sort_values(ascending=False).iloc[int(len(rs)*v)]\n",
    "        t2 = c2['y'].sort_values(ascending=False).iloc[80]\n",
    "        other['y'] = other['y'].map(lambda x: 1 if x >= t else 0)\n",
    "        c2['y'] = c2['y'].map(lambda x: 1 if x >= t2 else 0)\n",
    "        return pd.concat([c2, other])\n",
    "            \n",
    "\n",
    "    \n",
    "    def _upsample(self, x):\n",
    "        pos = x[x['y'] == 1]\n",
    "        neg = x[x['y'] == 0]\n",
    "        poses = [pos] * int(np.floor(self.sample))\n",
    "        rate = self.sample - np.floor(self.sample)\n",
    "        if rate > 0:\n",
    "            poses + [pos.sample(frac=rate, random_state=42)]\n",
    "        poses += [neg]\n",
    "        data = pd.concat(poses).sample(frac=1)\n",
    "        return data\n",
    "        \n",
    "    def _downsample(self, x):\n",
    "        pos = x[x['y'] == 1]\n",
    "        neg = x[x['y'] == 0].sample(frac=self.sample, random_state=42)\n",
    "        data = pd.concat([pos, neg]).sample(frac=1)\n",
    "        return data\n",
    "    \n",
    "    def get_train_val_data_by_time(self, val_time=20211001):\n",
    "        #使用9.1做验证\n",
    "        train = self.trn.loc[self.trn['a3']!=val_time]\n",
    "        if self.sample > 0:\n",
    "            if self.sample < 1:\n",
    "                train = self._downsample(train)\n",
    "            else:\n",
    "                train = self._upsample(train)\n",
    "        x_train = train[self.feature_columns]\n",
    "        y_train = train['y']\n",
    "        val = self.trn.loc[self.trn['a3']==val_time]\n",
    "        x_val = val[self.feature_columns]\n",
    "        y_val = val['y']\n",
    "        return x_train, x_val, y_train, y_val\n",
    "    \n",
    "    def get_train_val_data(self, val_rate=0.3):\n",
    "        if self.sample == 0:\n",
    "            train = self.trn[self.feature_columns]\n",
    "            y = self.trn['y']\n",
    "        elif self.sample < 1:\n",
    "            train = self._downsample(self.trn)\n",
    "            y = train['y']\n",
    "            train = train[self.feature_columns]\n",
    "        else:\n",
    "            train = self._upsample(self.trn)\n",
    "            y = train['y']\n",
    "            train = train[self.feature_columns]\n",
    "        if val_rate > 0:\n",
    "            x_train, x_val, y_train, y_val = train_test_split(train, y, test_size=val_rate, random_state=0, shuffle=False)\n",
    "            return x_train, x_val, y_train, y_val\n",
    "        else:\n",
    "            return train, y\n",
    "    def get_test(self):\n",
    "        return self.tst[self.feature_columns]\n",
    "    \n",
    "    def get_k_fold_train_val_data(self, k):\n",
    "        if self.sample == 0:\n",
    "            train = self.trn[self.feature_columns]\n",
    "            y = self.trn['y']\n",
    "        elif self.sample < 1:\n",
    "            train = self._downsample(self.trn)\n",
    "            y = train['y']\n",
    "            train = train[self.feature_columns]\n",
    "        else:\n",
    "            train = self._upsample(self.trn)\n",
    "            y = train['y']\n",
    "            train = train[self.feature_columns]\n",
    "        sk = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        for trn_idx, val_idx in sk.split(train,y):\n",
    "            trn, y_trn = train.iloc[trn_idx], y.iloc[trn_idx]\n",
    "            val, y_val = train.iloc[val_idx], y.iloc[val_idx]\n",
    "            yield trn, val, y_trn, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_score(y_true, y_pred):\n",
    "    y_pred = np.array(y_pred).squeeze()    \n",
    "    y_pre = pd.Series(y_pred)\n",
    "    tmp = y_pre.copy()\n",
    "    rate = tmp.sort_values(ascending=False).iloc[int(len(tmp)*y_true.mean())]\n",
    "    y_pre[y_pre >= rate] = 1\n",
    "    y_pre[y_pre < rate] = 0\n",
    "    recall = recall_score(y_true, y_pre)\n",
    "    precision = precision_score(y_true, y_pre)\n",
    "    f2 = 5 * recall * precision / (4 * precision + recall)\n",
    "    return f2, precision, recall\n",
    "\n",
    "def lgb_f2_score(y_true, y_hat):\n",
    "    y_hat = [1 if i >=0.072 else 0 for i in y_hat ]\n",
    "    precision = precision_score(y_true,y_hat,zero_division=1)\n",
    "    recall = recall_score(y_true,y_hat)\n",
    "    f2 = 5*recall*precision/(4*precision+recall)\n",
    "    return 'f2',f2,True\n",
    "\n",
    "def metrics_detail(y_true, y_pred, category, rate=None):\n",
    "    y_pred = np.array(y_pred).squeeze()    \n",
    "    y_pre = pd.Series(y_pred)\n",
    "    tmp = y_pre.copy()\n",
    "    if rate is None:\n",
    "        rate = tmp.sort_values(ascending=False).iloc[int(len(tmp)*y_true.mean())]\n",
    "    else:\n",
    "        rate = tmp.sort_values(ascending=False).iloc[int(len(tmp)*rate)]\n",
    "    y_pre[y_pre >= rate] = 1\n",
    "    y_pre[y_pre < rate] = 0\n",
    "    rs = pd.DataFrame({'y': y_true, 'pre': y_pre.values, 'a2': category})\n",
    "    recall = recall_score(rs['y'], rs['pre'])\n",
    "    precision = precision_score(rs['y'], rs['pre'])\n",
    "    f2 = 5 * recall * precision / (4 * precision + recall)\n",
    "    print('a2: total', ' precision: ', precision, ' recall: ', recall, ' f2: ', f2)\n",
    "    print(rs.groupby('a2')[['y', 'pre']].sum())\n",
    "    for c in rs['a2'].unique():\n",
    "        t = rs[rs['a2']==c]\n",
    "        recall = recall_score(t['y'], t['pre'])\n",
    "        precision = precision_score(t['y'], t['pre'])\n",
    "        f2 = 5 * recall * precision / (4 * precision + recall)\n",
    "        print('a2: ', c, ' precision: ', precision, ' recall: ', recall, ' f2: ', f2)\n",
    "\n",
    "def find_best_threshold(y_valid, oof_prob):\n",
    "    best_f2 = 0\n",
    "    \n",
    "    for th in tqdm([i/1000 for i in range(50, 200)]):\n",
    "        oof_prob_copy = oof_prob.copy()\n",
    "        oof_prob_copy[oof_prob_copy >= th] = 1\n",
    "        oof_prob_copy[oof_prob_copy < th] = 0\n",
    "        recall = recall_score(y_valid, oof_prob_copy)\n",
    "        precision = precision_score(y_valid, oof_prob_copy)\n",
    "        f2 = 5*recall*precision / (4*precision+recall)\n",
    "        \n",
    "        if f2 > best_f2:\n",
    "            best_th = th\n",
    "            best_f2 = f2\n",
    "        \n",
    "    return best_th, best_f2, oof_prob_copy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## basic feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3540580, 6)\n"
     ]
    }
   ],
   "source": [
    "test_old = pd.read_csv(root + 'x_test.csv')\n",
    "test_old.rename(columns={'c2':'a2','c3':'a3'}, inplace=True)\n",
    "label10 = pd.read_csv(root + 'y_test_A.csv')\n",
    "label10 = label10[['id','y']]\n",
    "test_old = test_old.merge(label10,on='id',how='left')\n",
    "train = pd.read_csv(root + 'x_train.csv')\n",
    "train_label = pd.read_csv(root + 'y_train.csv')\n",
    "train = train.merge(train_label, on='id', how='left')\n",
    "train = pd.concat([train,test_old])\n",
    "test = pd.read_csv(new + 'x_test_B.csv')\n",
    "test.rename(columns={'c2':'a2','c3':'a3'}, inplace=True)\n",
    "df = pd.concat([train, test]).reset_index(drop=True)\n",
    "df['a3'] = df['a3'].map(lambda x: int(str(x).replace('-', '')))\n",
    "del train, test,test_old,label10\n",
    "gc.collect()\n",
    "print(df.shape)\n",
    "def print_new_cols(new_cols,cols):\n",
    "    r = []\n",
    "    for i in new_cols:\n",
    "        if i not in cols:\n",
    "            r.append(i)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>0.026568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3</th>\n",
       "      <td>-0.106737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.026568</td>\n",
       "      <td>-0.027190</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a2        a3         y\n",
       "a2  1.000000 -0.106737  0.026568\n",
       "a3 -0.106737  1.000000 -0.027190\n",
       "y   0.026568 -0.027190  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()\n",
    "# minimize correlation between features\n",
    "# maximize correlation between features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d1', 'd2', 'd3', 'e1_mean', 'e1_cnt', 'e1_last', 'e2_last', 'e2_first', 'eval_delta', 'eval_first_delta']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = df.columns\n",
    "d = pd.read_csv(root + 'd.csv')\n",
    "new_d = pd.read_csv(new + 'd_bc.csv')\n",
    "d = pd.concat([d,new_d])\n",
    "d = d.drop_duplicates(['core_cust_id'])\n",
    "df = df.merge(d, on='core_cust_id', how='left')\n",
    "e = pd.read_csv(root + 'e.csv')\n",
    "new_e = pd.read_csv(new+'e_bc.csv')\n",
    "e = pd.concat([e,new_e])\n",
    "e = e.drop_duplicates(['core_cust_id', 'e2'])\n",
    "e_stats = []\n",
    "for end in [20211201,20211001, 20210901, 20210801, 20210701]:\n",
    "    e_stat = e.loc[e['e2']<end].groupby('core_cust_id').agg(e1_mean=('e1', 'mean'), e1_cnt=('e1', 'count'), e1_last=('e1', 'last'), e2_last=('e2', 'max'), e2_first=('e2', 'min')).reset_index()\n",
    "    e_stat['a3'] = end\n",
    "    e_stat['eval_delta'] = end - e_stat['e2_last']\n",
    "    e_stat['eval_first_delta'] = end - e_stat['e2_first']\n",
    "    e_stats.append(e_stat)\n",
    "\n",
    "####################################################################################################### e_stats hasnt been concat!\n",
    "e_stats = pd.concat(e_stats)\n",
    "df = df.merge(e_stat, on=['core_cust_id', 'a3'], how='left')\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns\n",
    "del d, e , e_stats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f22', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'create_date']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>core_cust_id</th>\n",
       "      <th>prod_code</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>y</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>e1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>create_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e3c3d57b83e425f8087b1d6d32a50f7</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>90318011</td>\n",
       "      <td>4</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa83c5fc05414c4d9727f0b32882f80e</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211530</td>\n",
       "      <td>1</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11245458ed6446cd9f88d57a5fc1d957</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>DECD21090102</td>\n",
       "      <td>2</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359a03ecc46240d9bc00eef58dbc85e3</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211119</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7a5d79036dfb46acb7348e741ab00d9f</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211125</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id core_cust_id      prod_code  a2        a3  \\\n",
       "0  4e3c3d57b83e425f8087b1d6d32a50f7   6e2105d9fe       90318011   4  20210801   \n",
       "1  aa83c5fc05414c4d9727f0b32882f80e   6e2105d9fe  GRHLA20211530   1  20210901   \n",
       "2  11245458ed6446cd9f88d57a5fc1d957   6e2105d9fe   DECD21090102   2  20210901   \n",
       "3  359a03ecc46240d9bc00eef58dbc85e3   6e2105d9fe  GRHLA20211119   1  20210801   \n",
       "4  7a5d79036dfb46acb7348e741ab00d9f   6e2105d9fe  GRHLA20211125   1  20210801   \n",
       "\n",
       "     y  d1   d2  d3  e1_mean  ...  f13  f14  f15  f16  f17  f18  f19  f20  \\\n",
       "0  0.0   1  4.0  32      NaN  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0   1  4.0  32      NaN  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0   1  4.0  32      NaN  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0   1  4.0  32      NaN  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0   1  4.0  32      NaN  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   f21  create_date  \n",
       "0  0.0      20280.0  \n",
       "1  0.0      20380.0  \n",
       "2  0.0      20380.0  \n",
       "3  0.0      20280.0  \n",
       "4  0.0      20280.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.read_csv(root + 'f.csv')\n",
    "new_f = pd.read_csv(new+'f_bc.csv')\n",
    "f = pd.concat([f,new_f])\n",
    "f.fillna(0, inplace=True)\n",
    "f['create_date'] = f['f1'].map(lambda x: int(str(x).replace('-', '')))\n",
    "f_cols = ['f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9','f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19','f20', 'f21']\n",
    "for c in f_cols:\n",
    "    f[c] = f[c].apply(lambda x: str(x).replace(',','')).astype('float')\n",
    "\n",
    "f_dict = {col: (col, 'mean') for col in f_cols}\n",
    "f_stat = f.groupby(['core_cust_id','f22']).agg(**f_dict).reset_index()\n",
    "f_stat['f22'] = f_stat['f22'].map(lambda x: x-29+100)\n",
    "df = df.merge(f_stat, left_on=['core_cust_id','a3'], right_on=['core_cust_id','f22'], how='left')\n",
    "df = df.merge(f.groupby('core_cust_id')['create_date'].min().reset_index(), how='left', on='core_cust_id')\n",
    "df['create_date'] = df['a3'] - df['create_date']\n",
    "del f_stat, f#, ff, feature\n",
    "gc.collect()\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['prod_date2', 'k1', 'k2', 'k3', 'k4', 'k5', 'k6', 'k10']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>core_cust_id</th>\n",
       "      <th>prod_code</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>y</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>e1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>create_date</th>\n",
       "      <th>prod_date2</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>k3</th>\n",
       "      <th>k4</th>\n",
       "      <th>k5</th>\n",
       "      <th>k6</th>\n",
       "      <th>k10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e3c3d57b83e425f8087b1d6d32a50f7</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>90318011</td>\n",
       "      <td>4</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa83c5fc05414c4d9727f0b32882f80e</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211530</td>\n",
       "      <td>1</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20380.0</td>\n",
       "      <td>209912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11245458ed6446cd9f88d57a5fc1d957</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>DECD21090102</td>\n",
       "      <td>2</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20380.0</td>\n",
       "      <td>209912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359a03ecc46240d9bc00eef58dbc85e3</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211119</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20280.0</td>\n",
       "      <td>209912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7a5d79036dfb46acb7348e741ab00d9f</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211125</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20280.0</td>\n",
       "      <td>209912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id core_cust_id      prod_code  a2        a3  \\\n",
       "0  4e3c3d57b83e425f8087b1d6d32a50f7   6e2105d9fe       90318011   4  20210801   \n",
       "1  aa83c5fc05414c4d9727f0b32882f80e   6e2105d9fe  GRHLA20211530   1  20210901   \n",
       "2  11245458ed6446cd9f88d57a5fc1d957   6e2105d9fe   DECD21090102   2  20210901   \n",
       "3  359a03ecc46240d9bc00eef58dbc85e3   6e2105d9fe  GRHLA20211119   1  20210801   \n",
       "4  7a5d79036dfb46acb7348e741ab00d9f   6e2105d9fe  GRHLA20211125   1  20210801   \n",
       "\n",
       "     y  d1   d2  d3  e1_mean  ...  f21  create_date  prod_date2  k1  k2  k3  \\\n",
       "0  0.0   1  4.0  32      NaN  ...  0.0      20280.0         NaN NaN NaN NaN   \n",
       "1  0.0   1  4.0  32      NaN  ...  0.0      20380.0    209912.0 NaN NaN NaN   \n",
       "2  0.0   1  4.0  32      NaN  ...  0.0      20380.0    209912.0 NaN NaN NaN   \n",
       "3  0.0   1  4.0  32      NaN  ...  0.0      20280.0    209912.0 NaN NaN NaN   \n",
       "4  0.0   1  4.0  32      NaN  ...  0.0      20280.0    209912.0 NaN NaN NaN   \n",
       "\n",
       "    k4   k5   k6  k10  \n",
       "0  NaN  NaN  NaN  NaN  \n",
       "1  2.0  NaN  1.0  NaN  \n",
       "2  NaN  NaN  2.0  1.0  \n",
       "3  2.0  NaN  1.0  NaN  \n",
       "4  2.0  5.0  1.0  NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A理财产品表2\n",
    "k = pd.read_csv(root + 'k.csv')\n",
    "# B理财产品表2\n",
    "l = pd.read_csv(root + 'l.csv')\n",
    "# C理财产品表2\n",
    "m = pd.read_csv(root + 'm.csv')\n",
    "prod_info2 = pd.DataFrame()\n",
    "prod_info2['prod_code'] = k['prod_code'].to_list() + l['prod_code'].to_list() + m['prod_code'].to_list()\n",
    "prod_info2['prod_date2'] = k['k11'].to_list() + l['l7'].to_list() + m['m9'].to_list()\n",
    "prod_info2['k1'] = k['k1'].to_list() + l['l1'].to_list() + m['m1'].to_list()\n",
    "prod_info2['k2'] = k['k2'].to_list() + l['l2'].to_list() + m['m2'].to_list()\n",
    "prod_info2['k3'] = k['k3'].to_list() + l['l3'].to_list() + m['m3'].to_list()\n",
    "prod_info2['k4'] = k['k4'].to_list() + l['l4'].to_list() + m['m4'].to_list()\n",
    "prod_info2['k5'] = k['k5'].to_list() + l['l5'].to_list() + m['m5'].to_list()\n",
    "prod_info2['k6'] = k['k6'].to_list() + l['l6'].to_list() + m['m6'].to_list()\n",
    "# prod_info2['k7'] = k['k7'].to_list() + [np.nan]*len(l) + m['m7'].to_list()\n",
    "prod_info2['k10'] = k['k10'].to_list() + [np.nan]*len(l) + m['m8'].to_list()\n",
    "# prod_info2['k8'] = k['k8'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "# prod_info2['k9'] = k['k9'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "prod_info2['a2'] = [1] * len(k) + [3] * len(l) + [2] * len(m)\n",
    "\n",
    "drop_cols = [c for c in prod_info2.columns if prod_info2[c].dtype != 'object' and prod_info2[c].std() == 0]\n",
    "print(drop_cols)\n",
    "prod_info2.drop(drop_cols, axis=1, inplace=True)\n",
    "prod_info2 = prod_info2.drop_duplicates(['prod_code', 'a2'])\n",
    "df = df.merge(prod_info2, how='left', on=['prod_code', 'a2'])\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['prod_date1', 'bid_type', 'recur_type', 'prod_type', 'exp_level', 'is_guncun', 'hold_days', 'prod_type2', 'j6', 'j9', 'j10']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>core_cust_id</th>\n",
       "      <th>prod_code</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>y</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>e1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_type</th>\n",
       "      <th>recur_type</th>\n",
       "      <th>prod_type</th>\n",
       "      <th>exp_level</th>\n",
       "      <th>is_guncun</th>\n",
       "      <th>hold_days</th>\n",
       "      <th>prod_type2</th>\n",
       "      <th>j6</th>\n",
       "      <th>j9</th>\n",
       "      <th>j10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e3c3d57b83e425f8087b1d6d32a50f7</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>90318011</td>\n",
       "      <td>4</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa83c5fc05414c4d9727f0b32882f80e</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211530</td>\n",
       "      <td>1</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11245458ed6446cd9f88d57a5fc1d957</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>DECD21090102</td>\n",
       "      <td>2</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359a03ecc46240d9bc00eef58dbc85e3</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211119</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7a5d79036dfb46acb7348e741ab00d9f</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211125</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id core_cust_id      prod_code  a2        a3  \\\n",
       "0  4e3c3d57b83e425f8087b1d6d32a50f7   6e2105d9fe       90318011   4  20210801   \n",
       "1  aa83c5fc05414c4d9727f0b32882f80e   6e2105d9fe  GRHLA20211530   1  20210901   \n",
       "2  11245458ed6446cd9f88d57a5fc1d957   6e2105d9fe   DECD21090102   2  20210901   \n",
       "3  359a03ecc46240d9bc00eef58dbc85e3   6e2105d9fe  GRHLA20211119   1  20210801   \n",
       "4  7a5d79036dfb46acb7348e741ab00d9f   6e2105d9fe  GRHLA20211125   1  20210801   \n",
       "\n",
       "     y  d1   d2  d3  e1_mean  ...  bid_type  recur_type  prod_type  exp_level  \\\n",
       "0  0.0   1  4.0  32      NaN  ...         1           0        1.0        2.0   \n",
       "1  0.0   1  4.0  32      NaN  ...         0           1        1.0        1.0   \n",
       "2  0.0   1  4.0  32      NaN  ...         0           0        2.0        NaN   \n",
       "3  0.0   1  4.0  32      NaN  ...         0           1        1.0        1.0   \n",
       "4  0.0   1  4.0  32      NaN  ...         0           1        1.0        1.0   \n",
       "\n",
       "   is_guncun  hold_days  prod_type2   j6   j9  j10  \n",
       "0        NaN        NaN         NaN  0.0  1.0  1.0  \n",
       "1        0.0      115.0         NaN  NaN  NaN  NaN  \n",
       "2        NaN        0.0         NaN  NaN  NaN  NaN  \n",
       "3        0.0        7.0         NaN  NaN  NaN  NaN  \n",
       "4        0.0      146.0         NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A理财产品表1\n",
    "g = pd.read_csv(root + 'g.csv')\n",
    "# B理财产品表1\n",
    "h = pd.read_csv(root + 'h.csv')\n",
    "# C理财产品表1\n",
    "i = pd.read_csv(root + 'i.csv')\n",
    "# D理财产品表1\n",
    "j = pd.read_csv(root + 'j.csv')\n",
    "prod_info1 = pd.DataFrame()\n",
    "prod_info1['prod_code'] = g['prod_code'].to_list() + h['prod_code'].to_list() + i['prod_code'].to_list() + j['prod_code'].to_list()\n",
    "prod_info1['prod_date1'] = g['g9'].to_list() + h['h8'].to_list() + i['i9'].to_list() + j['j13'].to_list()\n",
    "prod_info1['bid_type'] = g['g1'].to_list() + h['h1'].to_list() + i['i1'].to_list() + j['j1'].to_list()\n",
    "prod_info1['recur_type'] = g['g2'].to_list() + h['h2'].to_list() + i['i2'].to_list() + j['j2'].to_list()\n",
    "prod_info1['prod_type'] = g['g3'].to_list() + h['h3'].to_list() + i['i3'].to_list() + j['j3'].to_list()\n",
    "prod_info1['exp_level'] = g['g4'].to_list() + h['h4'].to_list() + i['i4'].to_list() + j['j4'].to_list()\n",
    "prod_info1['is_guncun'] = g['g5'].to_list() + [np.nan] * len(h) + [np.nan] * len(i) + [np.nan] * len(j)################## why?\n",
    "prod_info1['hold_days'] = g['g8'].to_list() + [np.nan] * len(h) + i['i8'].to_list() + [np.nan] * len(j)\n",
    "prod_info1['prod_type2'] = [np.nan]*len(g) + h['h7'].to_list() + [np.nan] * len(i) + [np.nan] * len(j)\n",
    "prod_info1['j6'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j6'].to_list()\n",
    "prod_info1['j9'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j9'].to_list()\n",
    "prod_info1['j10'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j10'].to_list()\n",
    "prod_info1['a2'] = [1] * len(g) + [3] * len(h) + [2] * len(i) + [4] * len(j)\n",
    "drop_cols = [c for c in prod_info1.columns if prod_info1[c].dtype != 'object' and prod_info1[c].std() == 0]\n",
    "print(drop_cols)\n",
    "prod_info1.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "prod_info1 = prod_info1.drop_duplicates(['prod_code', 'a2'])\n",
    "\n",
    "df = df.merge(prod_info1, how='left', on=['prod_code', 'a2'])\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['profit_rate', 'max_profit_rate', 'min_profit_rate']\n"
     ]
    }
   ],
   "source": [
    "#收益率\n",
    "profit = pd.DataFrame()\n",
    "profit['prod_code'] = g['prod_code'].to_list() + h['prod_code'].to_list() + i['prod_code'].to_list() + j['prod_code'].to_list() + k['prod_code'].to_list() + l['prod_code'].to_list() + m['prod_code'].to_list()\n",
    "profit['profit_rate'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j11'].to_list() + k['k7'].to_list() + [np.nan]*len(l) + m['m7'].to_list()\n",
    "profit['max_profit_rate'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j7'].to_list() + k['k8'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "profit['min_profit_rate'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j8'].to_list() + k['k9'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "profit['a2'] = [1] * len(g) + [3] * len(h) + [2] * len(i) + [4] * len(j) + [1] * len(k) + [3] * len(l) + [2] * len(m)\n",
    "profit = profit.groupby(['prod_code', 'a2']).mean().reset_index()\n",
    "\n",
    "drop_cols = [c for c in profit.columns if profit[c].dtype != 'object' and profit[c].std() == 0]\n",
    "print(drop_cols)\n",
    "profit.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "df = df.merge(profit, how='left', on=['prod_code', 'a2'])\n",
    "df.head()\n",
    "\n",
    "\n",
    "del k, l, m\n",
    "del g, h, i, j\n",
    "gc.collect()\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prod_code_nunique_in_uid', 'n1_cnt_in_uid', 'n_nunique_in_uid', 'n3_nunique_in_uid', 'n6_mean', 'n7_mean', 'n8_nunique', 'n9_nunique', 'n10_mean', 'u_buy_days', 'n8_last_x', 'n9_last_x', 'exp_level_mean', 'hold_days_mean', 'k10_mean', 'profit_rate_mean', 'max_profit_rate_mean', 'min_profit_rate_mean', 'u_first_buy_delta', 'u_last_buy_delta', 'u_first_last_buy_delta', 'user_max_buy_date', 'prod_code_nunique_in_uid_a2', 'n1_cnt_in_uid_a2', 'n_nunique_in_uid_a2', 'n3_nunique_in_uid_a2', 'n6_mean_a2', 'n7_mean_a2', 'n8_nunique_a2', 'n9_nunique_a2', 'n10_mean_a2', 'u_buy_days_a2', 'n8_last_y', 'n9_last_y', 'exp_level_mean_a2', 'hold_days_mean_a2', 'k10_mean_a2', 'profit_rate_mean_a2', 'max_profit_rate_mean_a2', 'min_profit_rate_mean_a2', 'u_first_buy_delta_a2', 'u_last_buy_delta_a2', 'u_first_last_buy_delta_a2', 'user_max_buy_date_a2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 7\n",
    "skip = 0 #跳过月提取特征\n",
    "months = [20210701, 20210801, 20210901, 20211001,20211201]\n",
    "# A类产品交易流水表\n",
    "n = pd.read_csv(root + 'n.csv')\n",
    "new_n = pd.read_csv(new + 'n_bc.csv')\n",
    "n=pd.concat([n,new_n])\n",
    "# #B类产品交易流水表\n",
    "o = pd.read_csv(root + 'o.csv')\n",
    "new_o = pd.read_csv(new + 'o_bc.csv')\n",
    "o=pd.concat([o,new_o])\n",
    "# C类产品交易流水表\n",
    "q = pd.read_csv(root + 'q.csv')\n",
    "new_q = pd.read_csv(new + 'q_bc.csv')\n",
    "q=pd.concat([q,new_q])\n",
    "# D类产品流水表\n",
    "p = pd.read_csv(root + 'p.csv')\n",
    "new_p = pd.read_csv(new + 'p_bc.csv')\n",
    "p=pd.concat([p,new_p])\n",
    "\n",
    "bid = pd.DataFrame()\n",
    "bid['core_cust_id'] = n['core_cust_id'].to_list() + o['core_cust_id'].to_list() + q['core_cust_id'].to_list() + p['core_cust_id'].to_list()\n",
    "bid['prod_code'] = n['prod_code'].to_list() + o['prod_code'].to_list() + q['prod_code'].to_list() + p['prod_code'].to_list()\n",
    "bid['date'] = n['n11'].to_list() + o['o12'].to_list() + q['q10'].to_list() + p['p12'].to_list()\n",
    "bid['a2'] = [1] * len(n) + [3] * len(o) + [2] * len(q) + [4] * len(p)\n",
    "bid['n1'] = n['n1'].to_list() + o['o1'].to_list() + q['q1'].to_list() + p['p1'].to_list()\n",
    "bid['n2'] = n['n2'].to_list() + o['o2'].to_list() + q['q2'].to_list() + p['p2'].to_list()\n",
    "bid['n3'] = n['n3'].to_list() + o['o3'].to_list() + q['q3'].to_list() + p['p3'].to_list()\n",
    "bid['n6'] = n['n6'].to_list() + o['o6'].to_list() + q['q6'].to_list() + p['p6'].to_list()\n",
    "bid['n7'] = n['n7'].to_list() + o['o7'].to_list() + q['q7'].to_list() + p['p7'].to_list()\n",
    "bid['n8'] = n['n8'].to_list() + o['o9'].to_list() + q['q8'].to_list() + p['p10'].to_list()\n",
    "bid['n9'] = n['n9'].to_list() + o['o8'].to_list() + q['q9'].to_list() + p['p9'].to_list()\n",
    "bid['n10'] = n['n10'].to_list() + o['o10'].to_list() + [np.nan]*len(q) + [np.nan]*len(p)\n",
    "bid['n11'] = [np.nan]*len(n) + o['o11'].to_list() + [np.nan]*len(q) + [np.nan]*len(p)\n",
    "bid['n12'] = [np.nan]*len(n) + [np.nan]*len(o) + [np.nan]*len(q) + p['p8'].to_list()\n",
    "bid['n13'] = [np.nan]*len(n) + [np.nan]*len(o) + [np.nan]*len(q) + p['p11'].to_list()\n",
    "\n",
    "bid['n7'] = bid['n7'].map(lambda x: str(x).replace(',', '') if x is not np.nan else np.nan).astype(float)\n",
    "bid['n11'] = bid['n11'].map(lambda x: str(x).replace(',', '') if x is not np.nan else np.nan).astype(float)\n",
    "bid['n10'] = bid['n10'].map(lambda x: str(x).replace(',', '') if x is not np.nan else np.nan).astype(float)\n",
    "\n",
    "bid_stats = []\n",
    "for date in months:\n",
    "    start = date - skip * 100 - window * 100\n",
    "    bid_dict = {'prod_code_nunique_in_uid': ('prod_code', 'nunique'), \n",
    "                'n1_cnt_in_uid': ('n1', 'count'),\n",
    "                'n_nunique_in_uid': ('n2', 'nunique'),\n",
    "                'n3_nunique_in_uid': ('n3', 'nunique'),\n",
    "                'n6_mean': ('n6', 'mean'),\n",
    "                'n7_mean': ('n7', 'mean'), \n",
    "                'n8_nunique': ('n8', 'nunique'),\n",
    "                'n9_nunique': ('n9', 'nunique'),\n",
    "                'n10_mean': ('n10', 'mean'),\n",
    "                'u_first_buy': ('date', 'min'), \n",
    "                'u_last_buy': ('date', 'max'), \n",
    "                'u_buy_days': ('date', 'nunique'), \n",
    "                'n8_last': ('n8', 'last'),\n",
    "                'n9_last': ('n9', 'last'),\n",
    "                'exp_level_mean': ('exp_level', 'mean'), \n",
    "                'hold_days_mean': ('hold_days', 'mean'),\n",
    "                'k10_mean': ('k10', 'mean'),\n",
    "                'profit_rate_mean': ('profit_rate', 'mean'),\n",
    "                'max_profit_rate_mean': ('max_profit_rate', 'mean'), \n",
    "                'min_profit_rate_mean': ('min_profit_rate', 'mean'),}\n",
    "    tmp_bid = bid.loc[(bid['date']>=start)&(bid['date']<date)]\n",
    "    tmp_bid = tmp_bid.drop_duplicates(['core_cust_id', 'prod_code', 'date'], keep='last')\n",
    "    tmp_bid = tmp_bid.merge(prod_info1.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    tmp_bid = tmp_bid.merge(prod_info2.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    tmp_bid = tmp_bid.merge(profit.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    bid_stat = tmp_bid.groupby('core_cust_id').agg(**bid_dict).reset_index()\n",
    "    bid_stat['a3'] = date\n",
    "    bid_stat['u_first_buy_delta'] = bid_stat['a3'] - bid_stat['u_first_buy']\n",
    "    bid_stat['u_last_buy_delta'] = bid_stat['a3'] - bid_stat['u_last_buy']\n",
    "    bid_stat['u_first_last_buy_delta'] = bid_stat['u_last_buy'] - bid_stat['u_first_buy']\n",
    "    bid_stat.drop(columns=['u_first_buy', 'u_last_buy'], inplace=True)\n",
    "    #最大交易次数在某天\n",
    "    tmp = tmp_bid.groupby(['core_cust_id', 'date'])['prod_code'].nunique().reset_index()\\\n",
    "        .sort_values(by=['core_cust_id', 'prod_code']).drop_duplicates(['core_cust_id'], keep='last')[['core_cust_id', 'date']]\\\n",
    "            .rename(columns={'date': 'user_max_buy_date'})\n",
    "    bid_stat = bid_stat.merge(tmp, how='left', on='core_cust_id')\n",
    "    bid_stat['user_max_buy_date'] = bid_stat['a3'] - bid_stat['user_max_buy_date']\n",
    "    bid_stats.append(bid_stat)\n",
    "    \n",
    "df = df.merge(pd.concat(bid_stats), how='left', on=['core_cust_id', 'a3'])\n",
    "\n",
    "\n",
    "bid_stats = []\n",
    "for date in months:\n",
    "    start = date - skip * 100 - window * 100\n",
    "    bid_dict = {'prod_code_nunique_in_uid_a2': ('prod_code', 'nunique'),\n",
    "                'n1_cnt_in_uid_a2': ('n1', 'count'), \n",
    "                'n_nunique_in_uid_a2': ('n2', 'nunique'),\n",
    "                'n3_nunique_in_uid_a2': ('n3', 'nunique'),\n",
    "                'n6_mean_a2': ('n6', 'mean'),\n",
    "                'n7_mean_a2': ('n7', 'mean'), \n",
    "                'n8_nunique_a2': ('n8', 'nunique'),\n",
    "                'n9_nunique_a2': ('n9', 'nunique'),\n",
    "                'n10_mean_a2': ('n10', 'mean'),\n",
    "                'u_first_buy_a2': ('date', 'min'), \n",
    "                'u_last_buy_a2': ('date', 'max'),\n",
    "                'u_buy_days_a2': ('date', 'nunique'), \n",
    "                'n8_last': ('n8', 'last'),\n",
    "                'n9_last': ('n9', 'last'),\n",
    "                'exp_level_mean_a2': ('exp_level', 'mean'),\n",
    "                'hold_days_mean_a2': ('hold_days', 'mean'),\n",
    "                'k10_mean_a2': ('k10', 'mean'), \n",
    "                'profit_rate_mean_a2': ('profit_rate', 'mean'),\n",
    "                'max_profit_rate_mean_a2': ('max_profit_rate', 'mean'),\n",
    "                'min_profit_rate_mean_a2': ('min_profit_rate', 'mean')}\n",
    "    tmp_bid = bid.loc[(bid['date']>=start)&(bid['date']<date)]\n",
    "    tmp_bid = tmp_bid.drop_duplicates(['core_cust_id', 'prod_code', 'date'], keep='last')\n",
    "    tmp_bid = tmp_bid.merge(prod_info1.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    tmp_bid = tmp_bid.merge(prod_info2.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    tmp_bid = tmp_bid.merge(profit.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    bid_stat = tmp_bid.groupby(['core_cust_id', 'a2']).agg(**bid_dict).reset_index()\n",
    "    bid_stat['a3'] = date\n",
    "    bid_stat['u_first_buy_delta_a2'] = bid_stat['a3'] - bid_stat['u_first_buy_a2']\n",
    "    bid_stat['u_last_buy_delta_a2'] = bid_stat['a3'] - bid_stat['u_last_buy_a2']\n",
    "    bid_stat['u_first_last_buy_delta_a2'] = bid_stat['u_last_buy_a2'] - bid_stat['u_first_buy_a2']\n",
    "    bid_stat.drop(columns=['u_first_buy_a2', 'u_last_buy_a2'], inplace=True)\n",
    "    #最大交易次数在某天\n",
    "    tmp = tmp_bid.groupby(['core_cust_id', 'a2', 'date'])['prod_code'].nunique().reset_index()\\\n",
    "        .sort_values(by=['core_cust_id', 'a2', 'prod_code']).drop_duplicates(['core_cust_id', 'a2'], keep='last')[['core_cust_id', 'a2', 'date']]\\\n",
    "            .rename(columns={'date': 'user_max_buy_date_a2'})\n",
    "    bid_stat = bid_stat.merge(tmp, how='left', on=['core_cust_id', 'a2'])\n",
    "    bid_stat['user_max_buy_date_a2'] = bid_stat['a3'] - bid_stat['user_max_buy_date_a2']\n",
    "    bid_stats.append(bid_stat)\n",
    "df = df.merge(pd.concat(bid_stats), how='left', on=['core_cust_id', 'a3', 'a2'])\n",
    "del bid_stat, o, p, q,new_o,new_q,new_p,n,new_n\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid_cnt_in_r3_equal_1', 'uid_cnt_in_r3_equal_2', 'prod_code_nunique_grp_uid_in_app_action', 'r5_nunique_grp_uid_in_app_action', 'user_click_days', 'exp_level_mean_click', 'hold_days_mean_click', 'k10_mean_click', 'profit_rate_mean_click', 'max_profit_rate_mean_click', 'min_profit_rate_mean_click', 'first_click_delta', 'last_click_delta', 'first_last_delta', 'user_max_click_prod', 'user_max_click_prod_cnt', 'prod_code_nunique_grp_uid_in_app_action_a2', 'r5_nunique_grp_uid_in_app_action_a2', 'user_click_days_a2', 'exp_level_mean_click_a2', 'hold_days_mean_click_a2', 'k10_mean_click_a2', 'profit_rate_mean_click_a2', 'max_profit_rate_mean_click_a2', 'min_profit_rate_mean_click_a2', 'first_click_deltaa2', 'last_click_deltaa2', 'first_last_deltaa2', 'user_max_click_prod_a2', 'user_max_click_prod_cnt_a2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>core_cust_id</th>\n",
       "      <th>prod_code</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>y</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>e1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>hold_days_mean_click_a2</th>\n",
       "      <th>k10_mean_click_a2</th>\n",
       "      <th>profit_rate_mean_click_a2</th>\n",
       "      <th>max_profit_rate_mean_click_a2</th>\n",
       "      <th>min_profit_rate_mean_click_a2</th>\n",
       "      <th>first_click_deltaa2</th>\n",
       "      <th>last_click_deltaa2</th>\n",
       "      <th>first_last_deltaa2</th>\n",
       "      <th>user_max_click_prod_a2</th>\n",
       "      <th>user_max_click_prod_cnt_a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e3c3d57b83e425f8087b1d6d32a50f7</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>90318011</td>\n",
       "      <td>4</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa83c5fc05414c4d9727f0b32882f80e</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211530</td>\n",
       "      <td>1</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11245458ed6446cd9f88d57a5fc1d957</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>DECD21090102</td>\n",
       "      <td>2</td>\n",
       "      <td>20210901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359a03ecc46240d9bc00eef58dbc85e3</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211119</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7a5d79036dfb46acb7348e741ab00d9f</td>\n",
       "      <td>6e2105d9fe</td>\n",
       "      <td>GRHLA20211125</td>\n",
       "      <td>1</td>\n",
       "      <td>20210801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id core_cust_id      prod_code  a2        a3  \\\n",
       "0  4e3c3d57b83e425f8087b1d6d32a50f7   6e2105d9fe       90318011   4  20210801   \n",
       "1  aa83c5fc05414c4d9727f0b32882f80e   6e2105d9fe  GRHLA20211530   1  20210901   \n",
       "2  11245458ed6446cd9f88d57a5fc1d957   6e2105d9fe   DECD21090102   2  20210901   \n",
       "3  359a03ecc46240d9bc00eef58dbc85e3   6e2105d9fe  GRHLA20211119   1  20210801   \n",
       "4  7a5d79036dfb46acb7348e741ab00d9f   6e2105d9fe  GRHLA20211125   1  20210801   \n",
       "\n",
       "     y  d1   d2  d3  e1_mean  ...  hold_days_mean_click_a2  k10_mean_click_a2  \\\n",
       "0  0.0   1  4.0  32      NaN  ...                      NaN                NaN   \n",
       "1  0.0   1  4.0  32      NaN  ...                      NaN                NaN   \n",
       "2  0.0   1  4.0  32      NaN  ...                      NaN                NaN   \n",
       "3  0.0   1  4.0  32      NaN  ...                      NaN                NaN   \n",
       "4  0.0   1  4.0  32      NaN  ...                      NaN                NaN   \n",
       "\n",
       "   profit_rate_mean_click_a2  max_profit_rate_mean_click_a2  \\\n",
       "0                        NaN                            NaN   \n",
       "1                        NaN                            NaN   \n",
       "2                        NaN                            NaN   \n",
       "3                        NaN                            NaN   \n",
       "4                        NaN                            NaN   \n",
       "\n",
       "   min_profit_rate_mean_click_a2  first_click_deltaa2  last_click_deltaa2  \\\n",
       "0                            NaN                  NaN                 NaN   \n",
       "1                            NaN                  NaN                 NaN   \n",
       "2                            NaN                  NaN                 NaN   \n",
       "3                            NaN                  NaN                 NaN   \n",
       "4                            NaN                  NaN                 NaN   \n",
       "\n",
       "   first_last_deltaa2  user_max_click_prod_a2  user_max_click_prod_cnt_a2  \n",
       "0                 NaN                     NaN                         NaN  \n",
       "1                 NaN                     NaN                         NaN  \n",
       "2                 NaN                     NaN                         NaN  \n",
       "3                 NaN                     NaN                         NaN  \n",
       "4                 NaN                     NaN                         NaN  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# APP点击行为表\n",
    "r = pd.read_csv(root + 'r.csv')\n",
    "new_r = pd.read_csv(new+'r_bc.csv')\n",
    "r = pd.concat([r,new_r])\n",
    "r['date'] = r['r5'].map(lambda x: str(x).split(' ')[0].replace('-','')).astype(int)\n",
    "window = 7\n",
    "skip = 0 #跳过月提取特征\n",
    "months = [20210701, 20210801, 20210901, 20211001,20211201]\n",
    "r_dict = {'prod_code_nunique_grp_uid_in_app_action': ('prod_code', 'nunique'), \n",
    "          'r5_nunique_grp_uid_in_app_action': ('r5', 'count'),\n",
    "          'user_click_days': ('date', 'nunique'),\n",
    "          'first_click': ('date', 'min'),\n",
    "          'last_click': ('date', 'max'),\n",
    "          'exp_level_mean_click': ('exp_level', 'mean'), \n",
    "          'hold_days_mean_click': ('hold_days', 'mean'), \n",
    "          'k10_mean_click': ('k10', 'mean'),\n",
    "          'profit_rate_mean_click': ('profit_rate', 'mean'), \n",
    "          'max_profit_rate_mean_click': ('max_profit_rate', 'mean'),\n",
    "          'min_profit_rate_mean_click': ('min_profit_rate', 'mean'),}\n",
    "pivots = []\n",
    "pivots1 = []\n",
    "pivots2 = []\n",
    "r_stats = []\n",
    "r_prod_aggs = []\n",
    "r_cust_prod_aggs = []\n",
    "for date in months:\n",
    "    start = date - skip * 100 - window * 100\n",
    "    rr = r.loc[(r['date']>=start) & (r['date']<date)]\n",
    "    rr = rr.merge(prod_info1, how='left', on='prod_code')\n",
    "    rr = rr.merge(prod_info2.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    rr = rr.merge(profit.drop(columns=['a2']), how='left', on='prod_code')\n",
    "    r_stat = rr.groupby(['core_cust_id']).agg(**r_dict).reset_index()\n",
    "    r_stat['a3'] = date\n",
    "    r_stat['first_click_delta'] = r_stat['a3'] - r_stat['first_click']\n",
    "    r_stat['last_click_delta'] = r_stat['a3'] - r_stat['last_click']\n",
    "    r_stat['first_last_delta'] = r_stat['last_click'] - r_stat['first_click']\n",
    "    r_stat.drop(columns=['first_click', 'last_click'], inplace=True)\n",
    "    ##最大点击次数\n",
    "    tmp = rr.groupby(['core_cust_id', 'date'])['prod_code'].nunique().reset_index()\\\n",
    "        .sort_values(by=['core_cust_id', 'prod_code']).drop_duplicates(['core_cust_id'], keep='last')[['core_cust_id', 'date']]\\\n",
    "            .rename(columns={'date': 'user_max_click_prod'})\n",
    "    r_stat = r_stat.merge(tmp, how='left', on=['core_cust_id'])\n",
    "    r_stat['user_max_click_prod'] = r_stat['a3'] - r_stat['user_max_click_prod']\n",
    "    tmp = rr.groupby(['core_cust_id', 'date'])['prod_code'].count().reset_index()\\\n",
    "        .sort_values(by=['core_cust_id', 'prod_code']).drop_duplicates(['core_cust_id'], keep='last')[['core_cust_id', 'date']]\\\n",
    "            .rename(columns={'date': 'user_max_click_prod_cnt'})\n",
    "    r_stat = r_stat.merge(tmp, how='left', on=['core_cust_id'])\n",
    "    r_stat['user_max_click_prod_cnt'] = r_stat['a3'] - r_stat['user_max_click_prod_cnt']\n",
    "    r_stats.append(r_stat)\n",
    "    \n",
    "    r_pivot_stat = pd.pivot_table(rr, index='core_cust_id', columns=['r3'], values=['r1'], aggfunc='count').fillna(0)\n",
    "    r_pivot_stat = r_pivot_stat.reset_index()\n",
    "    r_pivot_stat.columns = ['core_cust_id', 'uid_cnt_in_r3_equal_1', 'uid_cnt_in_r3_equal_2']\n",
    "    \n",
    "    r_pivot_stat1 = pd.pivot_table(rr, index='prod_code', columns=['r3'], values=['r1'], aggfunc='count').fillna(0)\n",
    "    r_pivot_stat1 = r_pivot_stat1.reset_index()\n",
    "    r_pivot_stat1.columns = ['prod_code', 'pid_cnt_in_r3_equal_1', 'pid_cnt_in_r3_equal_2']\n",
    "    \n",
    "    r_pivot_stat2 = pd.pivot_table(rr, index=['core_cust_id','prod_code'], columns=['r3'], values=['r1'], aggfunc='count').fillna(0)\n",
    "    r_pivot_stat2 =  r_pivot_stat2.reset_index()\n",
    "    r_pivot_stat2.columns = ['core_cust_id','prod_code','cust_prod_r1_1_count','cust_prod_r1_2_count']\n",
    "    \n",
    "    r_pivot_stat['a3'] = date\n",
    "    r_pivot_stat1['a3'] = date\n",
    "    r_pivot_stat2['a3'] = date\n",
    "    \n",
    "    pivots.append(r_pivot_stat)\n",
    "    pivots1.append(r_pivot_stat1)\n",
    "    pivots2.append(r_pivot_stat2)\n",
    "    \n",
    "    r_prod_agg = rr.groupby('prod_code').agg(cust_id_count = ('r1','count')).reset_index()\n",
    "    r_prod_agg['a3'] = date\n",
    "    r_prod_aggs.append(r_prod_agg)\n",
    "    r_cust_prod_agg = rr.groupby(['prod_code','core_cust_id']).agg(\n",
    "                                            cust_id_prod_code_count = ('r1','count')).reset_index()\n",
    "    r_cust_prod_agg['a3'] = date\n",
    "    r_cust_prod_aggs.append(r_cust_prod_agg)\n",
    "    \n",
    "r_pivot_stat = pd.concat(pivots)\n",
    "df = df.merge(r_pivot_stat, on=['core_cust_id', 'a3'], how='left')\n",
    "r_stat = pd.concat(r_stats)\n",
    "df = df.merge(r_stat, on=['core_cust_id', 'a3'], how='left')\n",
    "## new features\n",
    "'''r_pivot_stat1 = pd.concat(pivots1)\n",
    "df = df.merge(r_pivot_stat1, on=['prod_code', 'a3'], how='left')\n",
    "r_pivot_stat2 = pd.concat(pivots2)\n",
    "df = df.merge(r_pivot_stat2, on=['core_cust_id','prod_code', 'a3'], how='left')\n",
    "r_stat = pd.concat(r_prod_aggs)\n",
    "df = df.merge(r_stat, on=['prod_code', 'a3'], how='left')\n",
    "r_stat = pd.concat(r_cust_prod_aggs)\n",
    "df = df.merge(r_stat, on=['core_cust_id','prod_code', 'a3'], how='left')\n",
    "df['cust_id_prod_code_count_div_cust_id_count'] = df['cust_id_prod_code_count'] / df['cust_id_count']\n",
    "df['cust_id_prod_code_count_div_prod_code_count'] = df['cust_id_prod_code_count'] / df['r5_nunique_grp_uid_in_app_action']'''\n",
    "\n",
    "del r_prod_aggs,r_cust_prod_aggs,r_stats,r_pivot_stat1,r_pivot_stat2,r_stat,pivots,pivots1,pivots2\n",
    "gc.collect()\n",
    "for col in ['a2']:\n",
    "    r_dict = {'prod_code_nunique_grp_uid_in_app_action_'+col: ('prod_code', 'nunique'),\n",
    "              'r5_nunique_grp_uid_in_app_action_'+col: ('r5', 'count'),\n",
    "              'user_click_days_'+col: ('date', 'nunique'),\n",
    "            'first_click': ('date', 'min'),\n",
    "              'last_click': ('date', 'max'),\n",
    "            'exp_level_mean_click_'+col: ('exp_level', 'mean'),\n",
    "              'hold_days_mean_click_'+col: ('hold_days', 'mean'), \n",
    "              'k10_mean_click_'+col: ('k10', 'mean'),\n",
    "            'profit_rate_mean_click_'+col: ('profit_rate', 'mean'),\n",
    "              'max_profit_rate_mean_click_'+col: ('max_profit_rate', 'mean'),\n",
    "              'min_profit_rate_mean_click_'+col: ('min_profit_rate', 'mean'),\n",
    "            }\n",
    "    r_stats = []\n",
    "    for date in months:\n",
    "        start = date - skip * 100 - window * 100\n",
    "        rr = r.loc[(r['date']>=start) & (r['date']<date)]\n",
    "        rr = rr.merge(prod_info1, how='left', on='prod_code')\n",
    "        rr = rr.merge(prod_info2.drop(columns=['a2']), how='left', on='prod_code')\n",
    "        rr = rr.merge(profit.drop(columns=['a2']), how='left', on='prod_code')\n",
    "        r_stat = rr.groupby(['core_cust_id', col]).agg(**r_dict).reset_index()\n",
    "        r_stat['a3'] = date\n",
    "        r_stat['first_click_delta'+col] = r_stat['a3'] - r_stat['first_click']\n",
    "        r_stat['last_click_delta'+col] = r_stat['a3'] - r_stat['last_click']\n",
    "        r_stat['first_last_delta'+col] = r_stat['last_click'] - r_stat['first_click']\n",
    "        r_stat.drop(columns=['first_click', 'last_click'], inplace=True)\n",
    "        ##最大点击次数\n",
    "        tmp = rr.groupby(['core_cust_id', col, 'date'])['prod_code'].nunique().reset_index()\\\n",
    "            .sort_values(by=['core_cust_id', col, 'prod_code']).drop_duplicates(['core_cust_id', col], keep='last')[['core_cust_id', col, 'date']]\\\n",
    "                .rename(columns={'date': 'user_max_click_prod_'+col})\n",
    "        r_stat = r_stat.merge(tmp, how='left', on=['core_cust_id', col])\n",
    "        r_stat['user_max_click_prod_'+col] = r_stat['a3'] - r_stat['user_max_click_prod_'+col]\n",
    "        tmp = rr.groupby(['core_cust_id', col, 'date'])['prod_code'].count().reset_index()\\\n",
    "            .sort_values(by=['core_cust_id', col, 'prod_code']).drop_duplicates(['core_cust_id', col], keep='last')[['core_cust_id', col, 'date']]\\\n",
    "                .rename(columns={'date': 'user_max_click_prod_cnt_'+col})\n",
    "        r_stat = r_stat.merge(tmp, how='left', on=['core_cust_id', col])\n",
    "        r_stat['user_max_click_prod_cnt_'+col] = r_stat['a3'] - r_stat['user_max_click_prod_cnt_'+col]\n",
    "        \n",
    "        r_stats.append(r_stat)\n",
    "    r_stat = pd.concat(r_stats)\n",
    "    df = df.merge(r_stat, on=['core_cust_id', col, 'a3'], how='left')\n",
    "\n",
    "print_new_cols(df.columns,df_columns)\n",
    "df_columns = df.columns\n",
    "del r, r_pivot_stat, r_stat\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new columns: Index(['borrow_cnt', 'borrow_amt_mean_grp_uid', 'borrow_amt_max_grp_uid',\n",
      "       'borrow_amt_last_grp_uid', 'first_borrow_delta', 'last_borrow_delta',\n",
      "       'first_last_borrow_delta', 's3', 'user_max_borrow_v',\n",
      "       'user_max_borrow_date', 'loan_cnt', 'loan_amt_mean_grp_uid',\n",
      "       'loan_amt_max_grp_uid', 'loan_amt_last_grp_uid', 'first_loan_delta',\n",
      "       'last_loan_delta', 'first_last_loan_delta', 's6', 'user_max_loan_v',\n",
      "       'user_max_loan_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 账户交易流水表\n",
    "s = pd.read_csv(root + 's.csv')\n",
    "new_s = pd.read_csv(new + 's_bc.csv')\n",
    "s = pd.concat([s,new_s])\n",
    "s['date'] = s['s5'].map(lambda x: str(x).replace('-', '')).astype(int)\n",
    "s['s4'] = s['s4'].apply(lambda x: str(x).replace(',','')).astype('float')  \n",
    "\n",
    "window = 7\n",
    "skip = 0 #跳过月提取特征\n",
    "months = [20210701, 20210801, 20210901, 20211001,20211201]\n",
    "\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "for date in months:\n",
    "    start = date - skip * 100 - window * 100\n",
    "    ss = s.loc[(s['date']>=start) & (s['date']<date)]\n",
    "    tmp = ss.groupby('s3').size().reset_index()\n",
    "    tmp.columns = ['core_cust_id','borrow_cnt']\n",
    "    tmp['borrow_amt_mean_grp_uid'] = ss.groupby('s3')['s4'].agg('mean').values\n",
    "    tmp['borrow_amt_max_grp_uid'] = ss.groupby('s3')['s4'].agg('max').values\n",
    "    tmp['borrow_amt_last_grp_uid'] = ss.sort_values(by=['s3', 'date']).groupby('s3')['s4'].agg('last').values\n",
    "    tmp['first_borrow'] = ss.groupby('s3')['date'].agg('min').values\n",
    "    tmp['last_borrow'] = ss.groupby('s3')['date'].agg('max').values\n",
    "    tmp['a3'] = date\n",
    "    tmp['first_borrow_delta'] = tmp['a3'] - tmp['first_borrow']\n",
    "    tmp['last_borrow_delta'] = tmp['a3'] - tmp['last_borrow']\n",
    "    tmp['first_last_borrow_delta'] = tmp['last_borrow'] - tmp['first_borrow']\n",
    "    tmp.drop(columns=['first_borrow', 'last_borrow'], inplace=True)\n",
    "    t = ss.groupby(['s3', 'date'])['s4'].sum().reset_index().sort_values(by=['s3', 's4']).drop_duplicates(['s3'], keep='last')[['s3', 's4', 'date']]\\\n",
    "            .rename(columns={'date': 'user_max_borrow_date', 's4': 'user_max_borrow_v'})\n",
    "    tmp = tmp.merge(t, how='left', left_on='core_cust_id', right_on='s3')\n",
    "    tmp['user_max_borrow_date'] = tmp['a3'] - tmp['user_max_borrow_date']\n",
    "    \n",
    "    feature1.append(tmp)\n",
    "    \n",
    "    tmp = ss.groupby('s6').size().reset_index()\n",
    "    tmp.columns = ['core_cust_id','loan_cnt']\n",
    "    tmp['loan_amt_mean_grp_uid'] = ss.groupby('s6')['s4'].agg('mean').values\n",
    "    tmp['loan_amt_max_grp_uid'] = ss.groupby('s6')['s4'].agg('max').values\n",
    "    tmp['loan_amt_last_grp_uid'] = ss.sort_values(by=['s6', 'date']).groupby('s6')['s4'].agg('last').values\n",
    "    tmp['first_loan'] = ss.groupby('s6')['date'].agg('min').values\n",
    "    tmp['last_loan'] = ss.groupby('s6')['date'].agg('max').values\n",
    "    \n",
    "    tmp['a3'] = date\n",
    "    tmp['first_loan_delta'] = tmp['a3'] - tmp['first_loan']\n",
    "    tmp['last_loan_delta'] = tmp['a3'] - tmp['last_loan']\n",
    "    tmp['first_last_loan_delta'] = tmp['last_loan'] - tmp['first_loan']\n",
    "    tmp.drop(columns=['first_loan', 'last_loan'], inplace=True)\n",
    "    t = ss.groupby(['s6', 'date'])['s4'].sum().reset_index().sort_values(by=['s6', 's4']).drop_duplicates(['s6'], keep='last')[['s6', 's4', 'date']]\\\n",
    "            .rename(columns={'date': 'user_max_loan_date', 's4': 'user_max_loan_v'})\n",
    "    tmp = tmp.merge(t, how='left', left_on='core_cust_id', right_on='s6')\n",
    "    tmp['user_max_loan_date'] = tmp['a3'] - tmp['user_max_loan_date']\n",
    "    feature2.append(tmp)\n",
    "feature1 = pd.concat(feature1)\n",
    "feature2 = pd.concat(feature2)\n",
    "\n",
    "df = df.merge(feature1, how='left', on=['core_cust_id', 'a3'])\n",
    "del feature1,tmp ,s,t,new_s\n",
    "gc.collect()\n",
    "df = df.merge(feature2, how='left', on=['core_cust_id', 'a3'])\n",
    "del feature2\n",
    "gc.collect()\n",
    "print('new columns:',df.columns[-(len(df.columns)-len(df_columns)):])\n",
    "df_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k1', 'k2', 'k3', 'prod_type2', 'j9', 'j10']\n"
     ]
    }
   ],
   "source": [
    "# 保存数据\n",
    "drop_cols = ['prod_date1', 'prod_date2', 's3', 's6']\n",
    "df.drop(drop_cols, axis=1,inplace=True)\n",
    "\n",
    "sp_cols = [c for c in df.columns if df[c].dtype != 'object' and df[c].std() == 0]\n",
    "print(sp_cols)\n",
    "df.drop(sp_cols, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## this knn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''g = pd.read_csv(root + 'g.csv')\n",
    "# B理财产品表1\n",
    "h = pd.read_csv(root + 'h.csv')\n",
    "# C理财产品表1\n",
    "i = pd.read_csv(root + 'i.csv')\n",
    "# D理财产品表1\n",
    "j = pd.read_csv(root + 'j.csv')\n",
    "prod_info1 = pd.DataFrame()\n",
    "prod_info1['prod_code'] = g['prod_code'].to_list() + h['prod_code'].to_list() + i['prod_code'].to_list() + j['prod_code'].to_list()\n",
    "prod_info1['prod_date1'] = g['g9'].to_list() + h['h8'].to_list() + i['i9'].to_list() + j['j13'].to_list()\n",
    "prod_info1['bid_type'] = g['g1'].to_list() + h['h1'].to_list() + i['i1'].to_list() + j['j1'].to_list()\n",
    "prod_info1['recur_type'] = g['g2'].to_list() + h['h2'].to_list() + i['i2'].to_list() + j['j2'].to_list()\n",
    "prod_info1['prod_type'] = g['g3'].to_list() + h['h3'].to_list() + i['i3'].to_list() + j['j3'].to_list()\n",
    "prod_info1['exp_level'] = g['g4'].to_list() + h['h4'].to_list() + i['i4'].to_list() + j['j4'].to_list()\n",
    "prod_info1['is_guncun'] = g['g5'].to_list() + [np.nan] * len(h) + [np.nan] * len(i) + [np.nan] * len(j)################## why?\n",
    "prod_info1['hold_days'] = g['g8'].to_list() + [np.nan] * len(h) + i['i8'].to_list() + [np.nan] * len(j)\n",
    "prod_info1['prod_type2'] = [np.nan]*len(g) + h['h7'].to_list() + [np.nan] * len(i) + [np.nan] * len(j)\n",
    "prod_info1['j6'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j6'].to_list()\n",
    "prod_info1['j9'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j9'].to_list()\n",
    "prod_info1['j10'] = [np.nan]*len(g) + [np.nan]*len(h) + [np.nan] * len(i) + j['j10'].to_list()\n",
    "prod_info1['a2'] = [1] * len(g) + [3] * len(h) + [2] * len(i) + [4] * len(j)\n",
    "prod_info1['prod_date1'] = prod_info1['prod_date1'].replace(209912,202112)\n",
    "pivot = prod_info1.loc[:,['prod_date1','bid_type','recur_type','exp_level','is_guncun','hold_days','a2']]\n",
    "pivot = pivot.fillna(pivot.mean())\n",
    "pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "print('start knn')\n",
    "N_NEIGHBORS_MAX = 100\n",
    "class Neighbors:\n",
    "    def __init__(self, pivot, p, metric='minkowski', metric_params=None):\n",
    "        nn = NearestNeighbors(n_neighbors=N_NEIGHBORS_MAX, p=p, metric=metric, metric_params=metric_params)\n",
    "        nn.fit(pivot)\n",
    "        self.distances, self.neighbors = nn.kneighbors(pivot, return_distance=True)\n",
    "with timer('k_neighbors_cust_prod_c'):\n",
    "    k_neighbors_cust_prod_c = Neighbors(pivot, 2, metric='canberra')\n",
    "    #k_neighbors_cust_prod_m = Neighbors(pivot, 2, metric='mahalanobis', metric_params={'V':np.cov(pivot.values.T)})\n",
    "cols_agg = {\n",
    "    'hold_days': [np.mean, np.min, np.max],\n",
    "}\n",
    "\n",
    "neighbor_sizes = [30,40]\n",
    "def make_knn_features(df,neighbor_sizes,all_neighbors,cols_agg):\n",
    "    result = np.zeros([len(neighbor_sizes),len(all_neighbors),len(cols_agg.keys())*3])\n",
    "    for i,size in enumerate(neighbor_sizes):\n",
    "        neighbors = all_neighbors[:,:size]\n",
    "        agg_values = np.zeros([len(all_neighbors),len(cols_agg.keys())*3])\n",
    "        for row in tqdm(range(len(all_neighbors))):\n",
    "            part_df = df.iloc[neighbors[row]]\n",
    "            for index,col in enumerate(cols_agg.keys()):\n",
    "                mean = np.mean(part_df[col])\n",
    "                amin = np.min(part_df[col])\n",
    "                amax = np.max(part_df[col])\n",
    "                agg_values[row,index*3:(index+1)*3] = np.array([mean,amin,amax])\n",
    "        result[i] = agg_values\n",
    "    return result\n",
    "a = make_knn_features(prod_info1,neighbor_sizes,k_neighbors_cust_prod_c.neighbors,cols_agg)\n",
    "knn_hold = pd.DataFrame()\n",
    "knn_hold['prod_code'] = prod_info1['prod_code']\n",
    "for i,col in enumerate(cols_agg.keys()):\n",
    "    for j,agg in enumerate(['mean','min','max']):\n",
    "        for k,size in enumerate(neighbor_sizes):\n",
    "            knn_hold[col+'_'+str(size)+'nn_'+agg] = a[k,:,i*3+j]\n",
    "df = df.merge(knn_hold,on='prod_code',how='left')\n",
    "for i in tqdm(df.columns):\n",
    "    if '0nn' in i:\n",
    "        df[i] = df['hold_days'] - df[i] '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profit rate knn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''k = pd.read_csv(root + 'k.csv')\n",
    "# B理财产品表2\n",
    "l = pd.read_csv(root + 'l.csv')\n",
    "# C理财产品表2\n",
    "m = pd.read_csv(root + 'm.csv')\n",
    "j = pd.read_csv(root + 'j.csv')\n",
    "profit = pd.DataFrame()\n",
    "profit['prod_code'] = j['prod_code'].to_list() + k['prod_code'].to_list() + l['prod_code'].tolist() + m['prod_code'].to_list()\n",
    "profit['profit_rate'] =  j['j11'].to_list() + k['k7'].to_list() + [np.nan]*len(l) + m['m7'].to_list()\n",
    "profit['max_profit_rate'] =j['j7'].to_list() + k['k8'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "profit['min_profit_rate'] =  j['j8'].to_list() + k['k9'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "profit['a2'] = [4] * len(j) + [1] * len(k) + [3] * len(l) + [2] * len(m)\n",
    "\n",
    "pivot = profit.loc[:,['profit_rate','max_profit_rate','min_profit_rate','a2']]\n",
    "pivot = pivot.fillna(pivot.mean())\n",
    "pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "N_NEIGHBORS_MAX = 40\n",
    "class Neighbors:\n",
    "    def __init__(self, pivot, p, metric='minkowski', metric_params=None):\n",
    "        nn = NearestNeighbors(n_neighbors=N_NEIGHBORS_MAX, p=p, metric=metric, metric_params=metric_params)\n",
    "        nn.fit(pivot)\n",
    "        self.distances, self.neighbors = nn.kneighbors(pivot, return_distance=True)\n",
    "with timer('k_neighbors_cust_prod_c'):\n",
    "    k_neighbors_cust_prod_c = Neighbors(pivot, 2, metric='canberra')\n",
    "a = np.zeros([10000,100])\n",
    "with timer('k_neighbors_cust_prod_c'):\n",
    "    k_neighbors_cust_prod_c = Neighbors(a, 2, metric='canberra')\n",
    "cols_agg = {\n",
    "    'profit_rate': [np.mean, np.min, np.max],\n",
    "    'max_profit_rate':[np.mean, np.min, np.max],\n",
    "    'min_profit_rate':[np.mean, np.min, np.max]\n",
    "}\n",
    "\n",
    "neighbor_sizes = [40,500]\n",
    "def make_knn_features(df,neighbor_sizes,all_neighbors,cols_agg):\n",
    "    result = np.zeros([len(neighbor_sizes),len(all_neighbors),len(cols_agg.keys())*3])\n",
    "    for i,size in enumerate(neighbor_sizes):\n",
    "        neighbors = all_neighbors[:,:size]\n",
    "        agg_values = np.zeros([len(all_neighbors),len(cols_agg.keys())*3])\n",
    "        for row in tqdm(range(len(all_neighbors))):\n",
    "            part_df = df.iloc[neighbors[row]]\n",
    "            for index,col in enumerate(cols_agg.keys()):\n",
    "                mean = np.mean(part_df[col])\n",
    "                amin = np.min(part_df[col])\n",
    "                amax = np.max(part_df[col])\n",
    "                agg_values[row,index*3:(index+1)*3] = np.array([mean,amin,amax])\n",
    "        result[i] = agg_values\n",
    "    return result\n",
    "a = make_knn_features(profit,neighbor_sizes,k_neighbors_cust_prod_c.neighbors,cols_agg)\n",
    "knn_hold = pd.DataFrame()\n",
    "knn_hold['prod_code'] = profit['prod_code']\n",
    "for i,col in enumerate(cols_agg.keys()):\n",
    "    for j,agg in enumerate(['mean','min','max']):\n",
    "        for k,size in enumerate(neighbor_sizes):\n",
    "            knn_hold[col+'_'+str(size)+'nn_'+agg] = a[k,:,i*3+j]\n",
    "df = df.merge(knn_hold,on='prod_code',how='left')\n",
    "for i in tqdm(df.columns):\n",
    "    if 'nn' in i:\n",
    "        if 'max_profit_rate' in i:\n",
    "            df[i] = df[i] = df['max_profit_rate']\n",
    "        elif 'min_profit_rate'in i:\n",
    "            df[i] = df[i] = df['min_profit_rate']\n",
    "        elif 'profit_rate' in i:\n",
    "            df[i] = df[i] = df['profit_rate']'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## second level features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### diff features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:21<00:00,  7.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_cols = ['e1_last','d2','age_level']\n",
    "df['age_level'] = np.floor(df['d3'] / 10)\n",
    "yes = df[df['y']==1]\n",
    "for i in tqdm(count_cols):\n",
    "    '''cnts = df[i].value_counts(normalize=True).reset_index()\n",
    "    cnts.columns=[i,i+'_cnts_all']\n",
    "    df = df.merge(cnts,how='left',on=i)'''\n",
    "    gc.collect()\n",
    "    cnts = yes[i].value_counts(normalize=True).reset_index()\n",
    "    cnts.columns=[i,i+'_cnts_yes']\n",
    "    df = df.merge(cnts,how='left',on=i)\n",
    "    del cnts\n",
    "    gc.collect()\n",
    "df.drop(columns=['age_level'],inplace=True)\n",
    "\n",
    "del yes\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = pd.read_csv(root + 'g.csv')\n",
    "# B理财产品表1\n",
    "h = pd.read_csv(root + 'h.csv')\n",
    "# C理财产品表1\n",
    "i = pd.read_csv(root + 'i.csv')\n",
    "# D理财产品表1\n",
    "j = pd.read_csv(root + 'j.csv')\n",
    "prod_info1 = pd.DataFrame()\n",
    "prod_info1['exp_level'] = g['g4'].to_list() + h['h4'].to_list() + i['i4'].to_list() + j['j4'].to_list()\n",
    "prod_info1['hold_days'] = g['g8'].to_list() + [np.nan] * len(h) + i['i8'].to_list() + [np.nan] * len(j)\n",
    "prod_info1['a2'] = [1] * len(g) + [3] * len(h) + [2] * len(i) + [4] * len(j)\n",
    "prod_agg_dict={\n",
    "    'exp_level':[np.min,np.max,np.mean],\n",
    "    'hold_days':[np.min,np.max,np.mean],\n",
    "}\n",
    "prod_agg = prod_info1.groupby(['a2']).agg(prod_agg_dict)\n",
    "prod_agg.columns = ['_'.join(i) + '_ina2' for i in prod_agg.columns]\n",
    "prod_agg = prod_agg.reset_index()\n",
    "df = df.merge(prod_agg,how='left',on=['a2'])\n",
    "prod_cols = ['exp_level','hold_days']\n",
    "agg_cols = ['amin','amax','mean']\n",
    "for i in prod_cols:\n",
    "    for j in agg_cols:\n",
    "        df[i+'_'+j+'_a2_diff'] = df[i] - df[i+'_'+j+'_ina2']\n",
    "df.drop(columns = ['exp_level_amin_ina2', 'exp_level_amax_ina2',\n",
    "       'exp_level_mean_ina2', 'hold_days_amin_ina2', 'hold_days_amax_ina2',\n",
    "       'hold_days_mean_ina2'],inplace=True)\n",
    "del g,h,i,j, prod_info1,prod_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = pd.read_csv(root + 'k.csv')\n",
    "# B理财产品表2\n",
    "l = pd.read_csv(root + 'l.csv')\n",
    "# C理财产品表2\n",
    "m = pd.read_csv(root + 'm.csv')\n",
    "j = pd.read_csv(root + 'j.csv')\n",
    "profit = pd.DataFrame()\n",
    "profit['profit_rate'] =  j['j11'].to_list() + k['k7'].to_list() + [np.nan]*len(l) + m['m7'].to_list()\n",
    "profit['max_profit_rate'] =j['j7'].to_list() + k['k8'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "profit['min_profit_rate'] =  j['j8'].to_list() + k['k9'].to_list() + [np.nan]*len(l) + [np.nan]*len(m)\n",
    "profit['a2'] = [4] * len(j) + [1] * len(k) + [3] * len(l) + [2] * len(m)\n",
    "prod_agg_dict={\n",
    "    'profit_rate':[np.min,np.max,np.mean],\n",
    "    'max_profit_rate':[np.min,np.max,np.mean],\n",
    "    'min_profit_rate':[np.min,np.max,np.mean]\n",
    "}\n",
    "prod_agg = profit.groupby(['a2']).agg(prod_agg_dict)\n",
    "prod_agg.columns = ['_'.join(i) + '_ina2' for i in prod_agg.columns]\n",
    "prod_agg = prod_agg.reset_index()\n",
    "df = df.merge(prod_agg,how='left',on=['a2'])\n",
    "prod_cols = ['profit_rate','max_profit_rate','min_profit_rate']\n",
    "agg_cols = ['amin','amax','mean']\n",
    "for i in prod_cols:\n",
    "    for j in agg_cols:\n",
    "        df[i+'_'+j+'_a2_diff'] = df[i] - df[i+'_'+j+'_ina2']\n",
    "df.drop(columns = ['profit_rate_amin_ina2', 'profit_rate_amax_ina2',\n",
    "       'profit_rate_mean_ina2', 'max_profit_rate_amin_ina2', 'max_profit_rate_amax_ina2',\n",
    "       'max_profit_rate_mean_ina2','min_profit_rate_amin_ina2', 'min_profit_rate_amax_ina2',\n",
    "       'min_profit_rate_mean_ina2'],inplace=True)\n",
    "del k,l,m,j, profit,prod_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''n = pd.read_csv(root + 'n.csv')\n",
    "new_n = pd.read_csv(new + 'n_bc.csv')\n",
    "n=pd.concat([n,new_n])\n",
    "# #B类产品交易流水表\n",
    "o = pd.read_csv(root + 'o.csv')\n",
    "new_o = pd.read_csv(new + 'o_bc.csv')\n",
    "o=pd.concat([o,new_o])\n",
    "# C类产品交易流水表\n",
    "q = pd.read_csv(root + 'q.csv')\n",
    "new_q = pd.read_csv(new + 'q_bc.csv')\n",
    "q=pd.concat([q,new_q])\n",
    "# D类产品流水表\n",
    "p = pd.read_csv(root + 'p.csv')\n",
    "new_p = pd.read_csv(new + 'p_bc.csv')\n",
    "p=pd.concat([p,new_p])\n",
    "\n",
    "bid = pd.DataFrame()\n",
    "bid['a2'] = [1] * len(n) + [3] * len(o) + [2] * len(q) + [4] * len(p)\n",
    "bid['n6'] = n['n6'].to_list() + o['o6'].to_list() + q['q6'].to_list() + p['p6'].to_list()\n",
    "bid['n7'] = n['n7'].to_list() + o['o7'].to_list() + q['q7'].to_list() + p['p7'].to_list()\n",
    "bid['n10'] = n['n10'].to_list() + o['o10'].to_list() + [np.nan]*len(q) + [np.nan]*len(p)\n",
    "bid['n12'] = [np.nan]*len(n) + [np.nan]*len(o) + [np.nan]*len(q) + p['p8'].to_list()\n",
    "bid['n13'] = [np.nan]*len(n) + [np.nan]*len(o) + [np.nan]*len(q) + p['p11'].to_list()\n",
    "\n",
    "bid['n7'] = bid['n7'].map(lambda x: str(x).replace(',', '') if x is not np.nan else np.nan).astype(float)\n",
    "bid['n10'] = bid['n10'].map(lambda x: str(x).replace(',', '') if x is not np.nan else np.nan).astype(float)\n",
    "bid.head()\n",
    "prod_agg_dict={\n",
    "    'n6':[np.min,np.max,np.mean],\n",
    "    'n7':[np.min,np.max,np.mean],\n",
    "    'n10':[np.min,np.max,np.mean],\n",
    "    #'n12':[np.min,np.max,np.mean],\n",
    "    #'n13':[np.min,np.max,np.mean],\n",
    "}\n",
    "prod_agg = bid.groupby(['a2']).agg(prod_agg_dict)\n",
    "prod_agg.columns = ['_'.join(i) + '_ina2' for i in prod_agg.columns]\n",
    "prod_agg = prod_agg.reset_index()\n",
    "df = df.merge(prod_agg,how='left',on=['a2'])\n",
    "prod_cols = ['n6','n7','n10']#,'n12','n13']\n",
    "agg_cols = ['amin','amax','mean']\n",
    "drop_agg = []\n",
    "for i in prod_cols:\n",
    "    for j in agg_cols:\n",
    "        agg_col = i+'_'+j+'_ina2'\n",
    "        drop_agg.append(agg_col)\n",
    "        df[i+'_'+j+'_a2_diff'] = df[i+'_mean'] - df[agg_col]\n",
    "\n",
    "df.drop(columns = drop_agg,inplace=True)\n",
    "del n,o,p,q,new_n,new_o,new_p,new_q, bid,prod_agg\n",
    "gc.collect()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### more analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''all_buy = df[['core_cust_id','prod_code','a3','y']]\n",
    "all_buy = all_buy.sort_values('a3',ascending=True)\n",
    "buy_again = all_buy[all_buy.duplicated(['core_cust_id','prod_code'],keep=False)]\n",
    "prod_cust = buy_again.groupby(['core_cust_id','prod_code']).agg(sdas = ('y','sum')).reset_index()\n",
    "last_buys = []\n",
    "last_record_deltas = []\n",
    "last_cust = None\n",
    "last_prod = None\n",
    "buy_again = buy_again.sort_values(['core_cust_id','prod_code','a3'],ascending=True)\n",
    "for index,row in tqdm(buy_again.iterrows()):\n",
    "    cust = row['core_cust_id']\n",
    "    prod = row['prod_code']\n",
    "    a3 = row['a3']\n",
    "    if cust == last_cust and prod==last_prod:\n",
    "        last_buys.append(last_y)\n",
    "        last_record_deltas.append(a3-last_a3)\n",
    "    else:\n",
    "        last_buys.append(np.NaN)\n",
    "        last_record_deltas.append(np.NaN)\n",
    "    last_cust = cust\n",
    "    last_prod = prod\n",
    "    last_a3 = a3\n",
    "    last_y = row['y']\n",
    "buy_again['last_buy'] = last_buys\n",
    "buy_again['last_record_delta'] = last_record_deltas\n",
    "tmp = buy_again[buy_again['last_buy'].notna()]\n",
    "tmp.drop(columns='y',inplace=True)\n",
    "df = df.merge(tmp,on=['core_cust_id','prod_code','a3'],how='left')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''s = pd.read_csv(root + 's.csv')\n",
    "new_s = pd.read_csv(new + 's_bc.csv')\n",
    "s = pd.concat([s,new_s])\n",
    "s['date'] = s['s5'].map(lambda x: str(x).replace('-', '')).astype(int)\n",
    "s['s4'] = s['s4'].apply(lambda x: str(x).replace(',','')).astype('float')  \n",
    "\n",
    "window = 7\n",
    "skip = 0 #跳过月提取特征\n",
    "months = [20210701, 20210801, 20210901, 20211001,20211201]\n",
    "\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "for date in months:\n",
    "    start = date - skip * 100 - window * 100\n",
    "    ss = s.loc[(s['date']>=start) & (s['date']<date)]\n",
    "    tmp = ss.groupby('s3').size().reset_index()\n",
    "    tmp.columns = ['core_cust_id','borrow_cnt']\n",
    "    \n",
    "    tmp['borrow_amt_sum_grp_uid'] = ss.groupby('s3')['s4'].agg('sum').values\n",
    "    tmp['a3'] = date\n",
    "    tmp = tmp[['core_cust_id','borrow_amt_sum_grp_uid','a3']]\n",
    "    feature1.append(tmp)\n",
    "    \n",
    "    tmp = ss.groupby('s6').size().reset_index()\n",
    "    tmp.columns = ['core_cust_id','loan_cnt']\n",
    "    tmp['loan_amt_sum_grp_uid'] = ss.groupby('s6')['s4'].agg('sum').values\n",
    "    \n",
    "    tmp['a3'] = date\n",
    "    tmp = tmp[['core_cust_id','loan_amt_sum_grp_uid','a3']]\n",
    "    feature2.append(tmp)\n",
    "feature1 = pd.concat(feature1)\n",
    "feature2 = pd.concat(feature2)\n",
    "feature1['borrow_amt_sum_grp_uid'] = feature1['borrow_amt_sum_grp_uid'].fillna(0)\n",
    "feature2['loan_amt_sum_grp_uid'] = feature2['loan_amt_sum_grp_uid'].fillna(0)\n",
    "feature1 = feature1.sort_values(['core_cust_id','a3'],ascending=True)\n",
    "feature2 = feature2.sort_values(['core_cust_id','a3'],ascending=True)\n",
    "feature1['borrow_sum_diff'] = feature1.groupby('core_cust_id')['borrow_amt_sum_grp_uid'].apply(lambda x:x.diff())\n",
    "feature2['loan_sum_diff'] = feature2.groupby('core_cust_id')['loan_amt_sum_grp_uid'].apply(lambda x:x.diff())\n",
    "df = df.merge(feature1, how='left', on=['core_cust_id', 'a3'])\n",
    "del feature1,tmp ,s,new_s\n",
    "gc.collect()\n",
    "df = df.merge(feature2, how='left', on=['core_cust_id', 'a3'])\n",
    "del feature2\n",
    "gc.collect()\n",
    "df['borrow_load_diff'] = df['borrow_amt_sum_grp_uid'] - df['loan_amt_sum_grp_uid'] \n",
    "df['borrow_load_ratio'] =df['borrow_amt_sum_grp_uid'] /( df['loan_amt_sum_grp_uid'] +1)\n",
    "df['borrow_amt_sum_grp_uid'] = df['borrow_amt_sum_grp_uid'].fillna(0)\n",
    "df['loan_amt_sum_grp_uid'] = df['loan_amt_sum_grp_uid'].fillna(0)\n",
    "\n",
    "\n",
    "f = pd.read_csv(root + 'f.csv')\n",
    "new_f = pd.read_csv(new+'f_bc.csv')\n",
    "f = pd.concat([f,new_f])\n",
    "f.fillna(0, inplace=True)\n",
    "f['create_date'] = f['f1'].map(lambda x: int(str(x).replace('-', '')))\n",
    "f_cols = ['f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9','f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19','f20', 'f21']\n",
    "for c in f_cols:\n",
    "    f[c] = f[c].apply(lambda x: str(x).replace(',','')).astype('float')\n",
    "f_dict = {col: (col, 'mean') for col in f_cols}\n",
    "f_stat = f.groupby(['core_cust_id','f22']).agg(**f_dict).reset_index()\n",
    "f_stat['f22'] = f_stat['f22'].map(lambda x: x-29+100)\n",
    "new_stat = f_stat[['core_cust_id','f22']]\n",
    "new_stat['season_assets'] = f_stat['f2'] +f_stat['f3'] +f_stat['f4']+f_stat['f5']+f_stat['f6']\n",
    "new_stat['month_assets'] = f_stat['f12'] +f_stat['f13']+f_stat['f14']+f_stat['f15']+f_stat['f16']\n",
    "new_stat['year_assets'] = f_stat['f17']+f_stat['f18']+f_stat['f19']+f_stat['f20']+f_stat['f21']\n",
    "new_stat['all_assets'] = new_stat['season_assets']+new_stat['month_assets']+new_stat['year_assets']\n",
    "new_stat['hour_assets'] = f_stat['f7']+f_stat['f8']+f_stat['f9']+f_stat['f10']+f_stat['f11']\n",
    "new_stat['season_assets_diff'] = new_stat.groupby('core_cust_id')['season_assets'].apply(lambda x:x.diff())\n",
    "new_stat['month_assets_diff'] = new_stat.groupby('core_cust_id')['month_assets'].apply(lambda x:x.diff())\n",
    "new_stat['year_assets_diff'] = new_stat.groupby('core_cust_id')['year_assets'].apply(lambda x:x.diff())\n",
    "new_stat['all_assets_diff'] = new_stat.groupby('core_cust_id')['all_assets'].apply(lambda x:x.diff())\n",
    "new_stat['hour_assets_diff'] = new_stat.groupby('core_cust_id')['hour_assets'].apply(lambda x:x.diff())\n",
    "df = df.merge(new_stat,left_on=['core_cust_id','a3'],right_on=['core_cust_id','f22'], how='left')\n",
    "df['all_assets_include_hour_loan'] = df['all_assets']  + df['hour_assets']\n",
    "df['all_assets_include_hour_loan_div_loan'] = df['all_assets_include_hour_loan'] /( df['loan_amt_sum_grp_uid'] +1)\n",
    "df['loan_cnt'] = df['loan_cnt'].fillna(0)\n",
    "df['borrow_cnt'] =df['borrow_cnt'].fillna(0)\n",
    "df['n1_cnt_in_uid'] = df['n1_cnt_in_uid'].fillna(0)\n",
    "df['borrow&loan_count'] = df['loan_cnt'] + df['borrow_cnt'] \n",
    "df['all_trade_count'] = df['borrow&loan_count'] + df['n1_cnt_in_uid']\n",
    "df['cash_ratio'] = df['hour_assets'] / (df['loan_amt_sum_grp_uid']+1)\n",
    "\n",
    "def fenxiang(a,bins):\n",
    "    for i in range(len(bins)):\n",
    "        if i==len(bins)-1:\n",
    "            return i\n",
    "        elif a>=bins[i] and a<bins[i+1]:\n",
    "            return i\n",
    "df['e1_mean_bin'] = df['e1_mean'].apply(lambda x:fenxiang(x,[1,2,3,4]))\n",
    "df['eval_first_delta_bin'] = df['eval_first_delta'].apply(lambda x:fenxiang(x,[0,10000,20000\n",
    "                                                                           ,30000,40000]))\n",
    "df['creat_date_bin'] = df['create_date'].apply(lambda x:fenxiang(x,[0,5000,15000,25000]))\n",
    "df['hold_days_bin'] = df['hold_days'].apply(lambda x:fenxiang(x,[0,1,50,220,310]))\n",
    "df['max_profit_rate_bin'] = df['max_profit_rate'].apply(lambda x:fenxiang(x,[0,0.005,0.027,0.05]))\n",
    "df['min_profit_rate_bin'] = df['min_profit_rate'].apply(lambda x:fenxiang(x,[0,0.005,0.014,0.018,0.037]))\n",
    "df['n8_last_bin'] = df['n8_last_x'].apply(lambda x:fenxiang(x,[0,1.5,2.5,5.5,6.5]))\n",
    "df['exp_level_mean_bin'] = df['exp_level_mean'].apply(lambda x:fenxiang(x,[0,1.01,1.9,2.03]))\n",
    "df['k10_mean_bin'] = df['k10_mean'].apply(lambda x:fenxiang(x,[0,1.1,1.8,2.1,4.8]))\n",
    "df['profit_rate_mean_bin'] = df['profit_rate_mean'].apply(lambda x:fenxiang(x,[0,0.1,3,3.3]))\n",
    "df['max_profit_rate_mean_bin'] = df['max_profit_rate_mean'].apply(lambda x:fenxiang(x,[0,0.003,0.04,0.46]))\n",
    "df['min_profit_rate_mean_bin'] = df['min_profit_rate_mean'].apply(lambda x:fenxiang(x,[0,0.003,0.01,0.016]))\n",
    "df['n8_nunique_a2_bin'] = df['n8_nunique_a2'].apply(lambda x:fenxiang(x,[0,0.5,3.5,5.5]))\n",
    "df['hold_days_mean_a2_bin'] = df['hold_days_mean_a2'].apply(lambda x:fenxiang(x,[0,1,30]))\n",
    "df['hold_days_mean_click_bin'] = df['hold_days_mean_click'].apply(lambda x:fenxiang(x,[0,1,350]))\n",
    "\n",
    "pianchas = []\n",
    "profit_cha = []\n",
    "hold_cha = []\n",
    "for i in df.columns:\n",
    "    if 'piancha' in i:\n",
    "        pianchas.append(i)\n",
    "        if 'profit_rate' in i:\n",
    "            profit_cha.append(i)\n",
    "        elif 'hold_days' in i:\n",
    "            hold_cha.append(i)\n",
    "for i in pianchas:\n",
    "    df[i] = minmax_scale(df[i])\n",
    "for i,j in zip([pianchas,profit_cha,hold_cha],['','profit_rate_','hold_days_']):\n",
    "    piancha = df[i].values\n",
    "    piancha = np.nan_to_num(piancha,nan=1)\n",
    "    piancha = piancha.shape[1]-piancha.sum(axis=1)\n",
    "    df[j+'piancha_all_energy'] = piancha\n",
    "drop_piancha = ['piancha_145_hold_days_mean_click_a2','piancha_m256_hold_days_amax_a2_diff','piancha_3_n8_nunique','piancha_4_n_nunique_in_uid','piancha_3.5_n_nunique_in_uid_a2',\n",
    "                'piancha_0.42_d2_cnts_yes','piancha_134_hold_days_mean','piancha_115_hold_days_mean_a2','piancha_2.5_d2', 'piancha_60_d3',\n",
    "'piancha_2018_e2_first', 'piancha_145_hold_days_mean_click', 'piancha_30000_eval_first_delta', 'piancha_3_e1_cnt']\n",
    "df.drop(columns = drop_piancha,inplace=True)\n",
    "tmps = []\n",
    "tmp_all = df[['core_cust_id','a3','y']]\n",
    "for i in [20210801,20210901,20211001,20211201]:\n",
    "    tmp = tmp_all.loc[tmp_all['a3'] <i ]\n",
    "    tmp = tmp.groupby('core_cust_id').agg(pre_buy_all=('y','sum')).reset_index()\n",
    "    tmp['a3'] = i\n",
    "    tmps.append(tmp)\n",
    "tmps = pd.concat(tmps)\n",
    "df = df.merge(tmps,on=['core_cust_id','a3'],how='left')'''\n",
    "\n",
    "df['piancha_m256_hold_days_amax_a2_diff'] = abs(df['hold_days_amax_a2_diff']+256)\n",
    "df['piancha_145_hold_days_mean_click'] = abs(df['hold_days_mean_click']-145)\n",
    "df['piancha_m0.9_profit_rate_mean_a2_diff'] = abs(df['profit_rate_mean_a2_diff']+0.986191)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_csv('new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''def encode_cust_prod(train_df,test_df):\n",
    "    ''' use buy rate to encode cust_id and prod_code'''\n",
    "    label = 'y'\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "    enc_list = ['core_cust_id','prod_code']\n",
    "    for f in tqdm(enc_list):\n",
    "        train_df[f + '_target_enc'] = 0\n",
    "        test_df[f + '_target_enc'] = 0\n",
    "        for i, (trn_idx, val_idx) in enumerate(skf.split(train_df, train_df[label])):\n",
    "            trn_x = train_df[[f, label]].iloc[trn_idx].reset_index(drop=True)\n",
    "            val_x = train_df[[f]].iloc[val_idx].reset_index(drop=True)\n",
    "            enc_df = trn_x.groupby(f, as_index=False)[label].agg({f + '_target_enc': 'mean'})\n",
    "            val_x = val_x.merge(enc_df, on=f, how='left')\n",
    "            test_x = test_df[[f]].merge(enc_df, on=f, how='left')\n",
    "            val_x[f + '_target_enc'] = val_x[f + '_target_enc'].fillna(train_df[label].mean())\n",
    "            test_x[f + '_target_enc'] = test_x[f + '_target_enc'].fillna(train_df[label].mean())\n",
    "            train_df.loc[val_idx, f + '_target_enc'] = val_x[f + '_target_enc'].values\n",
    "            test_df[f + '_target_enc'] += test_x[f + '_target_enc'].values / skf.n_splits\n",
    "    return train_df,test_df\n",
    "\n",
    "\n",
    "train_df = df[df['a3']<20211001]\n",
    "test_df = df[df['a3']==20211001]\n",
    "train_df,test_df = encode_cust_prod(train_df,test_df)\n",
    "df = pd.concat([train_df,test_df])\n",
    "del train_df,test_df\n",
    "gc.collect()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d1', 'd2', 'd3', 'e1_mean', 'e1_cnt', 'e1_last', 'e2_last', 'e2_first', 'eval_delta', 'eval_first_delta', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'create_date', 'k5', 'k10', 'exp_level', 'is_guncun', 'hold_days', 'j6', 'profit_rate', 'max_profit_rate', 'min_profit_rate', 'prod_code_nunique_in_uid', 'n1_cnt_in_uid', 'n_nunique_in_uid', 'n3_nunique_in_uid', 'n6_mean', 'n7_mean', 'n8_nunique', 'n9_nunique', 'n10_mean', 'u_buy_days', 'n8_last_x', 'n9_last_x', 'exp_level_mean', 'hold_days_mean', 'k10_mean', 'profit_rate_mean', 'max_profit_rate_mean', 'min_profit_rate_mean', 'u_first_buy_delta', 'u_last_buy_delta', 'u_first_last_buy_delta', 'user_max_buy_date', 'prod_code_nunique_in_uid_a2', 'n1_cnt_in_uid_a2', 'n_nunique_in_uid_a2', 'n3_nunique_in_uid_a2', 'n6_mean_a2', 'n7_mean_a2', 'n8_nunique_a2', 'n9_nunique_a2', 'n10_mean_a2', 'u_buy_days_a2', 'n8_last_y', 'n9_last_y', 'exp_level_mean_a2', 'hold_days_mean_a2', 'k10_mean_a2', 'profit_rate_mean_a2', 'max_profit_rate_mean_a2', 'min_profit_rate_mean_a2', 'u_first_buy_delta_a2', 'u_last_buy_delta_a2', 'u_first_last_buy_delta_a2', 'user_max_buy_date_a2', 'uid_cnt_in_r3_equal_1', 'uid_cnt_in_r3_equal_2', 'prod_code_nunique_grp_uid_in_app_action', 'r5_nunique_grp_uid_in_app_action', 'user_click_days', 'exp_level_mean_click', 'hold_days_mean_click', 'k10_mean_click', 'profit_rate_mean_click', 'max_profit_rate_mean_click', 'min_profit_rate_mean_click', 'first_click_delta', 'last_click_delta', 'first_last_delta', 'user_max_click_prod', 'user_max_click_prod_cnt', 'prod_code_nunique_grp_uid_in_app_action_a2', 'r5_nunique_grp_uid_in_app_action_a2', 'user_click_days_a2', 'exp_level_mean_click_a2', 'hold_days_mean_click_a2', 'k10_mean_click_a2', 'profit_rate_mean_click_a2', 'max_profit_rate_mean_click_a2', 'min_profit_rate_mean_click_a2', 'first_click_deltaa2', 'last_click_deltaa2', 'first_last_deltaa2', 'user_max_click_prod_a2', 'user_max_click_prod_cnt_a2', 'borrow_cnt', 'borrow_amt_mean_grp_uid', 'borrow_amt_max_grp_uid', 'borrow_amt_last_grp_uid', 'first_borrow_delta', 'last_borrow_delta', 'first_last_borrow_delta', 'user_max_borrow_v', 'user_max_borrow_date', 'loan_cnt', 'loan_amt_mean_grp_uid', 'loan_amt_max_grp_uid', 'loan_amt_last_grp_uid', 'first_loan_delta', 'last_loan_delta', 'first_last_loan_delta', 'user_max_loan_v', 'user_max_loan_date', 'e1_last_cnts_yes', 'd2_cnts_yes', 'age_level_cnts_yes', 'exp_level_amin_a2_diff', 'exp_level_amax_a2_diff', 'exp_level_mean_a2_diff', 'hold_days_amin_a2_diff', 'hold_days_amax_a2_diff', 'hold_days_mean_a2_diff', 'profit_rate_amin_a2_diff', 'profit_rate_amax_a2_diff', 'profit_rate_mean_a2_diff', 'max_profit_rate_amin_a2_diff', 'max_profit_rate_amax_a2_diff', 'max_profit_rate_mean_a2_diff', 'min_profit_rate_amin_a2_diff', 'min_profit_rate_amax_a2_diff', 'min_profit_rate_mean_a2_diff', 'piancha_m256_hold_days_amax_a2_diff', 'piancha_145_hold_days_mean_click', 'piancha_m0.9_profit_rate_mean_a2_diff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_fea = ['a2','id','a3','y','core_cust_id','prod_code','f22', 's3', 's6', 'total', 'k1', 'k2', 'k3', 'k4', 'k6', 'bid_type', 'recur_type', 'prod_type', 'prod_type2']\n",
    "feature= [x for x in df.columns if x not in drop_fea]\n",
    "print(feature)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tst before:  587085 test end:  587085\n",
      "feature numbers:  153 x/y:  2953495 2953495 y_mean:  0.010249890384104256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(df, feature)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader.feature_columns.remove('a2')\n",
    "pool = ['piancha_m0.9_profit_rate_mean_a2_diff','piancha_145_hold_days_mean_click']#'profit_rate*hold_days']\n",
    "pool_xgb = ['piancha_m256_hold_days_amax_a2_diff']#'profit_rate*hold_days']\n",
    "feature = feature[:150]\n",
    "dataloader.feature_columns = feature + pool\n",
    "dataloader.setSample(0)\n",
    "X_train, X_valid, y_train, y_valid = dataloader.get_train_val_data_by_time()\n",
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LGB, CAT and XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed0 = 42\n",
    "from lightgbm import LGBMClassifier\n",
    "params1 = {'n_estimators': 500, \n",
    "           'learning_rate': 0.04223859360499718, \n",
    "           'num_leaves': 96, \n",
    "           'max_depth': 6,\n",
    "           'metric':'auc',\n",
    "           'min_data_in_leaf': 1300,\n",
    "           'lambda_l1': 0,\n",
    "           'lambda_l2': 7, \n",
    "           'min_gain_to_split': 0.28816893721038017,\n",
    "           'bagging_fraction': 0.5,\n",
    "           'bagging_freq': 1,\n",
    "           'feature_fraction': 0.8,\n",
    "            'random_state':356}\n",
    "\n",
    "params2 = {'num_leaves':128,\n",
    "                     'n_estimators':450,\n",
    "                     'learning_rate':0.01,\n",
    "                     'verbose':-1,\n",
    "                     'metric':'auc',\n",
    "                     'feature_fraction':0.8, \n",
    "                     'bagging_fraction':0.8,\n",
    "                     'lambda_l1':0.1,\n",
    "                     'lambda_l2':0.1,\n",
    "                     'min_child_weight':30,\n",
    "                     'random_state':seed0,\n",
    "                     'n_jobs':20}\n",
    "clf = LGBMClassifier(device='gpu',**params1)\n",
    "clf.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],eval_metric=[lgb_f2_score], verbose=20,early_stopping_rounds=100)\n",
    "oof_prob = clf.predict_proba(X_valid)[:, 1]\n",
    "oof_prob = clf.predict_proba(X_valid)[:, 1]\n",
    "best_th, best_f2, rate = find_best_threshold(y_valid, oof_prob)\n",
    "print(best_f2, best_th, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lightgbm\n",
      "Version: 3.2.1\n",
      "Summary: LightGBM Python Package\n",
      "Home-page: https://github.com/microsoft/LightGBM\n",
      "Author: None\n",
      "Author-email: None\n",
      "License: The MIT License (Microsoft)\n",
      "Location: c:\\users\\99298\\anaconda3\\envs\\ai\\lib\\site-packages\n",
      "Requires: scikit-learn, numpy, scipy, wheel\n",
      "Required-by: pycaret\n"
     ]
    }
   ],
   "source": [
    "!pip show lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. class weight \n",
    "2. find hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from catboost import CatBoostClassifier\n",
    "class F2Metric:\n",
    "    @staticmethod\n",
    "    def get_profit(y_true, y_hat):\n",
    "        y_hat = [1 if i >=0.072 else 0 for i in y_hat ]\n",
    "        precision = precision_score(y_true,y_hat,zero_division=1)\n",
    "        recall = recall_score(y_true,y_hat)\n",
    "        f2 = 5*recall*precision/(4*precision+recall)\n",
    "        return f2\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        return True # greater is better\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):            \n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        y_true = np.array(target).astype(int)\n",
    "        approx = approxes[0]\n",
    "        score = self.get_profit(y_true, approx)\n",
    "        return score, 1\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "    \n",
    "params_cat = {'iterations':3000,\n",
    "                     'learning_rate':0.1,\n",
    "                     'eval_metric':'AUC',\n",
    "                     'l2_leaf_reg':0.1,\n",
    "                     'task_type':\"GPU\",\n",
    "                     'random_seed':43}\n",
    "params_cat2 = {\"learning_rate\":0.1,\n",
    "            'task_type':\"GPU\",\n",
    "              'random_seed':43,\n",
    "            'iterations':3000,\n",
    "        'eval_metric':'AUC',\n",
    "        'l2_leaf_reg': 13,\n",
    "        'scale_pos_weight': 0.9406780584846045,\n",
    "        'depth': 4,\n",
    "        'bootstrap_type':'Bernoulli',\n",
    "        'subsample':0.22922161698463137}\n",
    "cat_clf = CatBoostClassifier(**params_cat2)\n",
    "cat_clf.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=300,early_stopping_rounds=100)\n",
    "result = cat_clf.predict_proba(X_valid)[:,1]\n",
    "print(lgb_f2_score(y_valid,result))\n",
    "best_th, best_f2, rate = find_best_threshold(y_valid, result)\n",
    "print(best_f2, best_th, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (samples this class)/all_samples_num\n",
    "1:   600  : 0: 400\n",
    "1:   1 - 600/1000 = 0.4\n",
    "0    1-  400/1000 = 0.6\n",
    "\n",
    "crossentropyloss([weight=[0.6,0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.2,0.2,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "params_xgb = {'n_estimators':1000,\n",
    "                     'learning_rate':0.1,\n",
    "                     'verbose':-1,\n",
    "                     'metrics':['auc'],\n",
    "                     'reg_alpha':0.1,\n",
    "                     'reg_lambda':0.1,\n",
    "                     'min_child_weight':30,\n",
    "                     'n_jobs':20}\n",
    "params_xgb2 = {'n_estimators':450,\n",
    "                     'learning_rate':0.1,\n",
    "              'seed':42,\n",
    "               'max_depth':5,\n",
    "               'reg_alpha':16,\n",
    "               'reg_lambda':0.8516218313773746,\n",
    "               'colsample_bytree':0.7962234301287214,\n",
    "               'gamma':5.524732779962722,\n",
    "               'metrics':['auc'],\n",
    "               'min_child_weight':6,\n",
    "              }\n",
    "xgb_clf = XGBClassifier(tree_method='gpu_hist', gpu_id=0,**params_xgb2)\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric='auc',\n",
    "        verbose=100,early_stopping_rounds=100)\n",
    "result = xgb_clf.predict_proba(X_valid)[:,1]\n",
    "print(lgb_f2_score(y_valid,result))\n",
    "best_th, best_f2, rate = find_best_threshold(y_valid, result)\n",
    "print(best_f2, best_th, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## rank pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''from __future__ import print_function\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "MIN_NUM_PER_CLASS = 10\n",
    "def assert_inputs_are_valid(X, s, prob_s_eq_1 = None):\n",
    "  '''Checks that X, s, and prob_s_eq_1\n",
    "  are correctly formatted'''\n",
    "  \n",
    "  if prob_s_eq_1 is not None:\n",
    "    if not isinstance(prob_s_eq_1, (np.ndarray, np.generic)):\n",
    "      raise TypeError(\"prob_s_eq_1 should be a numpy array.\")\n",
    "    if len(prob_s_eq_1) != len(s):\n",
    "      raise ValueError(\"prob_s_eq_1 and s must have same length.\")\n",
    "    # Check for valid probablities.\n",
    "    for i in prob_s_eq_1:\n",
    "      if i < 0 or i > 1:\n",
    "        raise ValueError(\"Values in prob_s_eq_1 must be between 0 and 1.\")\n",
    "\n",
    "  if not isinstance(s, (np.ndarray, np.generic)):\n",
    "    raise TypeError(\"s should be a numpy array.\")\n",
    "  if not isinstance(X, (np.ndarray, np.generic)):\n",
    "    raise TypeError(\"X should be a numpy array.\")\n",
    "  for i in s:\n",
    "    if i < 0 or i > 1 or (i > 0 and i < 1):\n",
    "      raise ValueError(\"s should only contain 0 or 1 values.\")\n",
    "          \n",
    "\n",
    "def compute_conf_counts_noise_rates_from_probabilities(\n",
    "  s, \n",
    "  prob_s_eq_1, \n",
    "  positive_lb_threshold = None,\n",
    "  negative_ub_threshold = None,\n",
    "  verbose = False,\n",
    "):\n",
    "\n",
    "  # Estimate the probability thresholds for confident counting \n",
    "  if positive_lb_threshold is None:\n",
    "    positive_lb_threshold = np.mean(prob_s_eq_1[s == 1]) # P(s^=1|s=1)\n",
    "  \n",
    "  if negative_ub_threshold is None:\n",
    "    negative_ub_threshold = np.mean(prob_s_eq_1[s == 0]) # P(s^=1|s=0)\n",
    "    \n",
    "  # Estimate the number of confident examples having s = 0 and y = 1\n",
    "  N_most_positive_size = sum((prob_s_eq_1 >= positive_lb_threshold) & (s == 0)) \n",
    "\n",
    "  # Estimate the number of confident examples having s = 1 and y = 1\n",
    "  P_most_positive_size = sum((prob_s_eq_1 >= positive_lb_threshold) & (s == 1))\n",
    "\n",
    "  # Estimate the number of confident examples having s = 0 and y = 0\n",
    "  N_least_positive_size = sum((prob_s_eq_1 <= negative_ub_threshold) & (s == 0))\n",
    "\n",
    "  # Estimate the number of confident examples having s = 1 and y = 0\n",
    "  P_least_positive_size = sum((prob_s_eq_1 <= negative_ub_threshold) & (s == 1))\n",
    "  \n",
    "  if verbose:\n",
    "    print(\"N_most_positive_size\", N_most_positive_size)\n",
    "    print(\"P_most_positive_size\", P_most_positive_size)\n",
    "    print(\"N_least_positive_size\", N_least_positive_size)\n",
    "    print(\"P_least_positive_size\", P_least_positive_size)\n",
    "  \n",
    "  # Confident Counts Estimator for p(s=0|y=1) ~ |s=0 and y=1| / |y=1|\n",
    "  # Allow np.NaN when float(N_most_positive_size + P_most_positive_size) == 0\n",
    "  rh1_conf = N_most_positive_size / float(N_most_positive_size + P_most_positive_size)\n",
    "\n",
    "  # Confident Counts Estimator for p(s=1|y=0) ~ |s=1 and y=0| / |y=0|\n",
    "  # Allow np.NaN when float(N_least_positive_size + P_least_positive_size) == 0\n",
    "  rh0_conf = P_least_positive_size / float(N_least_positive_size + P_least_positive_size)\n",
    "  \n",
    "  # Ensure that rh1, rh0 are in proper range [0,1)\n",
    "  rh0_conf = min(max(rh0_conf, 0.0), 0.9999)\n",
    "  rh1_conf = min(max(rh1_conf, 0.0), 0.9999)\n",
    "\n",
    "  if verbose:\n",
    "    print(\"Est count of s = 1 and y = 1:\", P_most_positive_size)\n",
    "    print(\"Est count of s = 0 and y = 1:\", N_most_positive_size)\n",
    "    print(\"Est count of s = 1 and y = 0:\", P_least_positive_size)\n",
    "    print(\"Est count of s = 0 and y = 0:\", N_least_positive_size)\n",
    "    print(\"rh1_conf:\", rh1_conf)\n",
    "    print(\"rh0_conf:\", rh0_conf)\n",
    "\n",
    "  return rh1_conf, rh0_conf\n",
    "\n",
    "\n",
    "def compute_noise_rates_and_cv_pred_proba(\n",
    "  X, \n",
    "  s, \n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "  clf = logreg(),\n",
    "  cv_n_folds = 3,\n",
    "  positive_lb_threshold = None,\n",
    "  negative_ub_threshold = None,\n",
    "  verbose = False,\n",
    "):\n",
    "  \n",
    "  # Number of classes\n",
    "  K = len(np.unique(s))\n",
    "  # Number of training examples\n",
    "  N = len(s)\n",
    "\n",
    "  # Create cross-validation object for out-of-sample predicted probabilities.\n",
    "  # CV folds preserve the fraction of noisy positive and\n",
    "  # noisy negative examples in each class.\n",
    "  kf = StratifiedKFold(n_splits = cv_n_folds, shuffle = True)\n",
    "\n",
    "  # Intialize result storage and final prob_s array\n",
    "  rh1_per_cv_fold = []\n",
    "  rh0_per_cv_fold = []\n",
    "  prob_s = np.zeros((N, K))\n",
    "\n",
    "  # Split X and s into \"cv_n_folds\" stratified folds.\n",
    "  for k, (cv_train_idx, cv_holdout_idx) in enumerate(kf.split(X, s)):\n",
    "\n",
    "    # Select the training and holdout cross-validated sets.\n",
    "    X_train_cv, X_holdout_cv = X[cv_train_idx], X[cv_holdout_idx]\n",
    "    s_train_cv, s_holdout_cv = s[cv_train_idx], s[cv_holdout_idx]\n",
    "\n",
    "    # Fit the clf classifier to the training set and \n",
    "    # predict on the holdout set and update prob_s. \n",
    "    clf = LGBMClassifier(num_leaves=128,\n",
    "                     n_estimators=500,\n",
    "                     learning_rate=0.01,\n",
    "                     verbose=-1,\n",
    "                     metric='auc',\n",
    "                     feature_fraction=0.8, \n",
    "                     bagging_fraction=0.8,\n",
    "                     lambda_l1=0.1,\n",
    "                     lambda_l2=0.1, \n",
    "                     min_child_weight=30,\n",
    "                     n_jobs=20)\n",
    "    if X_test is None:\n",
    "        clf.fit(X_train_cv, s_train_cv,eval_set=(X_holdout_cv,s_holdout_cv),early_stopping_rounds=50,eval_metric='auc',verbose=100)\n",
    "    else:\n",
    "        clf.fit(X_train_cv, s_train_cv,eval_set=(X_test,y_test),early_stopping_rounds=50,eval_metric='auc',verbose=100)\n",
    "    prob_s_cv = clf.predict_proba(X_holdout_cv) # P(s = k|x) # [:,1]\n",
    "    prob_s[cv_holdout_idx] = prob_s_cv\n",
    "\n",
    "    # Compute and append the confident counts noise estimators\n",
    "    # to estimate the positive and negative mislabeling rates.\n",
    "    rh1_cv, rh0_cv = compute_conf_counts_noise_rates_from_probabilities(\n",
    "      s = s_holdout_cv, \n",
    "      prob_s_eq_1 = prob_s_cv[:,1], # P(s = 1|x) \n",
    "      positive_lb_threshold = positive_lb_threshold,\n",
    "      negative_ub_threshold = negative_ub_threshold,\n",
    "      verbose = verbose,\n",
    "    )\n",
    "    rh1_per_cv_fold.append(rh1_cv)\n",
    "    rh0_per_cv_fold.append(rh0_cv)\n",
    "\n",
    "  # Return mean rh, omitting nan or inf values, and prob_s\n",
    "  return (\n",
    "    _mean_without_nan_inf(rh1_per_cv_fold), \n",
    "    _mean_without_nan_inf(rh0_per_cv_fold), \n",
    "    prob_s,\n",
    "  )\n",
    "\n",
    "\n",
    "def compute_cv_predicted_probabilities(\n",
    "  X, \n",
    "  y, # labels, can be noisy (s) or not noisy (y).\n",
    "  clf = logreg(),\n",
    "  cv_n_folds = 3,\n",
    "  verbose = False,\n",
    "):\n",
    "\n",
    "  return compute_noise_rates_and_cv_pred_proba(\n",
    "    X = X, \n",
    "    s = y, \n",
    "    clf = clf,\n",
    "    cv_n_folds = cv_n_folds,\n",
    "    verbose = verbose,\n",
    "  )[-1]\n",
    "\n",
    "\n",
    "def compute_conf_counts_noise_rates(\n",
    "  X, \n",
    "  s, \n",
    "  clf = logreg(),\n",
    "  cv_n_folds = 3,\n",
    "  positive_lb_threshold = None,\n",
    "  negative_ub_threshold = None,\n",
    "  verbose = False,\n",
    "):\n",
    "  return compute_noise_rates_and_cv_pred_proba(\n",
    "    X = X, \n",
    "    s = s, \n",
    "    clf = clf,\n",
    "    cv_n_folds = cv_n_folds,\n",
    "    positive_lb_threshold = positive_lb_threshold,\n",
    "    negative_ub_threshold = negative_ub_threshold,\n",
    "    verbose = verbose,\n",
    "  )[:-1]\n",
    "\n",
    "\n",
    "def compute_ps1_py1_pi1_pi0(s, rh1, rh0):\n",
    "  # Compute ps1 := P(s=1), py1 := P(y=1), and inverse noise rates pi1, pi0\n",
    "  ps1 = sum(s) / float(len(s))\n",
    "  py1 = (ps1 - rh0) / float(1 - rh1 - rh0)\n",
    "  pi1 = rh0 * (1 - py1) / float(ps1)\n",
    "  pi0 = (rh1 * py1) / float(1 - ps1)\n",
    "    \n",
    "#     # Equivalently, we can compute pi1, pi0, and py1 this way as well, but there is no need:\n",
    "#     pi1 = rh0 * (1 - ps1 - rh1) / float(ps1) / float(1 - rh1 - rh0)\n",
    "#     pi0 = rh1 * (ps1 - rh0) / float(1 - ps1) / float(1 - rh1 - rh0)\n",
    "#     py1 = ps1 * (1 - pi1) + pi0 * (1 - ps1)\n",
    "    \n",
    "  # Ensure that pi1, and pi0 are in proper range [0,1)\n",
    "  pi1 = min(max(pi1, 0.0), 0.9999)\n",
    "  pi0 = min(max(pi0, 0.0), 0.9999)\n",
    "  \n",
    "  return ps1, py1, pi1, pi0\n",
    "    \n",
    "\n",
    "def get_noise_indices(\n",
    "  s, \n",
    "  prob_s_eq_1, \n",
    "  frac_of_noise = 1.0,\n",
    "  pi1 = None,\n",
    "  pi0 = None,\n",
    "  num_to_remove_per_class = None,\n",
    "  verbose = False,\n",
    "):\n",
    "  size_P_noisy = sum(s == 1)\n",
    "  size_N_noisy = sum(s == 0)\n",
    "  \n",
    "  if pi1 is None or pi0 is None:\n",
    "    rh1, rh0 = compute_conf_counts_noise_rates_from_probabilities(s, prob_s_eq_1)\n",
    "    _, _, pi1, pi0 = compute_ps1_py1_pi1_pi0(s, rh1, rh0)\n",
    "  \n",
    "  if num_to_remove_per_class is None:\n",
    "    # Estimate k0 and k1 (number of non-confident examples to prune)\n",
    "    # When frac_of_noise = 1, k1 and k0 are the number of expected mislabeling errors.\n",
    "    k1 = size_P_noisy * pi1 * frac_of_noise\n",
    "    k0 = size_N_noisy * pi0 * frac_of_noise\n",
    "  else:\n",
    "    k1 = num_to_remove_per_class[1]\n",
    "    k0 = num_to_remove_per_class[0]\n",
    "  \n",
    "  # The number of examples to prune in P and N. Leave at least 10 examples.\n",
    "  k1 = max(min(int(k1), size_P_noisy - MIN_NUM_PER_CLASS), 0)\n",
    "  k0 = max(min(int(k0), size_N_noisy - MIN_NUM_PER_CLASS), 0)\n",
    "  \n",
    "  if verbose:\n",
    "    print('k1: ', k1, ', k0: ', k0)\n",
    "\n",
    "  # Peform Pruning with threshold probabilities from BFPRT algorithm in O(n)\n",
    "  # Don't prune if pi1 = 0 or there are not MIN_NUM_PER_CLASS in P_noisy\n",
    "  if (pi1 > 0 and size_P_noisy > MIN_NUM_PER_CLASS) or num_to_remove_per_class is not None:\n",
    "    kth_smallest = np.partition(prob_s_eq_1[s == 1], k1)[k1]\n",
    "  else:\n",
    "    kth_smallest = -1.0\n",
    "  # Don't prune if pi0 = 0 or there are not MIN_NUM_PER_CLASS in N_noisy\n",
    "  if (pi0 > 0 and size_N_noisy > MIN_NUM_PER_CLASS) or num_to_remove_per_class is not None:\n",
    "    kth_largest = -np.partition(-prob_s_eq_1[s == 0], k0)[k0] \n",
    "  else:\n",
    "    kth_largest = 2.0 \n",
    "  \n",
    "  if verbose:\n",
    "    print('kth_smallest: ', kth_smallest, ', kth_largest: ', kth_largest)\n",
    "\n",
    "  noise_mask = ((prob_s_eq_1 > kth_largest) & (s == 0)) | ((prob_s_eq_1 < kth_smallest) & (s == 1))\n",
    "  \n",
    "  return noise_mask\n",
    "\n",
    "def _mean_without_nan_inf(arr, replacement = None):\n",
    "  if replacement is not None:\n",
    "    return np.mean(\n",
    "      [replacement if math.isnan(x) or math.isinf(x) else x for x in arr]\n",
    "    )\n",
    "  \n",
    "  x_real = [x for x in arr if not math.isnan(x) and not math.isinf(x)]\n",
    "  \n",
    "  if len(x_real) == 0:\n",
    "      raise ValueError(\"All rho_conf estimates are NaN. Check that\" \\\n",
    "        \"positive_lb_threshold and negative_ub_threshold values are not\" \\\n",
    "        \"too extreme (near 1 or 0), resulting in division by zero.\")\n",
    "  else:\n",
    "    return np.mean(x_real)\n",
    "class RankPruning(object):\n",
    "  def __init__(self,\n",
    "    frac_pos2neg = None,\n",
    "    frac_neg2pos = None,\n",
    "    clf = None,\n",
    "  ):\n",
    "    \n",
    "    if frac_pos2neg is not None and frac_neg2pos is not None:\n",
    "      # Verify that rh1 + rh0 < 1 and pi0 + pi1 < 1.\n",
    "      if frac_pos2neg + frac_neg2pos >= 1:\n",
    "        raise Exception(\"frac_pos2neg + frac_neg2pos < 1 is \" + \\\n",
    "          \"a necessary condition for Rank Pruning.\")\n",
    "    \n",
    "    self.rh1 = frac_pos2neg\n",
    "    self.rh0 = frac_neg2pos\n",
    "    self.clf = logreg() if clf is None else clf\n",
    "  \n",
    "  \n",
    "  def get_fraction_of_positives_mislabeled_as_negative(self):\n",
    "    '''Accessor method for inverse positive noise rate.'''\n",
    "    return self.rh1\n",
    "  \n",
    "  \n",
    "  def get_fraction_of_negatives_mislabeled_as_positive(self):\n",
    "    '''Accessor method for inverse negative noise rate.'''\n",
    "    return self.rh0\n",
    "    \n",
    "  \n",
    "  def get_fraction_mislabeling_in_positive_set(self):\n",
    "    '''Accessor method for positive noise rate.'''\n",
    "    return self.pi1\n",
    "  \n",
    "  \n",
    "  def get_fraction_mislabeling_in_negative_set(self):\n",
    "    '''Accessor method for negative noise rate.'''\n",
    "    return self.pi0\n",
    "  \n",
    "  \n",
    "  def fit(\n",
    "    self, \n",
    "    X,\n",
    "    s,\n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "    cv_n_folds = 3,\n",
    "    pulearning = None,\n",
    "    prob_s_eq_1 = None,\n",
    "    positive_lb_threshold = None,\n",
    "    negative_ub_threshold = None,\n",
    "    verbose = False,\n",
    "  ):\n",
    "    \n",
    "    # Check if we are in the PU learning setting.\n",
    "    if pulearning is None:\n",
    "      pulearning = (self.rh0 == 0)\n",
    "    \n",
    "    assert_inputs_are_valid(X, s, prob_s_eq_1)\n",
    "    \n",
    "    # Compute noise rates (fraction of mislabeling) for the\n",
    "    # positive and negative sets. Also compute P(s=1|x) if needed.\n",
    "    if prob_s_eq_1 is None or self.rh1 is None or self.rh0 is None:\n",
    "      if prob_s_eq_1 is None:\n",
    "        rh1, rh0, prob_s = \\\n",
    "        compute_noise_rates_and_cv_pred_proba(\n",
    "          X = X, \n",
    "          s = s, \n",
    "          X_test=X_test,\n",
    "          y_test=y_test,\n",
    "          clf = self.clf,\n",
    "          cv_n_folds = cv_n_folds,\n",
    "          positive_lb_threshold = positive_lb_threshold,\n",
    "          negative_ub_threshold = negative_ub_threshold,\n",
    "          verbose = verbose,\n",
    "        )\n",
    "        # Only P(s=1|x) is needed for binary case\n",
    "        prob_s_eq_1 = prob_s[:,1]\n",
    "        del prob_s\n",
    "      else:\n",
    "        rh1, rh0 = \\\n",
    "        compute_conf_counts_noise_rates_from_probabilities(\n",
    "          s = s, \n",
    "          prob_s_eq_1 = prob_s_eq_1,\n",
    "          positive_lb_threshold = positive_lb_threshold,\n",
    "          negative_ub_threshold = negative_ub_threshold, \n",
    "          verbose = verbose,\n",
    "        )\n",
    "    \n",
    "    # Set the noise rates to user-provided values, if provided.\n",
    "    self.rh1 = self.rh1 if self.rh1 is not None else rh1\n",
    "    self.rh0 = self.rh0 if self.rh0 is not None else rh0\n",
    "    \n",
    "    # Set rh0 if we are in the pulearning setting\n",
    "    self.rh0 = 0.0 if pulearning else self.rh0\n",
    "    \n",
    "    # Compute ps1 := P(s=1), py1 := P(y=1), and inverse noise rates pi1, pi0\n",
    "    self.ps1, self.py1, self.pi1, self.pi0 = compute_ps1_py1_pi1_pi0(s, self.rh1, self.rh0)\n",
    "      \n",
    "    # Get the indices of the examples we wish to prune\n",
    "    prune_mask = get_noise_indices(s, prob_s_eq_1, pi1 = self.pi1, pi0 = self.pi0)\n",
    "    \n",
    "    X_mask = ~prune_mask\n",
    "    #X_pruned = X[X_mask]\n",
    "    #s_pruned = s[X_mask]\n",
    "    \n",
    "    # Re-weight examples in the loss function for the final fitting\n",
    "    # s.t. the \"apparent\" original number of examples in P and N\n",
    "    # is preserved, even though the pruned set may differ.\n",
    "    #sample_weight = np.ones(np.shape(s_pruned)) / float(1 - self.rh1)\n",
    "    #sample_weight[s_pruned == 0] = 1.0 / float(1 - self.rh0)\n",
    "    \n",
    "    #self.clf.fit(X_pruned, s_pruned, sample_weight = sample_weight,eval_set=(test_X,test_y),early_stopping_rounds=50,eval_metric=lgb_classifier_f1_score,verbose=50)\n",
    "    return X_mask\n",
    "    \n",
    "  def predict(self, X):\n",
    "    return self.clf.predict(X)\n",
    "  \n",
    "  \n",
    "  def predict_proba(self, X):\n",
    "    return self.clf.predict_proba(X)[:,1]\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_valid= X_valid.values\n",
    "y_valid = y_valid.values\n",
    "\n",
    "rp = RankPruning()\n",
    "prune_index = rp.fit(X_train,y_train,X_valid,y_valid,verbose=True,cv_n_folds=5)\n",
    "positive = 0\n",
    "for i in range(len(prune_index)):\n",
    "    if y_train[i] == 1 and prune_index[i] == False:\n",
    "        prune_index[i] = True\n",
    "        positive+=1\n",
    "positive\n",
    "X_train = X_train[prune_index]\n",
    "y_train = y_train[prune_index]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''import pickle\n",
    "import random\n",
    "from typing import List, Tuple, Optional, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num: np.ndarray, y: Optional[np.ndarray]):\n",
    "        super().__init__()\n",
    "        self.x_num = x_num\n",
    "        self.y = y.astype(np.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x_num[idx]\n",
    "        else:\n",
    "            return self.x_num[idx], self.y[idx]\n",
    "        \n",
    "\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_features: int,\n",
    "                 hidden_size: int,\n",
    "                 n_categories: List[int],\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0.2,\n",
    "                 channel_1: int = 256,\n",
    "                 channel_2: int = 512,\n",
    "                 channel_3: int = 512,\n",
    "                 dropout_top: float = 0.1,\n",
    "                 dropout_mid: float = 0.3,\n",
    "                 dropout_bottom: float = 0.2,\n",
    "                 weight_norm: bool = True,\n",
    "                 two_stage: bool = True,\n",
    "                 celu: bool = True,\n",
    "                 kernel1: int = 5,):\n",
    "        super().__init__()\n",
    "\n",
    "        num_targets = 2\n",
    "\n",
    "        cha_1_reshape = int(hidden_size / channel_1)\n",
    "        cha_po_1 = int(hidden_size / channel_1 / 2)\n",
    "        cha_po_2 = int(hidden_size / channel_1 / 2 / 2) * channel_3\n",
    "\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.cha_1 = channel_1\n",
    "        self.cha_2 = channel_2\n",
    "        self.cha_3 = channel_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "        self.two_stage = two_stage\n",
    "\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features),\n",
    "            nn.Dropout(dropout_top),\n",
    "            nn.utils.weight_norm(nn.Linear(num_features, hidden_size), dim=None),\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            #nn.Dropout(dropout_top),\n",
    "            nn.CELU(0.06) if celu else nn.ReLU()\n",
    "        )\n",
    "\n",
    "        def _norm(layer, dim=None):\n",
    "            return nn.utils.weight_norm(layer, dim=dim) if weight_norm else layer\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(channel_1),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_1, channel_2, kernel_size=kernel1, stride=1, padding=kernel1 // 2, bias=False)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(output_size=cha_po_1),\n",
    "            nn.BatchNorm1d(channel_2),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if self.two_stage:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_mid),\n",
    "                _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Conv1d(channel_2, channel_3, kernel_size=5, stride=1, padding=2, bias=True)),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.BatchNorm1d(cha_po_2),\n",
    "            nn.Dropout(dropout_bottom),\n",
    "            #_norm(nn.Linear(cha_po_2, num_targets), dim=0),\n",
    "            nn.Linear(cha_po_2, num_targets),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    #def forward(self, x_num, x_cat):\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.expand(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], self.cha_1, self.cha_1_reshape)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        if self.two_stage:\n",
    "            x = self.conv2(x) * x\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "        x = self.flt(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return torch.squeeze(x)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### cnn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def train_epoch(data_loader: DataLoader,\n",
    "                model: nn.Module,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                device,\n",
    "                clip_grad: float = 1.5):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    step = 0\n",
    "\n",
    "    for x, y in tqdm(data_loader, position=0, leave=True, desc='Training'):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.to(device, dtype=torch.float)\n",
    "        y = y.to(device, dtype=torch.long)\n",
    "        output = model(x)\n",
    "        loss = focal_loss(output,y)\n",
    "        losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "        loss.backward()\n",
    "\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "def evaluate(data_loader: DataLoader, model, device):\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            batch_size = x.size(0)\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "            with torch.no_grad():\n",
    "                output = F.softmax(model(x))[:,1]\n",
    "\n",
    "            loss = focal_loss(model(x),y)\n",
    "            # record loss\n",
    "            losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "\n",
    "            targets = y.detach().cpu().numpy()\n",
    "            output = output.detach().cpu().numpy()\n",
    "\n",
    "            final_targets.append(targets)\n",
    "            final_outputs.append(output)\n",
    "\n",
    "    final_targets = np.concatenate(final_targets)\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "    auc = roc_auc_score(final_targets,final_outputs)\n",
    "    precision = precision_score(final_targets, np.round(final_outputs))\n",
    "    recall = recall_score(final_targets, np.round(final_outputs))\n",
    "    f2_score = 5*recall*precision/(4*precision+recall)\n",
    "\n",
    "    return final_outputs, final_targets, losses.avg, auc,precision,recall,f2_score\n",
    "\n",
    "def train_nn(X: pd.DataFrame,\n",
    "             y: pd.DataFrame,\n",
    "             device,\n",
    "             folds: List[Tuple]=None,\n",
    "             emb_dim: int = 25,\n",
    "             batch_size: int = 1024,\n",
    "             model_type: str = 'cnn',\n",
    "             mlp_dropout: float = 0.0,\n",
    "             mlp_hidden: int = 64,\n",
    "             mlp_bn: bool = False,\n",
    "             cnn_hidden: int = 64,\n",
    "             cnn_channel1: int = 32,\n",
    "             cnn_channel2: int = 32,\n",
    "             cnn_channel3: int = 32,\n",
    "             cnn_kernel1: int = 5,\n",
    "             cnn_celu: bool = False,\n",
    "             cnn_weight_norm: bool = False,\n",
    "             dropout_emb: bool = 0.0,\n",
    "             lr: float = 1e-3,\n",
    "             weight_decay: float = 0.0,\n",
    "             model_path: str = 'fold_{}.pth',\n",
    "             scaler_type: str = 'standard',\n",
    "             output_dir: str = 'artifacts',\n",
    "             scheduler_type: str = 'onecycle',\n",
    "             optimizer_type: str = 'adam',\n",
    "             max_lr: float = 0.01,\n",
    "             epochs: int = 30,\n",
    "             seed: int = 42,\n",
    "             n_pca: int = -1,\n",
    "             batch_double_freq: int = 50,\n",
    "             cnn_dropout: float = 0.1,\n",
    "             na_cols: bool = True,\n",
    "             cnn_leaky_relu: bool = False,\n",
    "             patience: int = 8,\n",
    "             factor: float = 0.5,\n",
    "             X_valid:pd.DataFrame=None,\n",
    "            y_valid:pd.DataFrame=None,):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    best_losses = []\n",
    "    best_predictions = []\n",
    "    \n",
    "\n",
    "    cur_batch = batch_size\n",
    "    best_loss = 1e10\n",
    "    best_prediction = None\n",
    "    train_dataset = TabularDataset(X, y)\n",
    "    valid_dataset = TabularDataset(X_valid, y_valid)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cur_batch, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=cur_batch*10, shuffle=False)\n",
    "\n",
    "    \n",
    "    model = CNN(X.shape[1],\n",
    "                hidden_size=cnn_hidden,\n",
    "                n_categories=[],\n",
    "                emb_dim=emb_dim,\n",
    "                dropout_cat=dropout_emb,\n",
    "                channel_1=cnn_channel1,\n",
    "                channel_2=cnn_channel2,\n",
    "                channel_3=cnn_channel3,\n",
    "                two_stage=False,\n",
    "                kernel1=cnn_kernel1,\n",
    "                celu=cnn_celu,\n",
    "                dropout_top=cnn_dropout,\n",
    "                dropout_mid=cnn_dropout,\n",
    "                dropout_bottom=cnn_dropout,\n",
    "                weight_norm=cnn_weight_norm)\n",
    "    print(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if optimizer_type == 'adamw':\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_type == 'adam':\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    scheduler = epoch_scheduler = None\n",
    "    if scheduler_type == 'onecycle':\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=opt, pct_start=0.1, div_factor=1e3,\n",
    "                                                        max_lr=max_lr, epochs=epochs,\n",
    "                                                        steps_per_epoch=len(train_loader))\n",
    "    elif scheduler_type == 'reduce':\n",
    "        epoch_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt,\n",
    "                                                                     mode='max',\n",
    "                                                                     min_lr=1e-7,\n",
    "                                                                     patience=patience,\n",
    "                                                                     verbose=True,\n",
    "                                                                     factor=factor)\n",
    "    best_auc = 0\n",
    "    for epoch in range(epochs):\n",
    "        if epoch > 0 and epoch % batch_double_freq == 0:\n",
    "            cur_batch = cur_batch * 2\n",
    "            print(f'batch: {cur_batch}')\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=cur_batch,\n",
    "                                                       shuffle=True,\n",
    "                                                       num_workers=4)\n",
    "        train_loss = train_epoch(train_loader, model, opt, scheduler, device)\n",
    "        predictions, valid_targets, valid_loss, auc,precision,recall,f2_score  = evaluate(valid_loader, model, device=device)\n",
    "        print(f\"epoch {epoch}, train loss: {train_loss:.8f}, valid auc: {auc:.8f},precision: {precision:.8f},recall: {recall:.8f},f2: {f2_score:.8f},\")\n",
    "\n",
    "        if epoch_scheduler is not None:\n",
    "            epoch_scheduler.step(auc)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            print(f'new best auc:{auc}')\n",
    "            best_auc = auc\n",
    "            best_prediction = predictions\n",
    "            torch.save(model, os.path.join(output_dir, model_path.format(epoch)))\n",
    "\n",
    "    best_predictions.append(best_prediction)\n",
    "    best_losses.append(best_loss)\n",
    "    del train_dataset, valid_dataset, train_loader, valid_loader, opt\n",
    "    if scheduler is not None:\n",
    "        del scheduler\n",
    "    gc.collect()\n",
    "\n",
    "    return best_losses, best_prediction,model\n",
    "\n",
    "def preprocess_nn(\n",
    "        X: pd.DataFrame,\n",
    "        scaler: Optional[StandardScaler] = None,\n",
    "        scaler_type: str = 'standard',\n",
    "        n_pca: int = -1,\n",
    "        na_cols: bool = False):\n",
    "    X = X.values.astype(np.float32)\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        X = np.nan_to_num(X, posinf=0, neginf=0)\n",
    "        return X,scaler\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def fold_5_nn(threshold,X,y,X_test):\n",
    "    fold = 0\n",
    "    f2_scores = 0\n",
    "    k = 5\n",
    "    dataloader.setSample(0)\n",
    "    tst_data = dataloader.get_test()\n",
    "    dataloader.reset_pre()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for x_trn, x_val, y_trn, y_val in dataloader.get_k_fold_train_val_data(k=k):\n",
    "        x_trn['y'] = y_trn\n",
    "        x_pos = x_trn.loc[x_trn['y']==1]\n",
    "        for _ in range(10):\n",
    "            x_trn = pd.concat([x_trn,x_pos])\n",
    "        y_trn = x_trn['y']\n",
    "        x_trn.drop(columns=['y'],inplace=True)\n",
    "        print(x_trn.shape)\n",
    "        fold += 1\n",
    "        print(f'{fold} starting ....')\n",
    "        _,pred,model = train_nn(x_trn.drop(columns=['a2']),y_trn,\n",
    "             device,batch_size=512,\n",
    "             cnn_hidden = 64*4,cnn_channel1 = 64,cnn_channel2 = 64*2,cnn_channel3 = 64*2,\n",
    "             lr= 0.0001,epochs = 3,cnn_dropout= 0.2,\n",
    "             X_valid=x_val.drop(columns=['a2']),y_valid=y_val,)\n",
    "        model = model.cpu()\n",
    "        score = f2_score(y_val, pred)[0]\n",
    "        f2_scores += score\n",
    "        # weight = (tst_data['a2'] != 2).astype(int)\n",
    "        weight = None\n",
    "        pred = model(torch.tensor(tst_data.drop(columns=['a2']).values.astype(np.float32)))[:, 1]\n",
    "        pred = pred.detach().numpy()\n",
    "        dataloader.set_pre(pred, weight, k=k)\n",
    "        del x_trn,x_val,y_trn,y_val,model,pred\n",
    "        gc.collect()\n",
    "    print('the mean f2 score is: ', f2_scores / k)\n",
    "    dataloader.save_res(f'lgb_{k}_fold', 0.03,threshold) #0.977  976 977  977 978\n",
    "    \n",
    "def fold_5_nn(X,y,tst_data):\n",
    "    fold = 0\n",
    "    f2_scores = 0\n",
    "    k = 5\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    sk = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    result = 0\n",
    "    for trn_idx, val_idx in sk.split(X,y):\n",
    "        x_trn,y_trn = X[trn_idx],y[trn_idx]\n",
    "        x_val,y_val = X[val_idx],y[val_idx]\n",
    "        x_pos = x_trn[y_trn==1]\n",
    "        for _ in range(10):\n",
    "            x_trn = np.concatenate([x_trn,x_pos])\n",
    "            y_trn = np.concatenate([y_trn,np.ones(len(x_pos))])\n",
    "        print(x_trn.shape)\n",
    "        fold += 1\n",
    "        print(f'{fold} starting ....')\n",
    "        _,pred,model = train_nn(x_trn,y_trn,\n",
    "             device,batch_size=512,\n",
    "             cnn_hidden = 64*4,cnn_channel1 = 64,cnn_channel2 = 64*2,cnn_channel3 = 64*2,\n",
    "             lr= 0.0001,epochs = 4,cnn_dropout= 0.2,\n",
    "             X_valid=x_val,y_valid=y_val,)\n",
    "        model = model.cpu()\n",
    "        model.eval()\n",
    "        pred = model(torch.tensor(tst_data.astype(np.float32)))\n",
    "        pred = F.softmax(pred)[:,1]\n",
    "        pred = pred.detach().numpy()\n",
    "        result +=  pred / k\n",
    "        del x_trn,x_val,y_trn,y_val,model,pred\n",
    "        gc.collect()\n",
    "    return result \n",
    "X = np.concatenate([X_train,X_valid])\n",
    "y = np.concatenate([y_train,y_valid])\n",
    "focal_loss = FocalLoss(gamma=2)\n",
    "nn_result = fold_5_nn(X,y,X_test)    \n",
    "final_nn = [1 if i>=0.5 else 0 for i in nn_result]\n",
    "pred_df['y'] = final_nn\n",
    "pred_df'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### test cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''x_pos = X_train[y_train==1]\n",
    "for i in range(10):\n",
    "    X_train = np.concatenate([X_train,x_pos])\n",
    "    y_train = np.concatenate([y_train,np.ones(len(x_pos))])\n",
    "cur_batch=512\n",
    "device='cuda:0'\n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "valid_dataset = TabularDataset(X_valid, y_valid)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cur_batch, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=cur_batch*10, shuffle=False)\n",
    "model = CNN(X_train.shape[1],\n",
    "                hidden_size=64*4,\n",
    "                n_categories=[],\n",
    "                channel_1=64,\n",
    "                channel_2=64*2,\n",
    "                channel_3=64*2,\n",
    "                two_stage=False,\n",
    "                celu=False,\n",
    "                dropout_top=0.2,\n",
    "                dropout_mid=0.2,\n",
    "                dropout_bottom=0.2,\n",
    "            kernel1=5,\n",
    "                weight_norm=True)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0)\n",
    "scheduler = epoch_scheduler = None\n",
    "epochs=50\n",
    "best_auc=0\n",
    "focal_loss = FocalLoss(gamma=2)\n",
    "for epoch in range(epochs):\n",
    "    if epoch > 0 and epoch % 5 == 0:\n",
    "        cur_batch = cur_batch * 2\n",
    "        print(f'batch: {cur_batch}')\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=cur_batch,\n",
    "                                                   shuffle=True,)\n",
    "    train_loss = train_epoch(train_loader, model, opt, scheduler, device=device)\n",
    "    predictions, valid_targets, valid_loss, auc,precision,recall,f2_score  = evaluate(valid_loader, model, device=device)\n",
    "    print(f\"epoch {epoch}, train loss: {train_loss:.8f}, valid auc: {auc:.8f},precision: {precision:.8f},recall: {recall:.8f},f2: {f2_score:.8f},\")\n",
    "\n",
    "    if epoch_scheduler is not None:\n",
    "        epoch_scheduler.step(auc)\n",
    "\n",
    "    if auc > best_auc:\n",
    "        print(f'new best auc:{auc}')\n",
    "        best_auc = auc\n",
    "        best_prediction = predictions\n",
    "        #torch.save(model, os.path.join('cnn', model_path.format(cv_idx)))\n",
    "\n",
    "\n",
    "best_predictions.append(best_prediction)\n",
    "best_losses.append(best_loss)\n",
    "focal_loss = nn.BCELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_losses,best_predictions,scaler = train_nn(X_train,y_train,batch_size=1280,epochs=30,cnn_hidden=8*128,\n",
    "                                               device=device,X_valid=X_valid,y_valid=y_valid,\n",
    "                                              cnn_channel1=128,cnn_channel2=3*128,cnn_channel3=3*128,\n",
    "                                              lr = 0.00038,max_lr=0.0013,weight_decay=6.5e-6,optimizer_type='adam',scheduler_type='reduce',model_path=\"cnn_fold.pth\",cnn_dropout=0.0,\n",
    "                                              cnn_weight_norm=True,cnn_leaky_relu=False,patience=8,factor=0.3)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## find hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 18:49:01,768]\u001b[0m A new study created in memory with name: LGBM Classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.950659\tvalid_0's f2: 0.375326\n",
      "[200]\tvalid_0's auc: 0.954313\tvalid_0's f2: 0.385506\n",
      "[300]\tvalid_0's auc: 0.955937\tvalid_0's f2: 0.391426\n",
      "[400]\tvalid_0's auc: 0.956434\tvalid_0's f2: 0.39454\n",
      "[500]\tvalid_0's auc: 0.95652\tvalid_0's f2: 0.394917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[485]\tvalid_0's auc: 0.956528\tvalid_0's f2: 0.395288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 18:58:42,715]\u001b[0m Trial 0 finished with value: 0.39527706963638803 and parameters: {'n_estimators': 500, 'learning_rate': 0.04621652318231738, 'num_leaves': 96, 'max_depth': 4, 'min_data_in_leaf': 1200, 'lambda_l1': 7, 'lambda_l2': 5, 'min_gain_to_split': 7.172020096410888, 'bagging_fraction': 0.9000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 0.39527706963638803.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.22450694986508, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.22450694986508\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.94887\tvalid_0's f2: 0.372625\n",
      "[200]\tvalid_0's auc: 0.952298\tvalid_0's f2: 0.379976\n",
      "[300]\tvalid_0's auc: 0.95403\tvalid_0's f2: 0.385931\n",
      "[400]\tvalid_0's auc: 0.954643\tvalid_0's f2: 0.38847\n",
      "[500]\tvalid_0's auc: 0.95478\tvalid_0's f2: 0.389897\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[443]\tvalid_0's auc: 0.954808\tvalid_0's f2: 0.389406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 19:08:43,638]\u001b[0m Trial 1 finished with value: 0.3894270104779751 and parameters: {'n_estimators': 500, 'learning_rate': 0.023964113729771693, 'num_leaves': 192, 'max_depth': 5, 'min_data_in_leaf': 1700, 'lambda_l1': 7, 'lambda_l2': 6, 'min_gain_to_split': 12.22450694986508, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 0 with value: 0.39527706963638803.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.864496383838903, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.864496383838903\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.944559\tvalid_0's f2: 0.378436\n",
      "[200]\tvalid_0's auc: 0.951765\tvalid_0's f2: 0.384788\n",
      "[300]\tvalid_0's auc: 0.953303\tvalid_0's f2: 0.38816\n",
      "[400]\tvalid_0's auc: 0.954346\tvalid_0's f2: 0.390011\n",
      "[500]\tvalid_0's auc: 0.95482\tvalid_0's f2: 0.391081\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[485]\tvalid_0's auc: 0.954823\tvalid_0's f2: 0.391312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 19:19:01,845]\u001b[0m Trial 2 finished with value: 0.3913123893571485 and parameters: {'n_estimators': 500, 'learning_rate': 0.01327012602199348, 'num_leaves': 128, 'max_depth': 7, 'min_data_in_leaf': 1400, 'lambda_l1': 2, 'lambda_l2': 0, 'min_gain_to_split': 8.864496383838903, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.9000000000000001}. Best is trial 0 with value: 0.39527706963638803.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.269964488368576, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.269964488368576\n",
      "[LightGBM] [Warning] lambda_l1 is set=4, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.937524\tvalid_0's f2: 0.359673\n",
      "[200]\tvalid_0's auc: 0.947638\tvalid_0's f2: 0.365707\n",
      "[300]\tvalid_0's auc: 0.950448\tvalid_0's f2: 0.372969\n",
      "[400]\tvalid_0's auc: 0.952152\tvalid_0's f2: 0.379053\n",
      "[500]\tvalid_0's auc: 0.953288\tvalid_0's f2: 0.383091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.953288\tvalid_0's f2: 0.383091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 19:28:40,136]\u001b[0m Trial 3 finished with value: 0.38309132146302044 and parameters: {'n_estimators': 500, 'learning_rate': 0.01799240094625167, 'num_leaves': 288, 'max_depth': 4, 'min_data_in_leaf': 1700, 'lambda_l1': 4, 'lambda_l2': 9, 'min_gain_to_split': 10.269964488368576, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 0 with value: 0.39527706963638803.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.659776279662912, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.659776279662912\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.94721\tvalid_0's f2: 0.369654\n",
      "[200]\tvalid_0's auc: 0.951478\tvalid_0's f2: 0.377272\n",
      "[300]\tvalid_0's auc: 0.953591\tvalid_0's f2: 0.385719\n",
      "[400]\tvalid_0's auc: 0.955137\tvalid_0's f2: 0.391004\n",
      "[500]\tvalid_0's auc: 0.955636\tvalid_0's f2: 0.392917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[481]\tvalid_0's auc: 0.955666\tvalid_0's f2: 0.392013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 19:38:12,055]\u001b[0m Trial 4 finished with value: 0.39201340853463873 and parameters: {'n_estimators': 500, 'learning_rate': 0.0284211498903945, 'num_leaves': 32, 'max_depth': 4, 'min_data_in_leaf': 2000, 'lambda_l1': 3, 'lambda_l2': 1, 'min_gain_to_split': 10.659776279662912, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 0.39527706963638803.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.040713569177653, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.040713569177653\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.952784\tvalid_0's f2: 0.389704\n",
      "[200]\tvalid_0's auc: 0.954653\tvalid_0's f2: 0.390835\n",
      "[300]\tvalid_0's auc: 0.954943\tvalid_0's f2: 0.391845\n",
      "[400]\tvalid_0's auc: 0.955112\tvalid_0's f2: 0.392472\n",
      "[500]\tvalid_0's auc: 0.955187\tvalid_0's f2: 0.393368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[495]\tvalid_0's auc: 0.955195\tvalid_0's f2: 0.393339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 19:47:59,359]\u001b[0m Trial 5 finished with value: 0.39336827526274337 and parameters: {'n_estimators': 500, 'learning_rate': 0.033700662031145814, 'num_leaves': 224, 'max_depth': 12, 'min_data_in_leaf': 600, 'lambda_l1': 2, 'lambda_l2': 9, 'min_gain_to_split': 8.040713569177653, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 0 with value: 0.39527706963638803.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.4755799125644, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.4755799125644\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.947664\tvalid_0's f2: 0.388886\n",
      "[200]\tvalid_0's auc: 0.952952\tvalid_0's f2: 0.393085\n",
      "[300]\tvalid_0's auc: 0.954139\tvalid_0's f2: 0.393451\n",
      "[400]\tvalid_0's auc: 0.954655\tvalid_0's f2: 0.394684\n",
      "[500]\tvalid_0's auc: 0.954864\tvalid_0's f2: 0.39538\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.954864\tvalid_0's f2: 0.39538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 19:58:22,556]\u001b[0m Trial 6 finished with value: 0.3953795913961083 and parameters: {'n_estimators': 500, 'learning_rate': 0.015446567899586117, 'num_leaves': 160, 'max_depth': 10, 'min_data_in_leaf': 500, 'lambda_l1': 6, 'lambda_l2': 0, 'min_gain_to_split': 7.4755799125644, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.390455611649625, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.390455611649625\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.948825\tvalid_0's f2: 0.377744\n",
      "[200]\tvalid_0's auc: 0.95163\tvalid_0's f2: 0.384605\n",
      "[300]\tvalid_0's auc: 0.95277\tvalid_0's f2: 0.385584\n",
      "[400]\tvalid_0's auc: 0.954336\tvalid_0's f2: 0.388344\n",
      "[500]\tvalid_0's auc: 0.955064\tvalid_0's f2: 0.388316\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.955064\tvalid_0's f2: 0.388316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:08:23,998]\u001b[0m Trial 7 finished with value: 0.3883155971192088 and parameters: {'n_estimators': 500, 'learning_rate': 0.011939130314222167, 'num_leaves': 128, 'max_depth': 10, 'min_data_in_leaf': 900, 'lambda_l1': 9, 'lambda_l2': 5, 'min_gain_to_split': 7.390455611649625, 'bagging_fraction': 0.9000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.940953973013271, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.940953973013271\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.942847\tvalid_0's f2: 0.356024\n",
      "[200]\tvalid_0's auc: 0.949128\tvalid_0's f2: 0.369418\n",
      "[300]\tvalid_0's auc: 0.951665\tvalid_0's f2: 0.380627\n",
      "[400]\tvalid_0's auc: 0.953373\tvalid_0's f2: 0.386249\n",
      "[500]\tvalid_0's auc: 0.954429\tvalid_0's f2: 0.389195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.954429\tvalid_0's f2: 0.389195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:18:17,336]\u001b[0m Trial 8 finished with value: 0.38919485969053236 and parameters: {'n_estimators': 500, 'learning_rate': 0.03428540829579281, 'num_leaves': 256, 'max_depth': 3, 'min_data_in_leaf': 1200, 'lambda_l1': 8, 'lambda_l2': 1, 'min_gain_to_split': 5.940953973013271, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.9000000000000001}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.00330616593756, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.00330616593756\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.953943\tvalid_0's f2: 0.394227\n",
      "[200]\tvalid_0's auc: 0.954854\tvalid_0's f2: 0.393283\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.953923\tvalid_0's f2: 0.394616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:22:28,591]\u001b[0m Trial 9 finished with value: 0.3946156762905585 and parameters: {'n_estimators': 500, 'learning_rate': 0.03948968203759582, 'num_leaves': 288, 'max_depth': 9, 'min_data_in_leaf': 400, 'lambda_l1': 2, 'lambda_l2': 9, 'min_gain_to_split': 14.00330616593756, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.2696975433302864, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.2696975433302864\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.944409\tvalid_0's f2: 0.385472\n",
      "[200]\tvalid_0's auc: 0.952914\tvalid_0's f2: 0.391015\n",
      "[300]\tvalid_0's auc: 0.95456\tvalid_0's f2: 0.392854\n",
      "[400]\tvalid_0's auc: 0.955267\tvalid_0's f2: 0.393485\n",
      "Early stopping, best iteration is:\n",
      "[355]\tvalid_0's auc: 0.955094\tvalid_0's f2: 0.394237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:31:31,329]\u001b[0m Trial 10 finished with value: 0.3942372424936044 and parameters: {'n_estimators': 500, 'learning_rate': 0.022274743326619634, 'num_leaves': 32, 'max_depth': 12, 'min_data_in_leaf': 300, 'lambda_l1': 5, 'lambda_l2': 3, 'min_gain_to_split': 2.2696975433302864, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 1.0}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.487923112525495, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.487923112525495\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.954604\tvalid_0's f2: 0.388955\n",
      "[200]\tvalid_0's auc: 0.95628\tvalid_0's f2: 0.390759\n",
      "[300]\tvalid_0's auc: 0.956727\tvalid_0's f2: 0.390789\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's auc: 0.956505\tvalid_0's f2: 0.391706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:37:38,437]\u001b[0m Trial 11 finished with value: 0.3917063222297757 and parameters: {'n_estimators': 500, 'learning_rate': 0.04968624898913606, 'num_leaves': 128, 'max_depth': 7, 'min_data_in_leaf': 900, 'lambda_l1': 6, 'lambda_l2': 5, 'min_gain_to_split': 4.487923112525495, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.660857527731518, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.660857527731518\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.953819\tvalid_0's f2: 0.386818\n",
      "[200]\tvalid_0's auc: 0.955542\tvalid_0's f2: 0.388777\n",
      "[300]\tvalid_0's auc: 0.955991\tvalid_0's f2: 0.389043\n",
      "[400]\tvalid_0's auc: 0.956352\tvalid_0's f2: 0.390261\n",
      "[500]\tvalid_0's auc: 0.956381\tvalid_0's f2: 0.388701\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[489]\tvalid_0's auc: 0.956385\tvalid_0's f2: 0.388732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:46:00,890]\u001b[0m Trial 12 finished with value: 0.3887318532341722 and parameters: {'n_estimators': 500, 'learning_rate': 0.04821588333728263, 'num_leaves': 96, 'max_depth': 9, 'min_data_in_leaf': 700, 'lambda_l1': 9, 'lambda_l2': 3, 'min_gain_to_split': 3.660857527731518, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 6 with value: 0.3953795913961083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.28816893721038017, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.28816893721038017\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.953636\tvalid_0's f2: 0.388403\n",
      "[200]\tvalid_0's auc: 0.956552\tvalid_0's f2: 0.394659\n",
      "[300]\tvalid_0's auc: 0.957553\tvalid_0's f2: 0.395384\n",
      "[400]\tvalid_0's auc: 0.958084\tvalid_0's f2: 0.395651\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's auc: 0.957977\tvalid_0's f2: 0.39678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 20:53:55,841]\u001b[0m Trial 13 finished with value: 0.3967797584818861 and parameters: {'n_estimators': 500, 'learning_rate': 0.04223859360499718, 'num_leaves': 96, 'max_depth': 6, 'min_data_in_leaf': 1300, 'lambda_l1': 0, 'lambda_l2': 7, 'min_gain_to_split': 0.28816893721038017, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.5589066757465484, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.5589066757465484\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.95313\tvalid_0's f2: 0.382915\n",
      "[200]\tvalid_0's auc: 0.955892\tvalid_0's f2: 0.390042\n",
      "[300]\tvalid_0's auc: 0.957097\tvalid_0's f2: 0.390663\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's auc: 0.956847\tvalid_0's f2: 0.392449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:00:26,191]\u001b[0m Trial 14 finished with value: 0.39244935043801354 and parameters: {'n_estimators': 500, 'learning_rate': 0.04091221049405107, 'num_leaves': 192, 'max_depth': 6, 'min_data_in_leaf': 1500, 'lambda_l1': 0, 'lambda_l2': 7, 'min_gain_to_split': 0.5589066757465484, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.6302294552389731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.6302294552389731\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.952888\tvalid_0's f2: 0.381994\n",
      "[200]\tvalid_0's auc: 0.955589\tvalid_0's f2: 0.383322\n",
      "[300]\tvalid_0's auc: 0.957023\tvalid_0's f2: 0.385532\n",
      "[400]\tvalid_0's auc: 0.957305\tvalid_0's f2: 0.38148\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid_0's auc: 0.957258\tvalid_0's f2: 0.386263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:08:18,817]\u001b[0m Trial 15 finished with value: 0.3862631095779898 and parameters: {'n_estimators': 500, 'learning_rate': 0.04066554778256502, 'num_leaves': 64, 'max_depth': 10, 'min_data_in_leaf': 200, 'lambda_l1': 0, 'lambda_l2': 7, 'min_gain_to_split': 0.6302294552389731, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.788300918984916, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.788300918984916\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.951748\tvalid_0's f2: 0.389775\n",
      "[200]\tvalid_0's auc: 0.953346\tvalid_0's f2: 0.392333\n",
      "[300]\tvalid_0's auc: 0.953576\tvalid_0's f2: 0.392175\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's auc: 0.953474\tvalid_0's f2: 0.393052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:14:37,307]\u001b[0m Trial 16 finished with value: 0.3926518773164312 and parameters: {'n_estimators': 500, 'learning_rate': 0.029352592742560333, 'num_leaves': 160, 'max_depth': 8, 'min_data_in_leaf': 900, 'lambda_l1': 5, 'lambda_l2': 3, 'min_gain_to_split': 14.788300918984916, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 1.0}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.6790965159542477, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.6790965159542477\n",
      "[LightGBM] [Warning] lambda_l1 is set=4, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.944437\tvalid_0's f2: 0.379233\n",
      "[200]\tvalid_0's auc: 0.951776\tvalid_0's f2: 0.385732\n",
      "[300]\tvalid_0's auc: 0.953741\tvalid_0's f2: 0.389071\n",
      "[400]\tvalid_0's auc: 0.954938\tvalid_0's f2: 0.390733\n",
      "[500]\tvalid_0's auc: 0.955669\tvalid_0's f2: 0.391544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's auc: 0.955672\tvalid_0's f2: 0.391669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:23:04,412]\u001b[0m Trial 17 finished with value: 0.39166888474846956 and parameters: {'n_estimators': 500, 'learning_rate': 0.017719234587956517, 'num_leaves': 160, 'max_depth': 6, 'min_data_in_leaf': 500, 'lambda_l1': 4, 'lambda_l2': 7, 'min_gain_to_split': 2.6790965159542477, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.363583554333372, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.363583554333372\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.954249\tvalid_0's f2: 0.392596\n",
      "[200]\tvalid_0's auc: 0.955854\tvalid_0's f2: 0.391955\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.954249\tvalid_0's f2: 0.392596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:26:33,290]\u001b[0m Trial 18 finished with value: 0.39259560618388933 and parameters: {'n_estimators': 500, 'learning_rate': 0.03622808880151352, 'num_leaves': 224, 'max_depth': 11, 'min_data_in_leaf': 1100, 'lambda_l1': 6, 'lambda_l2': 4, 'min_gain_to_split': 5.363583554333372, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=1.987686855794954, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.987686855794954\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.951901\tvalid_0's f2: 0.385368\n",
      "[200]\tvalid_0's auc: 0.955465\tvalid_0's f2: 0.391295\n",
      "[300]\tvalid_0's auc: 0.956838\tvalid_0's f2: 0.393961\n",
      "[400]\tvalid_0's auc: 0.957503\tvalid_0's f2: 0.394198\n",
      "[500]\tvalid_0's auc: 0.957871\tvalid_0's f2: 0.392786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's auc: 0.957901\tvalid_0's f2: 0.392933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:35:40,575]\u001b[0m Trial 19 finished with value: 0.3929329198629019 and parameters: {'n_estimators': 500, 'learning_rate': 0.025120927999012638, 'num_leaves': 96, 'max_depth': 8, 'min_data_in_leaf': 1400, 'lambda_l1': 3, 'lambda_l2': 10, 'min_gain_to_split': 1.987686855794954, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.9000000000000001}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.508427905150782, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.508427905150782\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.952451\tvalid_0's f2: 0.390082\n",
      "[200]\tvalid_0's auc: 0.953215\tvalid_0's f2: 0.392096\n",
      "[300]\tvalid_0's auc: 0.953456\tvalid_0's f2: 0.393192\n",
      "[400]\tvalid_0's auc: 0.953526\tvalid_0's f2: 0.39394\n",
      "[500]\tvalid_0's auc: 0.953583\tvalid_0's f2: 0.39376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[476]\tvalid_0's auc: 0.953599\tvalid_0's f2: 0.394004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:43:51,622]\u001b[0m Trial 20 finished with value: 0.39376008606777835 and parameters: {'n_estimators': 500, 'learning_rate': 0.04405896227128796, 'num_leaves': 64, 'max_depth': 10, 'min_data_in_leaf': 700, 'lambda_l1': 10, 'lambda_l2': 8, 'min_gain_to_split': 10.508427905150782, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.856748326153311, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.856748326153311\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.952562\tvalid_0's f2: 0.386804\n",
      "[200]\tvalid_0's auc: 0.955315\tvalid_0's f2: 0.394818\n",
      "[300]\tvalid_0's auc: 0.956129\tvalid_0's f2: 0.395544\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's auc: 0.955967\tvalid_0's f2: 0.396222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:49:33,619]\u001b[0m Trial 21 finished with value: 0.3962218519911861 and parameters: {'n_estimators': 500, 'learning_rate': 0.04513592981805542, 'num_leaves': 96, 'max_depth': 5, 'min_data_in_leaf': 1200, 'lambda_l1': 6, 'lambda_l2': 5, 'min_gain_to_split': 6.856748326153311, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.295904343182834, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.295904343182834\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.952972\tvalid_0's f2: 0.388911\n",
      "[200]\tvalid_0's auc: 0.955089\tvalid_0's f2: 0.393803\n",
      "[300]\tvalid_0's auc: 0.955662\tvalid_0's f2: 0.394176\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's auc: 0.955273\tvalid_0's f2: 0.395288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 21:55:00,954]\u001b[0m Trial 22 finished with value: 0.3952882394025681 and parameters: {'n_estimators': 500, 'learning_rate': 0.043568881389843134, 'num_leaves': 64, 'max_depth': 6, 'min_data_in_leaf': 1100, 'lambda_l1': 6, 'lambda_l2': 1, 'min_gain_to_split': 6.295904343182834, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.287684444929596, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.287684444929596\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.951129\tvalid_0's f2: 0.381248\n",
      "[200]\tvalid_0's auc: 0.954194\tvalid_0's f2: 0.388598\n",
      "[300]\tvalid_0's auc: 0.954897\tvalid_0's f2: 0.388731\n",
      "[400]\tvalid_0's auc: 0.955256\tvalid_0's f2: 0.389967\n",
      "Early stopping, best iteration is:\n",
      "[353]\tvalid_0's auc: 0.955166\tvalid_0's f2: 0.39065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 22:02:31,677]\u001b[0m Trial 23 finished with value: 0.3906503625148794 and parameters: {'n_estimators': 500, 'learning_rate': 0.037281740446631934, 'num_leaves': 128, 'max_depth': 5, 'min_data_in_leaf': 1600, 'lambda_l1': 7, 'lambda_l2': 6, 'min_gain_to_split': 9.287684444929596, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.816036553572154, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.816036553572154\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] lambda_l2 is set=2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.95062\tvalid_0's f2: 0.382171\n",
      "[200]\tvalid_0's auc: 0.953955\tvalid_0's f2: 0.389392\n",
      "[300]\tvalid_0's auc: 0.955615\tvalid_0's f2: 0.39356\n",
      "[400]\tvalid_0's auc: 0.956405\tvalid_0's f2: 0.396196\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's auc: 0.956328\tvalid_0's f2: 0.396711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 22:11:25,698]\u001b[0m Trial 24 finished with value: 0.3967109829675903 and parameters: {'n_estimators': 500, 'learning_rate': 0.03202039459073311, 'num_leaves': 160, 'max_depth': 5, 'min_data_in_leaf': 1300, 'lambda_l1': 1, 'lambda_l2': 2, 'min_gain_to_split': 4.816036553572154, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.008733693529294, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.008733693529294\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.946749\tvalid_0's f2: 0.367073\n",
      "[200]\tvalid_0's auc: 0.952355\tvalid_0's f2: 0.377351\n",
      "[300]\tvalid_0's auc: 0.953899\tvalid_0's f2: 0.384321\n",
      "[400]\tvalid_0's auc: 0.954665\tvalid_0's f2: 0.38702\n",
      "[500]\tvalid_0's auc: 0.955074\tvalid_0's f2: 0.389044\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[490]\tvalid_0's auc: 0.955083\tvalid_0's f2: 0.389301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 22:19:51,231]\u001b[0m Trial 25 finished with value: 0.3893005650922273 and parameters: {'n_estimators': 500, 'learning_rate': 0.031543769334914984, 'num_leaves': 96, 'max_depth': 5, 'min_data_in_leaf': 1300, 'lambda_l1': 1, 'lambda_l2': 4, 'min_gain_to_split': 4.008733693529294, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.088031804741743, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.088031804741743\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l2 is set=2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.94474\tvalid_0's f2: 0.352551\n",
      "[200]\tvalid_0's auc: 0.950306\tvalid_0's f2: 0.369335\n",
      "[300]\tvalid_0's auc: 0.952574\tvalid_0's f2: 0.379934\n",
      "[400]\tvalid_0's auc: 0.954384\tvalid_0's f2: 0.385213\n",
      "[500]\tvalid_0's auc: 0.955417\tvalid_0's f2: 0.388012\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.955417\tvalid_0's f2: 0.388012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 22:28:16,627]\u001b[0m Trial 26 finished with value: 0.3880118787120975 and parameters: {'n_estimators': 500, 'learning_rate': 0.044098345050514166, 'num_leaves': 320, 'max_depth': 3, 'min_data_in_leaf': 2000, 'lambda_l1': 1, 'lambda_l2': 2, 'min_gain_to_split': 5.088031804741743, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 13 with value: 0.3967797584818861.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000\n",
      "[LightGBM] [Warning] min_gain_to_split is set=3.1661631218050266, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.1661631218050266\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.953374\tvalid_0's f2: 0.389803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-94b823aede33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LGBM Classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-94b823aede33>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LGBM Classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-94b823aede33>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlgb_f2_score\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#score= roc_auc_score(y_test, preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    893\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    686\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   2886\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2887\u001b[0m         \"\"\"\n\u001b[1;32m-> 2888\u001b[1;33m         return [item for i in range(1, self.__num_dataset)\n\u001b[0m\u001b[0;32m   2889\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0;32m   2890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2887\u001b[0m         \"\"\"\n\u001b[0;32m   2888\u001b[0m         return [item for i in range(1, self.__num_dataset)\n\u001b[1;32m-> 2889\u001b[1;33m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[0;32m   2890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2891\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'split'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   3400\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3401\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3402\u001b[1;33m                 \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3403\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3404\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, preds, dataset)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0margc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0margc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-94b823aede33>\u001b[0m in \u001b[0;36mlgb_f2_score\u001b[1;34m(y_true, y_hat)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m\u001b[1;36m0.072\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'f2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1739\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1741\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1742\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1434\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                          str(average_options))\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# check float and contains non-integer float values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'f'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna   \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from lightgbm import LGBMClassifier\n",
    "def lgb_f2_score(y_true, y_hat):\n",
    "    y_hat = [1 if i >=0.072 else 0 for i in y_hat ]\n",
    "    precision = precision_score(y_true,y_hat,zero_division=1)\n",
    "    recall = recall_score(y_true,y_hat)\n",
    "    f2 = 5*recall*precision/(4*precision+recall)\n",
    "    return 'f2',f2,True\n",
    "def objective(trial, X_train, y_train,X_test,y_test):\n",
    "    param_grid = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [500]),   \n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 32, 320, step=32),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 2000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 10, step=0.25), \n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 10, step=0.25),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 1, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 1, step=0.1\n",
    "        ),\n",
    "    }\n",
    "    model = LGBMClassifier(objective=\"binary\",metric='auc', random_state=42,**param_grid)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=[lgb_f2_score], \n",
    "        early_stopping_rounds=100,\n",
    "        verbose=100,\n",
    "    )\n",
    "    #score= roc_auc_score(y_test, preds)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    _,score,_= lgb_f2_score(y_test, preds)\n",
    "    return score \n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X_train, y_train,X_valid,y_valid)\n",
    "study.optimize(func, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (rmse): 0.96464\n",
      "\tBest params:\n",
      "\t\tn_estimators: 500\n",
      "\t\tlearning_rate: 0.043661421086800184\n",
      "\t\tnum_leaves: 128\n",
      "\t\tmax_depth: 11\n",
      "\t\tmin_data_in_leaf: 300\n",
      "\t\tlambda_l1: 5\n",
      "\t\tlambda_l2: 4\n",
      "\t\tmin_gain_to_split: 0.3475062054695284\n",
      "\t\tbagging_fraction: 0.30000000000000004\n",
      "\t\tbagging_freq: 1\n",
      "\t\tfeature_fraction: 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "'''print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find xgboost hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:37:23,082]\u001b[0m A new study created in memory with name: XGB Classifier\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86283\n",
      "[100]\tvalidation_0-auc:0.95450\n",
      "[200]\tvalidation_0-auc:0.95515\n",
      "[210]\tvalidation_0-auc:0.95515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:37:44,523]\u001b[0m Trial 0 finished with value: 0.37873444861342287 and parameters: {'max_depth': 17, 'gamma': 2.6007395703384173, 'reg_alpha': 32, 'reg_lambda': 0.5532243950081096, 'colsample_bytree': 0.7937117733212198, 'min_child_weight': 9}. Best is trial 0 with value: 0.37873444861342287.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87003\n",
      "[100]\tvalidation_0-auc:0.95486\n",
      "[200]\tvalidation_0-auc:0.95568\n",
      "[248]\tvalidation_0-auc:0.95568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:38:12,637]\u001b[0m Trial 1 finished with value: 0.3468989993018385 and parameters: {'max_depth': 14, 'gamma': 0.8515588779032487, 'reg_alpha': 22, 'reg_lambda': 0.22258478755915845, 'colsample_bytree': 0.6776778183882639, 'min_child_weight': 7}. Best is trial 0 with value: 0.37873444861342287.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.88165\n",
      "[100]\tvalidation_0-auc:0.95398\n",
      "[200]\tvalidation_0-auc:0.95399\n",
      "[203]\tvalidation_0-auc:0.95399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:38:32,645]\u001b[0m Trial 2 finished with value: 0.34428475643529716 and parameters: {'max_depth': 12, 'gamma': 4.803063167999287, 'reg_alpha': 5, 'reg_lambda': 0.24735996049179332, 'colsample_bytree': 0.8890208737236098, 'min_child_weight': 3}. Best is trial 0 with value: 0.37873444861342287.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86820\n",
      "[100]\tvalidation_0-auc:0.95448\n",
      "[200]\tvalidation_0-auc:0.95464\n",
      "[202]\tvalidation_0-auc:0.95464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:38:49,769]\u001b[0m Trial 3 finished with value: 0.38633362366890506 and parameters: {'max_depth': 11, 'gamma': 8.305591514439136, 'reg_alpha': 26, 'reg_lambda': 0.864817087356181, 'colsample_bytree': 0.5847714960065502, 'min_child_weight': 0}. Best is trial 3 with value: 0.38633362366890506.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86246\n",
      "[100]\tvalidation_0-auc:0.95402\n",
      "[200]\tvalidation_0-auc:0.95492\n",
      "[227]\tvalidation_0-auc:0.95492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:39:09,793]\u001b[0m Trial 4 finished with value: 0.3743262968785089 and parameters: {'max_depth': 9, 'gamma': 2.557190469985019, 'reg_alpha': 39, 'reg_lambda': 0.06955669108152895, 'colsample_bytree': 0.5729533074380952, 'min_child_weight': 5}. Best is trial 3 with value: 0.38633362366890506.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86161\n",
      "[100]\tvalidation_0-auc:0.95424\n",
      "[200]\tvalidation_0-auc:0.95598\n",
      "[239]\tvalidation_0-auc:0.95598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:39:29,199]\u001b[0m Trial 5 finished with value: 0.3971380885933952 and parameters: {'max_depth': 6, 'gamma': 4.620670208616502, 'reg_alpha': 37, 'reg_lambda': 0.9480888896380527, 'colsample_bytree': 0.8399348047685429, 'min_child_weight': 5}. Best is trial 5 with value: 0.3971380885933952.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87377\n",
      "[100]\tvalidation_0-auc:0.95457\n",
      "[199]\tvalidation_0-auc:0.95457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:39:47,188]\u001b[0m Trial 6 finished with value: 0.3753894080996885 and parameters: {'max_depth': 13, 'gamma': 7.778757397356002, 'reg_alpha': 15, 'reg_lambda': 0.27082252824630215, 'colsample_bytree': 0.5999090205835524, 'min_child_weight': 5}. Best is trial 5 with value: 0.3971380885933952.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86987\n",
      "[100]\tvalidation_0-auc:0.95466\n",
      "[200]\tvalidation_0-auc:0.95473\n",
      "[204]\tvalidation_0-auc:0.95473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:40:05,370]\u001b[0m Trial 7 finished with value: 0.3754570966918956 and parameters: {'max_depth': 11, 'gamma': 7.554507396156227, 'reg_alpha': 21, 'reg_lambda': 0.5773460555799219, 'colsample_bytree': 0.5930838328737424, 'min_child_weight': 4}. Best is trial 5 with value: 0.3971380885933952.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85838\n",
      "[100]\tvalidation_0-auc:0.95351\n",
      "[200]\tvalidation_0-auc:0.95642\n",
      "[300]\tvalidation_0-auc:0.95709\n",
      "[400]\tvalidation_0-auc:0.95722\n",
      "[449]\tvalidation_0-auc:0.95747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:40:41,500]\u001b[0m Trial 8 finished with value: 0.3763980698965219 and parameters: {'max_depth': 5, 'gamma': 0.08661116481693476, 'reg_alpha': 34, 'reg_lambda': 0.1606745008488013, 'colsample_bytree': 0.7501548027809151, 'min_child_weight': 10}. Best is trial 5 with value: 0.3971380885933952.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.88518\n",
      "[100]\tvalidation_0-auc:0.95545\n",
      "[200]\tvalidation_0-auc:0.95545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:41:01,721]\u001b[0m Trial 9 finished with value: 0.37816196027389504 and parameters: {'max_depth': 10, 'gamma': 5.81015394324136, 'reg_alpha': 5, 'reg_lambda': 0.9057552289522895, 'colsample_bytree': 0.9970614527947339, 'min_child_weight': 6}. Best is trial 5 with value: 0.3971380885933952.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.75656\n",
      "[100]\tvalidation_0-auc:0.94887\n",
      "[200]\tvalidation_0-auc:0.95504\n",
      "[300]\tvalidation_0-auc:0.95714\n",
      "[400]\tvalidation_0-auc:0.95814\n",
      "[449]\tvalidation_0-auc:0.95815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:41:28,565]\u001b[0m Trial 10 finished with value: 0.39482139988218284 and parameters: {'max_depth': 3, 'gamma': 3.376768211500087, 'reg_alpha': 13, 'reg_lambda': 0.7702804630271328, 'colsample_bytree': 0.8592132828774112, 'min_child_weight': 1}. Best is trial 5 with value: 0.3971380885933952.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.75656\n",
      "[100]\tvalidation_0-auc:0.94874\n",
      "[200]\tvalidation_0-auc:0.95466\n",
      "[300]\tvalidation_0-auc:0.95708\n",
      "[400]\tvalidation_0-auc:0.95830\n",
      "[449]\tvalidation_0-auc:0.95842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:41:55,721]\u001b[0m Trial 11 finished with value: 0.39743658786148955 and parameters: {'max_depth': 3, 'gamma': 3.4628792822029064, 'reg_alpha': 12, 'reg_lambda': 0.7492537964055451, 'colsample_bytree': 0.8657883354483311, 'min_child_weight': 1}. Best is trial 11 with value: 0.39743658786148955.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87244\n",
      "[100]\tvalidation_0-auc:0.95492\n",
      "[200]\tvalidation_0-auc:0.95684\n",
      "[242]\tvalidation_0-auc:0.95684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:42:16,291]\u001b[0m Trial 12 finished with value: 0.3967665788317962 and parameters: {'max_depth': 6, 'gamma': 5.515240167153026, 'reg_alpha': 12, 'reg_lambda': 0.7357292397751968, 'colsample_bytree': 0.931326826584243, 'min_child_weight': 2}. Best is trial 11 with value: 0.39743658786148955.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.91309\n",
      "[100]\tvalidation_0-auc:0.95634\n",
      "[200]\tvalidation_0-auc:0.95757\n",
      "[255]\tvalidation_0-auc:0.95757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:42:39,181]\u001b[0m Trial 13 finished with value: 0.38481076962153926 and parameters: {'max_depth': 7, 'gamma': 3.883552951047914, 'reg_alpha': 0, 'reg_lambda': 0.9873742568082459, 'colsample_bytree': 0.8203877570360429, 'min_child_weight': 8}. Best is trial 11 with value: 0.39743658786148955.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74521\n",
      "[100]\tvalidation_0-auc:0.94814\n",
      "[200]\tvalidation_0-auc:0.95340\n",
      "[300]\tvalidation_0-auc:0.95502\n",
      "[369]\tvalidation_0-auc:0.95502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:43:02,263]\u001b[0m Trial 14 finished with value: 0.39412139895822257 and parameters: {'max_depth': 3, 'gamma': 6.587615470476928, 'reg_alpha': 29, 'reg_lambda': 0.6892093427684659, 'colsample_bytree': 0.7022260811734344, 'min_child_weight': 0}. Best is trial 11 with value: 0.39743658786148955.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87679\n",
      "[100]\tvalidation_0-auc:0.95493\n",
      "[200]\tvalidation_0-auc:0.95559\n",
      "[227]\tvalidation_0-auc:0.95559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:43:26,007]\u001b[0m Trial 15 finished with value: 0.37091946232915396 and parameters: {'max_depth': 8, 'gamma': 1.7746458272679768, 'reg_alpha': 16, 'reg_lambda': 0.9897735763511334, 'colsample_bytree': 0.9500466542195904, 'min_child_weight': 3}. Best is trial 11 with value: 0.39743658786148955.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86146\n",
      "[100]\tvalidation_0-auc:0.95325\n",
      "[200]\tvalidation_0-auc:0.95556\n",
      "[260]\tvalidation_0-auc:0.95556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:43:46,780]\u001b[0m Trial 16 finished with value: 0.39304176581603345 and parameters: {'max_depth': 5, 'gamma': 4.401136227653103, 'reg_alpha': 40, 'reg_lambda': 0.3824724653608341, 'colsample_bytree': 0.8518100125071266, 'min_child_weight': 2}. Best is trial 11 with value: 0.39743658786148955.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74520\n",
      "[100]\tvalidation_0-auc:0.94832\n",
      "[200]\tvalidation_0-auc:0.95453\n",
      "[300]\tvalidation_0-auc:0.95720\n",
      "[400]\tvalidation_0-auc:0.95829\n",
      "[449]\tvalidation_0-auc:0.95882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:44:14,612]\u001b[0m Trial 17 finished with value: 0.39745478901540526 and parameters: {'max_depth': 3, 'gamma': 2.9893929767985528, 'reg_alpha': 8, 'reg_lambda': 0.8172856861957523, 'colsample_bytree': 0.7867285250890631, 'min_child_weight': 7}. Best is trial 17 with value: 0.39745478901540526.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74520\n",
      "[100]\tvalidation_0-auc:0.94862\n",
      "[200]\tvalidation_0-auc:0.95398\n",
      "[300]\tvalidation_0-auc:0.95643\n",
      "[400]\tvalidation_0-auc:0.95769\n",
      "[449]\tvalidation_0-auc:0.95812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:44:42,608]\u001b[0m Trial 18 finished with value: 0.39194745554546906 and parameters: {'max_depth': 3, 'gamma': 1.8110134098498443, 'reg_alpha': 8, 'reg_lambda': 0.4181516352236043, 'colsample_bytree': 0.7641620341175241, 'min_child_weight': 7}. Best is trial 17 with value: 0.39745478901540526.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.91214\n",
      "[100]\tvalidation_0-auc:0.95435\n",
      "[163]\tvalidation_0-auc:0.95435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:45:11,976]\u001b[0m Trial 19 finished with value: 0.3649613587611295 and parameters: {'max_depth': 16, 'gamma': 3.118649535516244, 'reg_alpha': 0, 'reg_lambda': 0.6487577775636479, 'colsample_bytree': 0.6803614640188086, 'min_child_weight': 7}. Best is trial 17 with value: 0.39745478901540526.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85796\n",
      "[100]\tvalidation_0-auc:0.95231\n",
      "[200]\tvalidation_0-auc:0.95705\n",
      "[300]\tvalidation_0-auc:0.95818\n",
      "[400]\tvalidation_0-auc:0.95816\n",
      "[449]\tvalidation_0-auc:0.95806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:45:43,611]\u001b[0m Trial 20 finished with value: 0.3899794820606665 and parameters: {'max_depth': 4, 'gamma': 1.4407777934172805, 'reg_alpha': 9, 'reg_lambda': 0.7852058823698223, 'colsample_bytree': 0.9030028995226476, 'min_child_weight': 10}. Best is trial 17 with value: 0.39745478901540526.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87189\n",
      "[100]\tvalidation_0-auc:0.95558\n",
      "[200]\tvalidation_0-auc:0.95694\n",
      "[250]\tvalidation_0-auc:0.95694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:46:04,925]\u001b[0m Trial 21 finished with value: 0.3989785271019825 and parameters: {'max_depth': 6, 'gamma': 4.782951091148435, 'reg_alpha': 18, 'reg_lambda': 0.8576498841347486, 'colsample_bytree': 0.8149817397386218, 'min_child_weight': 6}. Best is trial 21 with value: 0.3989785271019825.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85866\n",
      "[100]\tvalidation_0-auc:0.95456\n",
      "[200]\tvalidation_0-auc:0.95721\n",
      "[272]\tvalidation_0-auc:0.95721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:46:27,081]\u001b[0m Trial 22 finished with value: 0.40091638029782356 and parameters: {'max_depth': 5, 'gamma': 5.524732779962722, 'reg_alpha': 16, 'reg_lambda': 0.8516218313773746, 'colsample_bytree': 0.7962234301287214, 'min_child_weight': 6}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86985\n",
      "[100]\tvalidation_0-auc:0.95529\n",
      "[200]\tvalidation_0-auc:0.95542\n",
      "[212]\tvalidation_0-auc:0.95542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:46:46,405]\u001b[0m Trial 23 finished with value: 0.39545767377838953 and parameters: {'max_depth': 7, 'gamma': 5.665908756110859, 'reg_alpha': 19, 'reg_lambda': 0.8373528758289054, 'colsample_bytree': 0.7226758756666387, 'min_child_weight': 6}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85866\n",
      "[100]\tvalidation_0-auc:0.95423\n",
      "[200]\tvalidation_0-auc:0.95702\n",
      "[258]\tvalidation_0-auc:0.95702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:47:06,969]\u001b[0m Trial 24 finished with value: 0.39964065009664335 and parameters: {'max_depth': 5, 'gamma': 6.624311694268308, 'reg_alpha': 18, 'reg_lambda': 0.6328725517339621, 'colsample_bytree': 0.7839225452595551, 'min_child_weight': 8}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86983\n",
      "[100]\tvalidation_0-auc:0.95484\n",
      "[200]\tvalidation_0-auc:0.95488\n",
      "[201]\tvalidation_0-auc:0.95488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:47:26,552]\u001b[0m Trial 25 finished with value: 0.3862577098043593 and parameters: {'max_depth': 8, 'gamma': 6.79653546707887, 'reg_alpha': 24, 'reg_lambda': 0.6282418161828194, 'colsample_bytree': 0.6609983512673628, 'min_child_weight': 8}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85817\n",
      "[100]\tvalidation_0-auc:0.95392\n",
      "[200]\tvalidation_0-auc:0.95585\n",
      "[259]\tvalidation_0-auc:0.95585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:47:47,381]\u001b[0m Trial 26 finished with value: 0.3923766816143497 and parameters: {'max_depth': 5, 'gamma': 6.708703302547857, 'reg_alpha': 18, 'reg_lambda': 0.4907381102412772, 'colsample_bytree': 0.5230529905613849, 'min_child_weight': 9}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87172\n",
      "[100]\tvalidation_0-auc:0.95527\n",
      "[200]\tvalidation_0-auc:0.95622\n",
      "[221]\tvalidation_0-auc:0.95622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:48:08,114]\u001b[0m Trial 27 finished with value: 0.3990018099051171 and parameters: {'max_depth': 7, 'gamma': 5.123953559315507, 'reg_alpha': 26, 'reg_lambda': 0.9060968949207988, 'colsample_bytree': 0.811170587740286, 'min_child_weight': 6}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86947\n",
      "[100]\tvalidation_0-auc:0.95463\n",
      "[200]\tvalidation_0-auc:0.95488\n",
      "[206]\tvalidation_0-auc:0.95488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:48:28,930]\u001b[0m Trial 28 finished with value: 0.38036758093525186 and parameters: {'max_depth': 9, 'gamma': 6.378089632844584, 'reg_alpha': 28, 'reg_lambda': 0.6911497070950003, 'colsample_bytree': 0.7708145165095823, 'min_child_weight': 8}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86309\n",
      "[100]\tvalidation_0-auc:0.95345\n",
      "[198]\tvalidation_0-auc:0.95345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:48:48,297]\u001b[0m Trial 29 finished with value: 0.38163345275414245 and parameters: {'max_depth': 18, 'gamma': 8.812577752587783, 'reg_alpha': 32, 'reg_lambda': 0.5172834131768606, 'colsample_bytree': 0.8011554343310627, 'min_child_weight': 9}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86993\n",
      "[100]\tvalidation_0-auc:0.95535\n",
      "[200]\tvalidation_0-auc:0.95583\n",
      "[209]\tvalidation_0-auc:0.95583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:49:07,167]\u001b[0m Trial 30 finished with value: 0.39742432942334505 and parameters: {'max_depth': 7, 'gamma': 7.496306451276315, 'reg_alpha': 23, 'reg_lambda': 0.895183189163838, 'colsample_bytree': 0.7253511376639997, 'min_child_weight': 4}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86369\n",
      "[100]\tvalidation_0-auc:0.95547\n",
      "[200]\tvalidation_0-auc:0.95714\n",
      "[239]\tvalidation_0-auc:0.95714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:49:28,424]\u001b[0m Trial 31 finished with value: 0.39915219472172847 and parameters: {'max_depth': 6, 'gamma': 5.306741591836989, 'reg_alpha': 17, 'reg_lambda': 0.914866735978658, 'colsample_bytree': 0.8051702914356854, 'min_child_weight': 6}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.76743\n",
      "[100]\tvalidation_0-auc:0.95237\n",
      "[200]\tvalidation_0-auc:0.95721\n",
      "[300]\tvalidation_0-auc:0.95769\n",
      "[328]\tvalidation_0-auc:0.95769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:49:51,712]\u001b[0m Trial 32 finished with value: 0.39789911427954205 and parameters: {'max_depth': 4, 'gamma': 5.203481286495524, 'reg_alpha': 16, 'reg_lambda': 0.9453449276481976, 'colsample_bytree': 0.7958031023755353, 'min_child_weight': 6}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85864\n",
      "[100]\tvalidation_0-auc:0.95443\n",
      "[200]\tvalidation_0-auc:0.95653\n",
      "[259]\tvalidation_0-auc:0.95653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:50:13,670]\u001b[0m Trial 33 finished with value: 0.3971969050307018 and parameters: {'max_depth': 5, 'gamma': 6.115953274810677, 'reg_alpha': 20, 'reg_lambda': 0.9080932496558092, 'colsample_bytree': 0.7344156655733569, 'min_child_weight': 4}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87176\n",
      "[100]\tvalidation_0-auc:0.95552\n",
      "[200]\tvalidation_0-auc:0.95589\n",
      "[215]\tvalidation_0-auc:0.95589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:50:35,231]\u001b[0m Trial 34 finished with value: 0.3914288892596918 and parameters: {'max_depth': 8, 'gamma': 3.9835768319122518, 'reg_alpha': 27, 'reg_lambda': 0.5826071395162281, 'colsample_bytree': 0.8953316709573444, 'min_child_weight': 8}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85801\n",
      "[100]\tvalidation_0-auc:0.95177\n",
      "[200]\tvalidation_0-auc:0.95627\n",
      "[300]\tvalidation_0-auc:0.95665\n",
      "[313]\tvalidation_0-auc:0.95665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:51:00,904]\u001b[0m Trial 35 finished with value: 0.3940820443846671 and parameters: {'max_depth': 4, 'gamma': 5.117599170872984, 'reg_alpha': 25, 'reg_lambda': 0.8137851796324533, 'colsample_bytree': 0.8296085627614967, 'min_child_weight': 6}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86309\n",
      "[100]\tvalidation_0-auc:0.95513\n",
      "[200]\tvalidation_0-auc:0.95626\n",
      "[227]\tvalidation_0-auc:0.95626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:51:23,895]\u001b[0m Trial 36 finished with value: 0.3995865408154939 and parameters: {'max_depth': 6, 'gamma': 7.1120779587760445, 'reg_alpha': 22, 'reg_lambda': 0.7161543576705176, 'colsample_bytree': 0.6431616529147154, 'min_child_weight': 7}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86993\n",
      "[100]\tvalidation_0-auc:0.95381\n",
      "[200]\tvalidation_0-auc:0.95389\n",
      "[202]\tvalidation_0-auc:0.95389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:51:46,523]\u001b[0m Trial 37 finished with value: 0.3670157967032967 and parameters: {'max_depth': 15, 'gamma': 7.1552110992717965, 'reg_alpha': 22, 'reg_lambda': 0.7030001722266023, 'colsample_bytree': 0.6603756205278758, 'min_child_weight': 7}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87418\n",
      "[100]\tvalidation_0-auc:0.95562\n",
      "[200]\tvalidation_0-auc:0.95572\n",
      "[209]\tvalidation_0-auc:0.95572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:52:09,655]\u001b[0m Trial 38 finished with value: 0.3847235107250288 and parameters: {'max_depth': 9, 'gamma': 6.006899786318635, 'reg_alpha': 14, 'reg_lambda': 0.6377674110511491, 'colsample_bytree': 0.6175429297460532, 'min_child_weight': 5}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86365\n",
      "[100]\tvalidation_0-auc:0.95511\n",
      "[200]\tvalidation_0-auc:0.95668\n",
      "[226]\tvalidation_0-auc:0.95668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:52:30,452]\u001b[0m Trial 39 finished with value: 0.39964548677392964 and parameters: {'max_depth': 6, 'gamma': 8.185025960628332, 'reg_alpha': 10, 'reg_lambda': 0.4309765244650766, 'colsample_bytree': 0.6348682794755938, 'min_child_weight': 9}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87332\n",
      "[100]\tvalidation_0-auc:0.95418\n",
      "[196]\tvalidation_0-auc:0.95418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:52:51,491]\u001b[0m Trial 40 finished with value: 0.35512706644128017 and parameters: {'max_depth': 10, 'gamma': 8.18754079895795, 'reg_alpha': 10, 'reg_lambda': 0.3209921229557994, 'colsample_bytree': 0.6317883066622696, 'min_child_weight': 9}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86353\n",
      "[100]\tvalidation_0-auc:0.95492\n",
      "[200]\tvalidation_0-auc:0.95633\n",
      "[226]\tvalidation_0-auc:0.95633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:53:11,542]\u001b[0m Trial 41 finished with value: 0.3986369981115034 and parameters: {'max_depth': 6, 'gamma': 8.069518609478301, 'reg_alpha': 17, 'reg_lambda': 0.4833113885597323, 'colsample_bytree': 0.5600647221159126, 'min_child_weight': 8}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85867\n",
      "[100]\tvalidation_0-auc:0.95408\n",
      "[200]\tvalidation_0-auc:0.95571\n",
      "[240]\tvalidation_0-auc:0.95571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:53:31,677]\u001b[0m Trial 42 finished with value: 0.39465786314525814 and parameters: {'max_depth': 5, 'gamma': 8.94014022588901, 'reg_alpha': 21, 'reg_lambda': 0.5681559788431543, 'colsample_bytree': 0.70104789535126, 'min_child_weight': 10}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87265\n",
      "[100]\tvalidation_0-auc:0.95586\n",
      "[200]\tvalidation_0-auc:0.95585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:53:52,878]\u001b[0m Trial 43 finished with value: 0.3922975215911329 and parameters: {'max_depth': 13, 'gamma': 7.279715980635749, 'reg_alpha': 14, 'reg_lambda': 0.11652374331040405, 'colsample_bytree': 0.5412963673511757, 'min_child_weight': 7}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.76743\n",
      "[100]\tvalidation_0-auc:0.95212\n",
      "[200]\tvalidation_0-auc:0.95634\n",
      "[286]\tvalidation_0-auc:0.95634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:54:14,456]\u001b[0m Trial 44 finished with value: 0.39583049461779535 and parameters: {'max_depth': 4, 'gamma': 8.531559672778515, 'reg_alpha': 11, 'reg_lambda': 0.41858392288271284, 'colsample_bytree': 0.7508878341112702, 'min_child_weight': 5}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86371\n",
      "[100]\tvalidation_0-auc:0.95468\n",
      "[200]\tvalidation_0-auc:0.95575\n",
      "[221]\tvalidation_0-auc:0.95575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:54:34,241]\u001b[0m Trial 45 finished with value: 0.39595998146280287 and parameters: {'max_depth': 6, 'gamma': 7.781384593172534, 'reg_alpha': 20, 'reg_lambda': 0.7337417977839479, 'colsample_bytree': 0.643581454126479, 'min_child_weight': 9}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87065\n",
      "[100]\tvalidation_0-auc:0.95645\n",
      "[200]\tvalidation_0-auc:0.95691\n",
      "[214]\tvalidation_0-auc:0.95691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:54:55,022]\u001b[0m Trial 46 finished with value: 0.39822276189424877 and parameters: {'max_depth': 7, 'gamma': 6.895519639739003, 'reg_alpha': 5, 'reg_lambda': 0.31795905207338593, 'colsample_bytree': 0.6876657123403321, 'min_child_weight': 7}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.86356\n",
      "[100]\tvalidation_0-auc:0.95480\n",
      "[200]\tvalidation_0-auc:0.95676\n",
      "[239]\tvalidation_0-auc:0.95676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:55:16,542]\u001b[0m Trial 47 finished with value: 0.3988779419813903 and parameters: {'max_depth': 6, 'gamma': 6.288411746784491, 'reg_alpha': 16, 'reg_lambda': 0.029387656823907093, 'colsample_bytree': 0.6044275389494818, 'min_child_weight': 8}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.88079\n",
      "[100]\tvalidation_0-auc:0.95498\n",
      "[200]\tvalidation_0-auc:0.95508\n",
      "[201]\tvalidation_0-auc:0.95508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:55:35,865]\u001b[0m Trial 48 finished with value: 0.38094971127431737 and parameters: {'max_depth': 8, 'gamma': 7.721792513461082, 'reg_alpha': 3, 'reg_lambda': 0.5329107842626725, 'colsample_bytree': 0.86973810748586, 'min_child_weight': 9}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.85872\n",
      "[100]\tvalidation_0-auc:0.95440\n",
      "[200]\tvalidation_0-auc:0.95743\n",
      "[277]\tvalidation_0-auc:0.95743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 14:55:57,844]\u001b[0m Trial 49 finished with value: 0.39656682910803265 and parameters: {'max_depth': 5, 'gamma': 5.392551945959308, 'reg_alpha': 13, 'reg_lambda': 0.7706255375844219, 'colsample_bytree': 0.7752887430693021, 'min_child_weight': 5}. Best is trial 22 with value: 0.40091638029782356.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train,X_test,y_test):    \n",
    "    param_grid={'max_depth': trial.suggest_int(\"max_depth\", 3, 18, step=1),\n",
    "        'gamma': trial.suggest_float('gamma', 0,9),\n",
    "        'reg_alpha' : trial.suggest_int('reg_alpha', 0,40,step=1),\n",
    "        'reg_lambda' : trial.suggest_float('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : trial.suggest_int('min_child_weight', 0, 10, step=1),\n",
    "        'n_estimators': 450,\n",
    "        'learning_rate':0.1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    model = XGBClassifier(**param_grid,tree_method='gpu_hist', gpu_id=0)\n",
    "    model.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='auc',\n",
    "        verbose=100,early_stopping_rounds=100)\n",
    "    #score= roc_auc_score(y_test, preds)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    _,score,_= lgb_f2_score(y_test, preds)\n",
    "    return score \n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"XGB Classifier\")\n",
    "func = lambda trial: objective(trial, X_train, y_train,X_valid,y_valid)\n",
    "study.optimize(func, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value\n",
    "study.best_params.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (rmse): 0.40092\n",
      "\tBest params:\n",
      "\t\tmax_depth: 5\n",
      "\t\tgamma: 5.524732779962722\n",
      "\t\treg_alpha: 16\n",
      "\t\treg_lambda: 0.8516218313773746\n",
      "\t\tcolsample_bytree: 0.7962234301287214\n",
      "\t\tmin_child_weight: 6\n"
     ]
    }
   ],
   "source": [
    "'''print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")'''\n",
    "'''Best value (rmse): 0.40092\n",
    "Best params:\n",
    "\t\tmax_depth: 5\n",
    "\t\tgamma: 5.524732779962722\n",
    "\t\treg_alpha: 16\n",
    "\t\treg_lambda: 0.8516218313773746\n",
    "\t\tcolsample_bytree: 0.7962234301287214\n",
    "\t\tmin_child_weight: 6'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### find catboost hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:05:26,706]\u001b[0m A new study created in memory with name: Cat Classifier\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9383047\ttest: 0.9078805\tbest: 0.9078805 (0)\ttotal: 50.4ms\tremaining: 2m 31s\n",
      "300:\tlearn: 0.9723900\ttest: 0.9496141\tbest: 0.9496141 (300)\ttotal: 14.7s\tremaining: 2m 11s\n",
      "600:\tlearn: 0.9745376\ttest: 0.9521242\tbest: 0.9521242 (600)\ttotal: 29s\tremaining: 1m 55s\n",
      "900:\tlearn: 0.9760554\ttest: 0.9539808\tbest: 0.9539900 (898)\ttotal: 43.4s\tremaining: 1m 41s\n",
      "1200:\tlearn: 0.9771058\ttest: 0.9549968\tbest: 0.9549993 (1192)\ttotal: 57.9s\tremaining: 1m 26s\n",
      "1500:\tlearn: 0.9779561\ttest: 0.9555981\tbest: 0.9555981 (1500)\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "1800:\tlearn: 0.9787233\ttest: 0.9563986\tbest: 0.9563986 (1800)\ttotal: 1m 26s\tremaining: 57.7s\n",
      "2100:\tlearn: 0.9793246\ttest: 0.9568788\tbest: 0.9568850 (2096)\ttotal: 1m 41s\tremaining: 43.4s\n",
      "2400:\tlearn: 0.9799736\ttest: 0.9574559\tbest: 0.9574559 (2400)\ttotal: 1m 56s\tremaining: 29.1s\n",
      "2700:\tlearn: 0.9805185\ttest: 0.9576175\tbest: 0.9576960 (2645)\ttotal: 2m 12s\tremaining: 14.7s\n",
      "2999:\tlearn: 0.9810060\ttest: 0.9579159\tbest: 0.9579171 (2996)\ttotal: 2m 28s\tremaining: 0us\n",
      "bestTest = 0.9579170644\n",
      "bestIteration = 2996\n",
      "Shrink model to first 2997 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:07:58,976]\u001b[0m Trial 0 finished with value: 0.38544852191641177 and parameters: {'l2_leaf_reg': 28, 'scale_pos_weight': 0.628044989539613, 'depth': 7, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.472128693294293}. Best is trial 0 with value: 0.38544852191641177.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9404950\ttest: 0.9091239\tbest: 0.9091239 (0)\ttotal: 60.7ms\tremaining: 3m 1s\n",
      "300:\tlearn: 0.9792772\ttest: 0.9556438\tbest: 0.9556475 (294)\ttotal: 22.1s\tremaining: 3m 17s\n",
      "bestTest = 0.9559026659\n",
      "bestIteration = 424\n",
      "Shrink model to first 425 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:08:41,649]\u001b[0m Trial 1 finished with value: 0.3642671292281006 and parameters: {'l2_leaf_reg': 28, 'scale_pos_weight': 0.861363037541665, 'depth': 9, 'bootstrap_type': 'Bernoulli', 'subsample': 0.38994986123342057}. Best is trial 0 with value: 0.38544852191641177.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8723801\ttest: 0.8168189\tbest: 0.8168189 (0)\ttotal: 41.8ms\tremaining: 2m 5s\n",
      "300:\tlearn: 0.9511320\ttest: 0.9122730\tbest: 0.9123653 (294)\ttotal: 12.8s\tremaining: 1m 54s\n",
      "600:\tlearn: 0.9556394\ttest: 0.9198663\tbest: 0.9198663 (600)\ttotal: 25.5s\tremaining: 1m 41s\n",
      "900:\tlearn: 0.9578657\ttest: 0.9235482\tbest: 0.9235482 (900)\ttotal: 38.3s\tremaining: 1m 29s\n",
      "1200:\tlearn: 0.9595951\ttest: 0.9254091\tbest: 0.9254353 (1199)\ttotal: 51.5s\tremaining: 1m 17s\n",
      "1500:\tlearn: 0.9609771\ttest: 0.9280076\tbest: 0.9280605 (1490)\ttotal: 1m 4s\tremaining: 1m 4s\n",
      "1800:\tlearn: 0.9621436\ttest: 0.9300854\tbest: 0.9300854 (1800)\ttotal: 1m 17s\tremaining: 51.3s\n",
      "2100:\tlearn: 0.9631027\ttest: 0.9317907\tbest: 0.9318090 (2085)\ttotal: 1m 29s\tremaining: 38.5s\n",
      "2400:\tlearn: 0.9642254\ttest: 0.9330579\tbest: 0.9330579 (2400)\ttotal: 1m 43s\tremaining: 25.8s\n",
      "2700:\tlearn: 0.9650365\ttest: 0.9347481\tbest: 0.9347763 (2694)\ttotal: 1m 56s\tremaining: 12.9s\n",
      "2999:\tlearn: 0.9656646\ttest: 0.9355778\tbest: 0.9356295 (2961)\ttotal: 2m 10s\tremaining: 0us\n",
      "bestTest = 0.9356294572\n",
      "bestIteration = 2961\n",
      "Shrink model to first 2962 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:10:56,319]\u001b[0m Trial 2 finished with value: 0.28560319536248274 and parameters: {'l2_leaf_reg': 18, 'scale_pos_weight': 0.3573156167620832, 'depth': 4, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.858254007794361}. Best is trial 0 with value: 0.38544852191641177.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 43.8ms\tremaining: 2m 11s\n",
      "300:\tlearn: 0.9718814\ttest: 0.9517837\tbest: 0.9517837 (300)\ttotal: 13.4s\tremaining: 2m\n",
      "600:\tlearn: 0.9748893\ttest: 0.9551459\tbest: 0.9551459 (600)\ttotal: 26.8s\tremaining: 1m 47s\n",
      "900:\tlearn: 0.9761751\ttest: 0.9562134\tbest: 0.9562920 (876)\ttotal: 40.7s\tremaining: 1m 34s\n",
      "1200:\tlearn: 0.9771344\ttest: 0.9567752\tbest: 0.9568502 (1148)\ttotal: 54.6s\tremaining: 1m 21s\n",
      "1500:\tlearn: 0.9777462\ttest: 0.9572655\tbest: 0.9573060 (1419)\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "bestTest = 0.9573060274\n",
      "bestIteration = 1419\n",
      "Shrink model to first 1420 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:12:10,014]\u001b[0m Trial 3 finished with value: 0.403339978619514 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9009610516971068, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6055057774573963}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9231748\ttest: 0.8617755\tbest: 0.8617755 (0)\ttotal: 51.7ms\tremaining: 2m 35s\n",
      "300:\tlearn: 0.9775389\ttest: 0.9547834\tbest: 0.9547882 (299)\ttotal: 17.5s\tremaining: 2m 37s\n",
      "600:\tlearn: 0.9803807\ttest: 0.9561405\tbest: 0.9561426 (599)\ttotal: 34.6s\tremaining: 2m 18s\n",
      "900:\tlearn: 0.9821330\ttest: 0.9566069\tbest: 0.9566156 (811)\ttotal: 51.4s\tremaining: 1m 59s\n",
      "bestTest = 0.956615597\n",
      "bestIteration = 811\n",
      "Shrink model to first 812 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:13:06,199]\u001b[0m Trial 4 finished with value: 0.38142374488767705 and parameters: {'l2_leaf_reg': 4, 'scale_pos_weight': 0.9322282752796963, 'depth': 7, 'bootstrap_type': 'Bernoulli', 'subsample': 0.30642892924015885}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9124908\ttest: 0.8469695\tbest: 0.8469695 (0)\ttotal: 45.7ms\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9725593\ttest: 0.9521618\tbest: 0.9521618 (300)\ttotal: 14.6s\tremaining: 2m 11s\n",
      "600:\tlearn: 0.9749582\ttest: 0.9548699\tbest: 0.9548748 (598)\ttotal: 28.8s\tremaining: 1m 55s\n",
      "900:\tlearn: 0.9762282\ttest: 0.9565999\tbest: 0.9565999 (898)\ttotal: 43.4s\tremaining: 1m 41s\n",
      "1200:\tlearn: 0.9771959\ttest: 0.9572142\tbest: 0.9572142 (1200)\ttotal: 58.2s\tremaining: 1m 27s\n",
      "1500:\tlearn: 0.9778705\ttest: 0.9578839\tbest: 0.9578852 (1499)\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "1800:\tlearn: 0.9784533\ttest: 0.9581473\tbest: 0.9581555 (1797)\ttotal: 1m 28s\tremaining: 58.6s\n",
      "2100:\tlearn: 0.9790266\ttest: 0.9584874\tbest: 0.9585083 (2094)\ttotal: 1m 43s\tremaining: 44.3s\n",
      "bestTest = 0.9585086405\n",
      "bestIteration = 2143\n",
      "Shrink model to first 2144 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:15:01,300]\u001b[0m Trial 5 finished with value: 0.36690572705539964 and parameters: {'l2_leaf_reg': 14, 'scale_pos_weight': 0.451206578701823, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.42278730588975777}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9486721\ttest: 0.7209522\tbest: 0.7209522 (0)\ttotal: 79.2ms\tremaining: 3m 57s\n",
      "300:\tlearn: 0.9779766\ttest: 0.9516696\tbest: 0.9516696 (300)\ttotal: 24.7s\tremaining: 3m 41s\n",
      "600:\tlearn: 0.9806718\ttest: 0.9536241\tbest: 0.9536267 (597)\ttotal: 48.6s\tremaining: 3m 13s\n",
      "900:\tlearn: 0.9829330\ttest: 0.9550472\tbest: 0.9550482 (899)\ttotal: 1m 13s\tremaining: 2m 51s\n",
      "1200:\tlearn: 0.9841569\ttest: 0.9554687\tbest: 0.9556597 (1132)\ttotal: 1m 35s\tremaining: 2m 23s\n",
      "bestTest = 0.9556596577\n",
      "bestIteration = 1132\n",
      "Shrink model to first 1133 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:16:45,412]\u001b[0m Trial 6 finished with value: 0.27167355296354523 and parameters: {'l2_leaf_reg': 26, 'scale_pos_weight': 0.39967844288031246, 'depth': 10, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6711348364380412}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9186980\ttest: 0.8734945\tbest: 0.8734945 (0)\ttotal: 57.8ms\tremaining: 2m 53s\n",
      "300:\tlearn: 0.9587764\ttest: 0.9228600\tbest: 0.9228703 (298)\ttotal: 19.4s\tremaining: 2m 54s\n",
      "600:\tlearn: 0.9650919\ttest: 0.9338264\tbest: 0.9338264 (600)\ttotal: 39.4s\tremaining: 2m 37s\n",
      "900:\tlearn: 0.9680888\ttest: 0.9392756\tbest: 0.9392756 (900)\ttotal: 59.9s\tremaining: 2m 19s\n",
      "1200:\tlearn: 0.9702490\ttest: 0.9420312\tbest: 0.9420312 (1200)\ttotal: 1m 19s\tremaining: 1m 59s\n",
      "1500:\tlearn: 0.9717954\ttest: 0.9444605\tbest: 0.9444642 (1499)\ttotal: 1m 38s\tremaining: 1m 38s\n",
      "1800:\tlearn: 0.9729929\ttest: 0.9465525\tbest: 0.9465531 (1799)\ttotal: 1m 58s\tremaining: 1m 19s\n",
      "2100:\tlearn: 0.9739666\ttest: 0.9478315\tbest: 0.9478467 (2079)\ttotal: 2m 18s\tremaining: 59.3s\n",
      "2400:\tlearn: 0.9748915\ttest: 0.9488637\tbest: 0.9488803 (2395)\ttotal: 2m 38s\tremaining: 39.5s\n",
      "2700:\tlearn: 0.9756508\ttest: 0.9495284\tbest: 0.9495494 (2686)\ttotal: 2m 58s\tremaining: 19.7s\n",
      "2999:\tlearn: 0.9762882\ttest: 0.9500552\tbest: 0.9501081 (2983)\ttotal: 3m 18s\tremaining: 0us\n",
      "bestTest = 0.9501081407\n",
      "bestIteration = 2983\n",
      "Shrink model to first 2984 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:20:12,241]\u001b[0m Trial 7 finished with value: 0.009716682008796154 and parameters: {'l2_leaf_reg': 7, 'scale_pos_weight': 0.02140442272888058, 'depth': 9, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.634850799348895}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9268969\ttest: 0.8644270\tbest: 0.8644270 (0)\ttotal: 49.2ms\tremaining: 2m 27s\n",
      "300:\tlearn: 0.9700393\ttest: 0.9478284\tbest: 0.9478713 (299)\ttotal: 15s\tremaining: 2m 14s\n",
      "600:\tlearn: 0.9722914\ttest: 0.9517802\tbest: 0.9517802 (600)\ttotal: 30.5s\tremaining: 2m 1s\n",
      "900:\tlearn: 0.9735001\ttest: 0.9531423\tbest: 0.9531766 (868)\ttotal: 45.6s\tremaining: 1m 46s\n",
      "1200:\tlearn: 0.9743291\ttest: 0.9541377\tbest: 0.9541387 (1189)\ttotal: 1m\tremaining: 1m 30s\n",
      "1500:\tlearn: 0.9752927\ttest: 0.9554609\tbest: 0.9554609 (1500)\ttotal: 1m 16s\tremaining: 1m 16s\n",
      "1800:\tlearn: 0.9759579\ttest: 0.9561088\tbest: 0.9561088 (1800)\ttotal: 1m 31s\tremaining: 1m 1s\n",
      "bestTest = 0.956284374\n",
      "bestIteration = 1963\n",
      "Shrink model to first 1964 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:22:02,765]\u001b[0m Trial 8 finished with value: 0.1802299867315347 and parameters: {'l2_leaf_reg': 30, 'scale_pos_weight': 0.17003132681925934, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9914529935613907}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8690594\ttest: 0.7805253\tbest: 0.7805253 (0)\ttotal: 40.2ms\tremaining: 2m\n",
      "300:\tlearn: 0.9638224\ttest: 0.9367700\tbest: 0.9367700 (300)\ttotal: 11.5s\tremaining: 1m 43s\n",
      "600:\tlearn: 0.9680242\ttest: 0.9448644\tbest: 0.9448644 (600)\ttotal: 24s\tremaining: 1m 35s\n",
      "900:\tlearn: 0.9699377\ttest: 0.9479533\tbest: 0.9479559 (899)\ttotal: 35.9s\tremaining: 1m 23s\n",
      "1200:\tlearn: 0.9710989\ttest: 0.9500408\tbest: 0.9500518 (1183)\ttotal: 47s\tremaining: 1m 10s\n",
      "1500:\tlearn: 0.9719256\ttest: 0.9510427\tbest: 0.9510427 (1500)\ttotal: 58.1s\tremaining: 58s\n",
      "1800:\tlearn: 0.9724985\ttest: 0.9523019\tbest: 0.9523045 (1798)\ttotal: 1m 9s\tremaining: 46.1s\n",
      "2100:\tlearn: 0.9729177\ttest: 0.9529253\tbest: 0.9529253 (2100)\ttotal: 1m 20s\tremaining: 34.4s\n",
      "2400:\tlearn: 0.9733339\ttest: 0.9534128\tbest: 0.9534128 (2399)\ttotal: 1m 31s\tremaining: 22.8s\n",
      "2700:\tlearn: 0.9737122\ttest: 0.9536759\tbest: 0.9536759 (2700)\ttotal: 1m 42s\tremaining: 11.3s\n",
      "2999:\tlearn: 0.9739925\ttest: 0.9538997\tbest: 0.9538997 (2999)\ttotal: 1m 53s\tremaining: 0us\n",
      "bestTest = 0.9538997114\n",
      "bestIteration = 2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:24:00,493]\u001b[0m Trial 9 finished with value: 0.34601514605120814 and parameters: {'l2_leaf_reg': 23, 'scale_pos_weight': 0.41616100440162335, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.22062918225391426}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8091967\ttest: 0.7391798\tbest: 0.7391798 (0)\ttotal: 31.8ms\tremaining: 1m 35s\n",
      "300:\tlearn: 0.9523212\ttest: 0.9092963\tbest: 0.9092963 (300)\ttotal: 9.37s\tremaining: 1m 23s\n",
      "600:\tlearn: 0.9560592\ttest: 0.9198000\tbest: 0.9198000 (600)\ttotal: 19s\tremaining: 1m 15s\n",
      "900:\tlearn: 0.9592434\ttest: 0.9283349\tbest: 0.9283650 (896)\ttotal: 29s\tremaining: 1m 7s\n",
      "1200:\tlearn: 0.9606769\ttest: 0.9308850\tbest: 0.9308850 (1200)\ttotal: 38.9s\tremaining: 58.3s\n",
      "1500:\tlearn: 0.9617177\ttest: 0.9329996\tbest: 0.9330128 (1496)\ttotal: 48.7s\tremaining: 48.7s\n",
      "1800:\tlearn: 0.9621883\ttest: 0.9338849\tbest: 0.9338883 (1799)\ttotal: 58.4s\tremaining: 38.9s\n",
      "2100:\tlearn: 0.9629606\ttest: 0.9351722\tbest: 0.9351785 (2097)\ttotal: 1m 8s\tremaining: 29.2s\n",
      "2400:\tlearn: 0.9633404\ttest: 0.9357499\tbest: 0.9357504 (2399)\ttotal: 1m 18s\tremaining: 19.5s\n",
      "2700:\tlearn: 0.9644926\ttest: 0.9377073\tbest: 0.9377359 (2687)\ttotal: 1m 28s\tremaining: 9.75s\n",
      "2999:\tlearn: 0.9647015\ttest: 0.9381563\tbest: 0.9381723 (2986)\ttotal: 1m 37s\tremaining: 0us\n",
      "bestTest = 0.9381722808\n",
      "bestIteration = 2986\n",
      "Shrink model to first 2987 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:25:42,438]\u001b[0m Trial 10 finished with value: 0.31213445792033495 and parameters: {'l2_leaf_reg': 12, 'scale_pos_weight': 0.7060985628631367, 'depth': 1, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.41537368051137147}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7968594\ttest: 0.7473409\tbest: 0.7473409 (0)\ttotal: 33.9ms\tremaining: 1m 41s\n",
      "300:\tlearn: 0.9531856\ttest: 0.9179721\tbest: 0.9179721 (300)\ttotal: 9.29s\tremaining: 1m 23s\n",
      "bestTest = 0.9185156822\n",
      "bestIteration = 353\n",
      "Shrink model to first 354 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:26:00,094]\u001b[0m Trial 11 finished with value: 0.30325138342097296 and parameters: {'l2_leaf_reg': 20, 'scale_pos_weight': 0.7004414835576124, 'depth': 1, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.913098292670402}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9492289\ttest: 0.9004785\tbest: 0.9004785 (0)\ttotal: 151ms\tremaining: 7m 33s\n",
      "300:\tlearn: 0.9775206\ttest: 0.9465613\tbest: 0.9465912 (299)\ttotal: 40.5s\tremaining: 6m 3s\n",
      "600:\tlearn: 0.9830128\ttest: 0.9511880\tbest: 0.9511880 (600)\ttotal: 1m 19s\tremaining: 5m 17s\n",
      "900:\tlearn: 0.9862580\ttest: 0.9530253\tbest: 0.9530448 (897)\ttotal: 1m 58s\tremaining: 4m 37s\n",
      "1200:\tlearn: 0.9885214\ttest: 0.9544064\tbest: 0.9544064 (1200)\ttotal: 2m 38s\tremaining: 3m 57s\n",
      "bestTest = 0.9546605647\n",
      "bestIteration = 1297\n",
      "Shrink model to first 1298 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:29:10,941]\u001b[0m Trial 12 finished with value: 0.36127353338045365 and parameters: {'l2_leaf_reg': 10, 'scale_pos_weight': 0.720243933392453, 'depth': 12, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.865725062449464}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9235438\ttest: 0.8712027\tbest: 0.8712027 (0)\ttotal: 46ms\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9771159\ttest: 0.9553779\tbest: 0.9553779 (300)\ttotal: 15s\tremaining: 2m 14s\n",
      "600:\tlearn: 0.9796405\ttest: 0.9571879\tbest: 0.9571879 (600)\ttotal: 30s\tremaining: 1m 59s\n",
      "900:\tlearn: 0.9811214\ttest: 0.9580457\tbest: 0.9580457 (900)\ttotal: 45.2s\tremaining: 1m 45s\n",
      "1200:\tlearn: 0.9823010\ttest: 0.9586350\tbest: 0.9586350 (1200)\ttotal: 1m\tremaining: 1m 30s\n",
      "1500:\tlearn: 0.9833334\ttest: 0.9589009\tbest: 0.9589119 (1492)\ttotal: 1m 15s\tremaining: 1m 15s\n",
      "bestTest = 0.9589523673\n",
      "bestIteration = 1605\n",
      "Shrink model to first 1606 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:30:41,128]\u001b[0m Trial 13 finished with value: 0.3811115383477772 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.9877028692875568, 'depth': 7, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6713382090783904}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8939064\ttest: 0.8347275\tbest: 0.8347275 (0)\ttotal: 38.1ms\tremaining: 1m 54s\n",
      "bestTest = 0.9095520973\n",
      "bestIteration = 186\n",
      "Shrink model to first 187 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:30:54,899]\u001b[0m Trial 14 finished with value: 0.2915146116490906 and parameters: {'l2_leaf_reg': 22, 'scale_pos_weight': 0.5737782561948421, 'depth': 3, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.1321452451939}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031663\ttest: 0.8337291\tbest: 0.8337291 (0)\ttotal: 45.4ms\tremaining: 2m 16s\n",
      "300:\tlearn: 0.9739637\ttest: 0.9533029\tbest: 0.9533110 (299)\ttotal: 13.1s\tremaining: 1m 57s\n",
      "600:\tlearn: 0.9763149\ttest: 0.9555849\tbest: 0.9555874 (599)\ttotal: 26.3s\tremaining: 1m 44s\n",
      "900:\tlearn: 0.9775365\ttest: 0.9568621\tbest: 0.9568621 (900)\ttotal: 39.6s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9783575\ttest: 0.9574763\tbest: 0.9574808 (1198)\ttotal: 52.9s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9790584\ttest: 0.9577966\tbest: 0.9578047 (1436)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "bestTest = 0.9580512643\n",
      "bestIteration = 1682\n",
      "Shrink model to first 1683 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:32:17,454]\u001b[0m Trial 15 finished with value: 0.39766381938365886 and parameters: {'l2_leaf_reg': 24, 'scale_pos_weight': 0.8048768215101039, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.7227599401952391}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 39.3ms\tremaining: 1m 57s\n",
      "300:\tlearn: 0.9684142\ttest: 0.9437290\tbest: 0.9437290 (300)\ttotal: 11.6s\tremaining: 1m 44s\n",
      "600:\tlearn: 0.9719974\ttest: 0.9499758\tbest: 0.9499758 (600)\ttotal: 23.4s\tremaining: 1m 33s\n",
      "900:\tlearn: 0.9736522\ttest: 0.9523065\tbest: 0.9523070 (899)\ttotal: 34.9s\tremaining: 1m 21s\n",
      "1200:\tlearn: 0.9747583\ttest: 0.9534873\tbest: 0.9535313 (1192)\ttotal: 46.8s\tremaining: 1m 10s\n",
      "1500:\tlearn: 0.9754552\ttest: 0.9541425\tbest: 0.9541955 (1482)\ttotal: 58.4s\tremaining: 58.4s\n",
      "1800:\tlearn: 0.9759056\ttest: 0.9547099\tbest: 0.9547153 (1795)\ttotal: 1m 10s\tremaining: 46.6s\n",
      "2100:\tlearn: 0.9763322\ttest: 0.9553065\tbest: 0.9553088 (2098)\ttotal: 1m 21s\tremaining: 34.9s\n",
      "2400:\tlearn: 0.9766865\ttest: 0.9555533\tbest: 0.9556524 (2317)\ttotal: 1m 33s\tremaining: 23.3s\n",
      "bestTest = 0.9556524158\n",
      "bestIteration = 2317\n",
      "Shrink model to first 2318 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:33:55,388]\u001b[0m Trial 16 finished with value: 0.39124727782584057 and parameters: {'l2_leaf_reg': 24, 'scale_pos_weight': 0.8345027811893638, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.7073583079365747}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031663\ttest: 0.8337291\tbest: 0.8337291 (0)\ttotal: 46ms\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9741412\ttest: 0.9530020\tbest: 0.9530020 (300)\ttotal: 13.2s\tremaining: 1m 58s\n",
      "600:\tlearn: 0.9764947\ttest: 0.9555367\tbest: 0.9555845 (594)\ttotal: 26.4s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9778891\ttest: 0.9566969\tbest: 0.9567854 (887)\ttotal: 39.7s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9787891\ttest: 0.9577678\tbest: 0.9577737 (1195)\ttotal: 52.8s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9794961\ttest: 0.9581258\tbest: 0.9581288 (1496)\ttotal: 1m 6s\tremaining: 1m 5s\n",
      "1800:\tlearn: 0.9800625\ttest: 0.9583187\tbest: 0.9583233 (1793)\ttotal: 1m 19s\tremaining: 52.8s\n",
      "bestTest = 0.9585483372\n",
      "bestIteration = 1958\n",
      "Shrink model to first 1959 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:35:30,082]\u001b[0m Trial 17 finished with value: 0.39397168518800424 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.8398127028914811, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8196695279756145}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9126584\ttest: 0.8442071\tbest: 0.8442071 (0)\ttotal: 47.3ms\tremaining: 2m 21s\n",
      "300:\tlearn: 0.9742554\ttest: 0.9542650\tbest: 0.9542650 (300)\ttotal: 13.4s\tremaining: 2m\n",
      "600:\tlearn: 0.9767866\ttest: 0.9561091\tbest: 0.9561091 (600)\ttotal: 26.7s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9781841\ttest: 0.9572151\tbest: 0.9572151 (900)\ttotal: 40.2s\tremaining: 1m 33s\n",
      "bestTest = 0.9578187168\n",
      "bestIteration = 1066\n",
      "Shrink model to first 1067 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:36:26,229]\u001b[0m Trial 18 finished with value: 0.3981923861111957 and parameters: {'l2_leaf_reg': 1, 'scale_pos_weight': 0.7801392939068643, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5545422225579054}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8399295\ttest: 0.6869946\tbest: 0.6869946 (0)\ttotal: 36.2ms\tremaining: 1m 48s\n",
      "300:\tlearn: 0.9623030\ttest: 0.9326842\tbest: 0.9326842 (300)\ttotal: 10.5s\tremaining: 1m 33s\n",
      "600:\tlearn: 0.9680128\ttest: 0.9429638\tbest: 0.9429638 (600)\ttotal: 21.2s\tremaining: 1m 24s\n",
      "900:\tlearn: 0.9700526\ttest: 0.9461168\tbest: 0.9461168 (900)\ttotal: 31.9s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9713302\ttest: 0.9483443\tbest: 0.9483895 (1196)\ttotal: 42.6s\tremaining: 1m 3s\n",
      "1500:\tlearn: 0.9722239\ttest: 0.9491735\tbest: 0.9491735 (1500)\ttotal: 53.3s\tremaining: 53.2s\n",
      "1800:\tlearn: 0.9729783\ttest: 0.9503165\tbest: 0.9503228 (1797)\ttotal: 1m 4s\tremaining: 42.7s\n",
      "2100:\tlearn: 0.9735557\ttest: 0.9508321\tbest: 0.9508321 (2100)\ttotal: 1m 14s\tremaining: 32s\n",
      "2400:\tlearn: 0.9740325\ttest: 0.9513144\tbest: 0.9513275 (2390)\ttotal: 1m 25s\tremaining: 21.3s\n",
      "2700:\tlearn: 0.9744275\ttest: 0.9515960\tbest: 0.9516268 (2698)\ttotal: 1m 36s\tremaining: 10.7s\n",
      "bestTest = 0.9520988762\n",
      "bestIteration = 2793\n",
      "Shrink model to first 2794 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:38:13,723]\u001b[0m Trial 19 finished with value: 0.38454028118723493 and parameters: {'l2_leaf_reg': 1, 'scale_pos_weight': 0.9947628214609485, 'depth': 2, 'bootstrap_type': 'Bernoulli', 'subsample': 0.524752157917973}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9234194\ttest: 0.8709854\tbest: 0.8709854 (0)\ttotal: 49.1ms\tremaining: 2m 27s\n",
      "300:\tlearn: 0.9750254\ttest: 0.9543995\tbest: 0.9543995 (300)\ttotal: 14.3s\tremaining: 2m 7s\n",
      "600:\tlearn: 0.9776910\ttest: 0.9568758\tbest: 0.9568758 (600)\ttotal: 28.6s\tremaining: 1m 54s\n",
      "900:\tlearn: 0.9789410\ttest: 0.9574718\tbest: 0.9575833 (840)\ttotal: 42.8s\tremaining: 1m 39s\n",
      "bestTest = 0.9575833082\n",
      "bestIteration = 840\n",
      "Shrink model to first 841 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:39:02,144]\u001b[0m Trial 20 finished with value: 0.37623893658633606 and parameters: {'l2_leaf_reg': 8, 'scale_pos_weight': 0.5514477967583212, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5266568833766512}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9126584\ttest: 0.8442002\tbest: 0.8442002 (0)\ttotal: 48.2ms\tremaining: 2m 24s\n",
      "300:\tlearn: 0.9741456\ttest: 0.9537828\tbest: 0.9537828 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9768635\ttest: 0.9568025\tbest: 0.9568120 (596)\ttotal: 26.6s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9780979\ttest: 0.9577454\tbest: 0.9577546 (896)\ttotal: 39.8s\tremaining: 1m 32s\n",
      "bestTest = 0.9581074119\n",
      "bestIteration = 1093\n",
      "Shrink model to first 1094 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:39:58,659]\u001b[0m Trial 21 finished with value: 0.39676285160038793 and parameters: {'l2_leaf_reg': 2, 'scale_pos_weight': 0.7836537103169178, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6761493121111896}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 43.3ms\tremaining: 2m 9s\n",
      "300:\tlearn: 0.9723355\ttest: 0.9504046\tbest: 0.9504046 (300)\ttotal: 12.4s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9751162\ttest: 0.9543611\tbest: 0.9543611 (600)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9764574\ttest: 0.9556984\tbest: 0.9557732 (889)\ttotal: 37s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9772571\ttest: 0.9562605\tbest: 0.9563404 (1132)\ttotal: 49.3s\tremaining: 1m 13s\n",
      "bestTest = 0.9563403726\n",
      "bestIteration = 1132\n",
      "Shrink model to first 1133 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:40:53,116]\u001b[0m Trial 22 finished with value: 0.3977321048901489 and parameters: {'l2_leaf_reg': 5, 'scale_pos_weight': 0.9112214129020194, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.7783806178175924}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 43.2ms\tremaining: 2m 9s\n",
      "300:\tlearn: 0.9723364\ttest: 0.9516361\tbest: 0.9516361 (300)\ttotal: 12.4s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9751289\ttest: 0.9546374\tbest: 0.9546374 (600)\ttotal: 24.6s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9765677\ttest: 0.9561885\tbest: 0.9561885 (900)\ttotal: 37.1s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9773665\ttest: 0.9567185\tbest: 0.9567429 (1153)\ttotal: 49.4s\tremaining: 1m 13s\n",
      "1500:\tlearn: 0.9780781\ttest: 0.9572171\tbest: 0.9572560 (1494)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "bestTest = 0.9577786326\n",
      "bestIteration = 1676\n",
      "Shrink model to first 1677 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:42:10,330]\u001b[0m Trial 23 finished with value: 0.40140148871830655 and parameters: {'l2_leaf_reg': 5, 'scale_pos_weight': 0.9110859189449863, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8684403874667421}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 40.4ms\tremaining: 2m 1s\n",
      "300:\tlearn: 0.9722524\ttest: 0.9507123\tbest: 0.9507123 (300)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9751447\ttest: 0.9547627\tbest: 0.9547818 (598)\ttotal: 24.9s\tremaining: 1m 39s\n",
      "900:\tlearn: 0.9765602\ttest: 0.9563880\tbest: 0.9563919 (897)\ttotal: 37.4s\tremaining: 1m 27s\n",
      "1200:\tlearn: 0.9774079\ttest: 0.9571216\tbest: 0.9571301 (1192)\ttotal: 49.9s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9780905\ttest: 0.9576007\tbest: 0.9576072 (1488)\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "bestTest = 0.9576071799\n",
      "bestIteration = 1488\n",
      "Shrink model to first 1489 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:43:20,026]\u001b[0m Trial 24 finished with value: 0.40024790291430057 and parameters: {'l2_leaf_reg': 4, 'scale_pos_weight': 0.915210464006596, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9471568404883854}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8399295\ttest: 0.6869946\tbest: 0.6869946 (0)\ttotal: 36.1ms\tremaining: 1m 48s\n",
      "300:\tlearn: 0.9621427\ttest: 0.9333911\tbest: 0.9333911 (300)\ttotal: 10.5s\tremaining: 1m 33s\n",
      "600:\tlearn: 0.9677955\ttest: 0.9433400\tbest: 0.9433400 (600)\ttotal: 21.2s\tremaining: 1m 24s\n",
      "900:\tlearn: 0.9699895\ttest: 0.9461085\tbest: 0.9461093 (899)\ttotal: 31.9s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9712375\ttest: 0.9475465\tbest: 0.9475473 (1199)\ttotal: 42.6s\tremaining: 1m 3s\n",
      "1500:\tlearn: 0.9721440\ttest: 0.9487515\tbest: 0.9487790 (1490)\ttotal: 53.4s\tremaining: 53.3s\n",
      "1800:\tlearn: 0.9728138\ttest: 0.9495914\tbest: 0.9495928 (1799)\ttotal: 1m 4s\tremaining: 42.7s\n",
      "2100:\tlearn: 0.9734197\ttest: 0.9502938\tbest: 0.9502969 (2093)\ttotal: 1m 14s\tremaining: 32.1s\n",
      "2400:\tlearn: 0.9739312\ttest: 0.9507554\tbest: 0.9507774 (2374)\ttotal: 1m 25s\tremaining: 21.4s\n",
      "2700:\tlearn: 0.9742430\ttest: 0.9511957\tbest: 0.9512025 (2696)\ttotal: 1m 36s\tremaining: 10.7s\n",
      "bestTest = 0.9512025118\n",
      "bestIteration = 2696\n",
      "Shrink model to first 2697 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:45:03,937]\u001b[0m Trial 25 finished with value: 0.38138921618133875 and parameters: {'l2_leaf_reg': 10, 'scale_pos_weight': 0.9316481645770593, 'depth': 2, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9749305446858303}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9078657\ttest: 0.8416031\tbest: 0.8416031 (0)\ttotal: 41.5ms\tremaining: 2m 4s\n",
      "300:\tlearn: 0.9686506\ttest: 0.9458995\tbest: 0.9458995 (300)\ttotal: 12.2s\tremaining: 1m 49s\n",
      "600:\tlearn: 0.9721776\ttest: 0.9513946\tbest: 0.9514304 (593)\ttotal: 24.5s\tremaining: 1m 37s\n",
      "900:\tlearn: 0.9736682\ttest: 0.9531564\tbest: 0.9531599 (899)\ttotal: 36.9s\tremaining: 1m 25s\n",
      "1200:\tlearn: 0.9746760\ttest: 0.9544419\tbest: 0.9544475 (1186)\ttotal: 49.2s\tremaining: 1m 13s\n",
      "1500:\tlearn: 0.9753589\ttest: 0.9555641\tbest: 0.9555815 (1470)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "bestTest = 0.9557237625\n",
      "bestIteration = 1624\n",
      "Shrink model to first 1625 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:46:18,540]\u001b[0m Trial 26 finished with value: 0.3005334914048607 and parameters: {'l2_leaf_reg': 5, 'scale_pos_weight': 0.26130133268505906, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8923564271078923}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8690594\ttest: 0.7805253\tbest: 0.7805253 (0)\ttotal: 37.8ms\tremaining: 1m 53s\n",
      "300:\tlearn: 0.9675920\ttest: 0.9436608\tbest: 0.9436799 (299)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "600:\tlearn: 0.9719376\ttest: 0.9501185\tbest: 0.9501198 (594)\ttotal: 23s\tremaining: 1m 31s\n",
      "900:\tlearn: 0.9737245\ttest: 0.9519578\tbest: 0.9520224 (848)\ttotal: 34.6s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9747250\ttest: 0.9539067\tbest: 0.9539126 (1198)\ttotal: 46.1s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.9753564\ttest: 0.9547300\tbest: 0.9547346 (1496)\ttotal: 57.6s\tremaining: 57.6s\n",
      "1800:\tlearn: 0.9758318\ttest: 0.9551554\tbest: 0.9551667 (1796)\ttotal: 1m 9s\tremaining: 46s\n",
      "2100:\tlearn: 0.9762147\ttest: 0.9555243\tbest: 0.9555298 (2093)\ttotal: 1m 20s\tremaining: 34.4s\n",
      "2400:\tlearn: 0.9765720\ttest: 0.9559504\tbest: 0.9559506 (2399)\ttotal: 1m 32s\tremaining: 23s\n",
      "bestTest = 0.9561118484\n",
      "bestIteration = 2585\n",
      "Shrink model to first 2586 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:48:05,590]\u001b[0m Trial 27 finished with value: 0.3858029553546111 and parameters: {'l2_leaf_reg': 8, 'scale_pos_weight': 0.6510569297124121, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8853862400040974}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8399295\ttest: 0.6869946\tbest: 0.6869946 (0)\ttotal: 31.6ms\tremaining: 1m 34s\n",
      "300:\tlearn: 0.9602008\ttest: 0.9307922\tbest: 0.9308051 (298)\ttotal: 8.94s\tremaining: 1m 20s\n",
      "600:\tlearn: 0.9633960\ttest: 0.9356607\tbest: 0.9356607 (600)\ttotal: 18.1s\tremaining: 1m 12s\n",
      "900:\tlearn: 0.9650497\ttest: 0.9389119\tbest: 0.9389119 (900)\ttotal: 27.2s\tremaining: 1m 3s\n",
      "1200:\tlearn: 0.9665207\ttest: 0.9411603\tbest: 0.9411676 (1188)\ttotal: 36.3s\tremaining: 54.4s\n",
      "1500:\tlearn: 0.9671418\ttest: 0.9419917\tbest: 0.9419956 (1497)\ttotal: 45.6s\tremaining: 45.5s\n",
      "bestTest = 0.9420061707\n",
      "bestIteration = 1513\n",
      "Shrink model to first 1514 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:48:58,669]\u001b[0m Trial 28 finished with value: 0.36787663236771373 and parameters: {'l2_leaf_reg': 13, 'scale_pos_weight': 0.8860180128345473, 'depth': 2, 'bootstrap_type': 'Bernoulli', 'subsample': 0.12146661239566131}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9234123\ttest: 0.8721794\tbest: 0.8721794 (0)\ttotal: 51.4ms\tremaining: 2m 34s\n",
      "300:\tlearn: 0.9752705\ttest: 0.9555877\tbest: 0.9555877 (300)\ttotal: 14.2s\tremaining: 2m 7s\n",
      "600:\tlearn: 0.9775762\ttest: 0.9571674\tbest: 0.9571674 (600)\ttotal: 28.2s\tremaining: 1m 52s\n",
      "bestTest = 0.9573537707\n",
      "bestIteration = 754\n",
      "Shrink model to first 755 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:49:42,502]\u001b[0m Trial 29 finished with value: 0.36513928664410306 and parameters: {'l2_leaf_reg': 11, 'scale_pos_weight': 0.610065970453477, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8773723481715814}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9474549\ttest: 0.8808801\tbest: 0.8808801 (0)\ttotal: 59.5ms\tremaining: 2m 58s\n",
      "300:\tlearn: 0.9790711\ttest: 0.9565106\tbest: 0.9566727 (271)\ttotal: 16.9s\tremaining: 2m 31s\n",
      "bestTest = 0.9572156966\n",
      "bestIteration = 406\n",
      "Shrink model to first 407 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:50:14,695]\u001b[0m Trial 30 finished with value: 0.37872248597324126 and parameters: {'l2_leaf_reg': 3, 'scale_pos_weight': 0.7542115273492197, 'depth': 8, 'bootstrap_type': 'Bernoulli', 'subsample': 0.606652305957555}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 39.9ms\tremaining: 1m 59s\n",
      "300:\tlearn: 0.9722773\ttest: 0.9510470\tbest: 0.9510470 (300)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9752444\ttest: 0.9547423\tbest: 0.9547423 (600)\ttotal: 24.7s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9766501\ttest: 0.9557819\tbest: 0.9557819 (900)\ttotal: 36.9s\tremaining: 1m 25s\n",
      "1200:\tlearn: 0.9775977\ttest: 0.9563539\tbest: 0.9563845 (1191)\ttotal: 49.2s\tremaining: 1m 13s\n",
      "bestTest = 0.956438154\n",
      "bestIteration = 1212\n",
      "Shrink model to first 1213 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:51:12,203]\u001b[0m Trial 31 finished with value: 0.39605247948214084 and parameters: {'l2_leaf_reg': 1, 'scale_pos_weight': 0.9521391757076286, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5757363779036562}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031668\ttest: 0.8318245\tbest: 0.8318245 (0)\ttotal: 44.8ms\tremaining: 2m 14s\n",
      "300:\tlearn: 0.9743621\ttest: 0.9525697\tbest: 0.9526048 (297)\ttotal: 13.1s\tremaining: 1m 57s\n",
      "600:\tlearn: 0.9768650\ttest: 0.9559979\tbest: 0.9560320 (592)\ttotal: 26.5s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9781062\ttest: 0.9565623\tbest: 0.9565957 (868)\ttotal: 39.7s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9790033\ttest: 0.9576885\tbest: 0.9576945 (1195)\ttotal: 52.9s\tremaining: 1m 19s\n",
      "bestTest = 0.9578019083\n",
      "bestIteration = 1341\n",
      "Shrink model to first 1342 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:52:19,575]\u001b[0m Trial 32 finished with value: 0.38988236692015205 and parameters: {'l2_leaf_reg': 7, 'scale_pos_weight': 0.869569539962804, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.4677548971739798}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8922141\ttest: 0.8233845\tbest: 0.8233845 (0)\ttotal: 43.1ms\tremaining: 2m 9s\n",
      "300:\tlearn: 0.9723225\ttest: 0.9504712\tbest: 0.9504883 (296)\ttotal: 12.6s\tremaining: 1m 52s\n",
      "600:\tlearn: 0.9750633\ttest: 0.9537535\tbest: 0.9537736 (596)\ttotal: 25.2s\tremaining: 1m 40s\n",
      "900:\tlearn: 0.9763017\ttest: 0.9550937\tbest: 0.9551060 (895)\ttotal: 37.6s\tremaining: 1m 27s\n",
      "1200:\tlearn: 0.9772082\ttest: 0.9561139\tbest: 0.9561139 (1200)\ttotal: 49.9s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9779179\ttest: 0.9566689\tbest: 0.9567060 (1494)\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "bestTest = 0.9567059875\n",
      "bestIteration = 1494\n",
      "Shrink model to first 1495 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:53:29,563]\u001b[0m Trial 33 finished with value: 0.39542435424354244 and parameters: {'l2_leaf_reg': 5, 'scale_pos_weight': 0.8092043313648272, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8019857986441689}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9222296\ttest: 0.8548630\tbest: 0.8548630 (0)\ttotal: 49.1ms\tremaining: 2m 27s\n",
      "300:\tlearn: 0.9760650\ttest: 0.9566808\tbest: 0.9566808 (300)\ttotal: 14.2s\tremaining: 2m 7s\n",
      "600:\tlearn: 0.9786882\ttest: 0.9579427\tbest: 0.9581991 (551)\ttotal: 28.3s\tremaining: 1m 53s\n",
      "bestTest = 0.9581990838\n",
      "bestIteration = 551\n",
      "Shrink model to first 552 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:54:04,009]\u001b[0m Trial 34 finished with value: 0.39776222137605804 and parameters: {'l2_leaf_reg': 2, 'scale_pos_weight': 0.8896754613631772, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9387810240769976}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9079262\ttest: 0.8416031\tbest: 0.8416031 (0)\ttotal: 46.3ms\tremaining: 2m 18s\n",
      "300:\tlearn: 0.9716860\ttest: 0.9502002\tbest: 0.9502002 (300)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9744521\ttest: 0.9540983\tbest: 0.9541184 (595)\ttotal: 24.7s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9759482\ttest: 0.9554111\tbest: 0.9554206 (887)\ttotal: 37s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9767732\ttest: 0.9557026\tbest: 0.9557230 (1143)\ttotal: 49.3s\tremaining: 1m 13s\n",
      "bestTest = 0.9557229578\n",
      "bestIteration = 1143\n",
      "Shrink model to first 1144 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:54:58,947]\u001b[0m Trial 35 finished with value: 0.39305386985342167 and parameters: {'l2_leaf_reg': 4, 'scale_pos_weight': 0.6576206874749891, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.598927499911905}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9471604\ttest: 0.8991181\tbest: 0.8991181 (0)\ttotal: 61.9ms\tremaining: 3m 5s\n",
      "300:\tlearn: 0.9780105\ttest: 0.9554234\tbest: 0.9554234 (300)\ttotal: 16.9s\tremaining: 2m 31s\n",
      "600:\tlearn: 0.9808482\ttest: 0.9574448\tbest: 0.9574448 (600)\ttotal: 33.7s\tremaining: 2m 14s\n",
      "900:\tlearn: 0.9825958\ttest: 0.9582906\tbest: 0.9584593 (873)\ttotal: 50.6s\tremaining: 1m 57s\n",
      "bestTest = 0.9584592879\n",
      "bestIteration = 873\n",
      "Shrink model to first 874 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:55:57,553]\u001b[0m Trial 36 finished with value: 0.3827156609828226 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.7535941583088897, 'depth': 8, 'bootstrap_type': 'Bernoulli', 'subsample': 0.7543252482353681}. Best is trial 3 with value: 0.403339978619514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031668\ttest: 0.8318245\tbest: 0.8318245 (0)\ttotal: 45ms\tremaining: 2m 15s\n",
      "300:\tlearn: 0.9746592\ttest: 0.9552747\tbest: 0.9552747 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9770817\ttest: 0.9578783\tbest: 0.9578783 (600)\ttotal: 26.6s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9784050\ttest: 0.9586794\tbest: 0.9586904 (853)\ttotal: 39.8s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9793416\ttest: 0.9591722\tbest: 0.9591750 (1198)\ttotal: 53.2s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9800884\ttest: 0.9592142\tbest: 0.9592844 (1437)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "bestTest = 0.9592843652\n",
      "bestIteration = 1437\n",
      "Shrink model to first 1438 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:57:09,337]\u001b[0m Trial 37 finished with value: 0.4035458732871751 and parameters: {'l2_leaf_reg': 6, 'scale_pos_weight': 0.953249576216302, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6381586108274898}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 40.5ms\tremaining: 2m 1s\n",
      "300:\tlearn: 0.9692340\ttest: 0.9463817\tbest: 0.9463817 (300)\ttotal: 11.5s\tremaining: 1m 42s\n",
      "600:\tlearn: 0.9727551\ttest: 0.9511705\tbest: 0.9511932 (597)\ttotal: 23.1s\tremaining: 1m 32s\n",
      "900:\tlearn: 0.9743642\ttest: 0.9531913\tbest: 0.9531913 (900)\ttotal: 34.7s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9752013\ttest: 0.9539354\tbest: 0.9539654 (1190)\ttotal: 46.1s\tremaining: 1m 9s\n",
      "bestTest = 0.9539723694\n",
      "bestIteration = 1208\n",
      "Shrink model to first 1209 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:58:03,499]\u001b[0m Trial 38 finished with value: 0.3937996908127208 and parameters: {'l2_leaf_reg': 9, 'scale_pos_weight': 0.9549006833510368, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8301004474649415}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8399295\ttest: 0.6869946\tbest: 0.6869946 (0)\ttotal: 34.5ms\tremaining: 1m 43s\n",
      "300:\tlearn: 0.9595287\ttest: 0.9265143\tbest: 0.9265299 (299)\ttotal: 10.2s\tremaining: 1m 31s\n",
      "600:\tlearn: 0.9661079\ttest: 0.9378435\tbest: 0.9378435 (600)\ttotal: 20.9s\tremaining: 1m 23s\n",
      "900:\tlearn: 0.9686990\ttest: 0.9423993\tbest: 0.9424033 (899)\ttotal: 31.5s\tremaining: 1m 13s\n",
      "1200:\tlearn: 0.9698711\ttest: 0.9443145\tbest: 0.9443181 (1199)\ttotal: 42.2s\tremaining: 1m 3s\n",
      "1500:\tlearn: 0.9707444\ttest: 0.9456522\tbest: 0.9456522 (1500)\ttotal: 52.9s\tremaining: 52.9s\n",
      "1800:\tlearn: 0.9715089\ttest: 0.9465412\tbest: 0.9466041 (1771)\ttotal: 1m 3s\tremaining: 42.5s\n",
      "2100:\tlearn: 0.9720902\ttest: 0.9470581\tbest: 0.9470682 (2086)\ttotal: 1m 14s\tremaining: 31.9s\n",
      "2400:\tlearn: 0.9724753\ttest: 0.9473977\tbest: 0.9474394 (2387)\ttotal: 1m 25s\tremaining: 21.3s\n",
      "2700:\tlearn: 0.9728307\ttest: 0.9477313\tbest: 0.9477330 (2669)\ttotal: 1m 36s\tremaining: 10.6s\n",
      "bestTest = 0.9481016397\n",
      "bestIteration = 2850\n",
      "Shrink model to first 2851 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 18:59:52,795]\u001b[0m Trial 39 finished with value: 0.2682471532574202 and parameters: {'l2_leaf_reg': 6, 'scale_pos_weight': 0.48253676581485755, 'depth': 2, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6371132004986494}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9240405\ttest: 0.8729766\tbest: 0.8729766 (0)\ttotal: 53.1ms\tremaining: 2m 39s\n",
      "300:\tlearn: 0.9616202\ttest: 0.9292141\tbest: 0.9292243 (297)\ttotal: 14.5s\tremaining: 2m 10s\n",
      "600:\tlearn: 0.9661467\ttest: 0.9360988\tbest: 0.9360988 (600)\ttotal: 29.1s\tremaining: 1m 55s\n",
      "900:\tlearn: 0.9690855\ttest: 0.9397675\tbest: 0.9397867 (896)\ttotal: 43.8s\tremaining: 1m 42s\n",
      "1200:\tlearn: 0.9710106\ttest: 0.9416650\tbest: 0.9416650 (1200)\ttotal: 58.6s\tremaining: 1m 27s\n",
      "1500:\tlearn: 0.9728581\ttest: 0.9447950\tbest: 0.9447950 (1500)\ttotal: 1m 13s\tremaining: 1m 13s\n",
      "1800:\tlearn: 0.9738930\ttest: 0.9461004\tbest: 0.9461004 (1800)\ttotal: 1m 27s\tremaining: 58.6s\n",
      "2100:\tlearn: 0.9749322\ttest: 0.9474562\tbest: 0.9474926 (2078)\ttotal: 1m 42s\tremaining: 44s\n",
      "2400:\tlearn: 0.9762064\ttest: 0.9484024\tbest: 0.9484158 (2396)\ttotal: 1m 57s\tremaining: 29.4s\n",
      "2700:\tlearn: 0.9769590\ttest: 0.9491304\tbest: 0.9491403 (2699)\ttotal: 2m 12s\tremaining: 14.7s\n",
      "2999:\tlearn: 0.9776399\ttest: 0.9498031\tbest: 0.9498064 (2987)\ttotal: 2m 27s\tremaining: 0us\n",
      "bestTest = 0.949806422\n",
      "bestIteration = 2987\n",
      "Shrink model to first 2988 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:02:24,430]\u001b[0m Trial 40 finished with value: 0.36766075181569075 and parameters: {'l2_leaf_reg': 20, 'scale_pos_weight': 0.8604209123936365, 'depth': 7, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.324971139818878}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9019926\ttest: 0.8310483\tbest: 0.8310483 (0)\ttotal: 46.6ms\tremaining: 2m 19s\n",
      "300:\tlearn: 0.9747801\ttest: 0.9553004\tbest: 0.9554002 (293)\ttotal: 13.9s\tremaining: 2m 4s\n",
      "600:\tlearn: 0.9772222\ttest: 0.9574465\tbest: 0.9574541 (598)\ttotal: 27.3s\tremaining: 1m 48s\n",
      "bestTest = 0.9579055011\n",
      "bestIteration = 728\n",
      "Shrink model to first 729 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:03:05,570]\u001b[0m Trial 41 finished with value: 0.3952636998055143 and parameters: {'l2_leaf_reg': 3, 'scale_pos_weight': 0.995512216616084, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3561677605063057}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9222277\ttest: 0.8610519\tbest: 0.8610519 (0)\ttotal: 48.3ms\tremaining: 2m 24s\n",
      "300:\tlearn: 0.9762215\ttest: 0.9554547\tbest: 0.9554700 (299)\ttotal: 14.5s\tremaining: 2m 10s\n",
      "600:\tlearn: 0.9787607\ttest: 0.9575038\tbest: 0.9575038 (600)\ttotal: 28.7s\tremaining: 1m 54s\n",
      "900:\tlearn: 0.9801094\ttest: 0.9580351\tbest: 0.9580351 (900)\ttotal: 42.7s\tremaining: 1m 39s\n",
      "bestTest = 0.9581897259\n",
      "bestIteration = 986\n",
      "Shrink model to first 987 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:04:00,976]\u001b[0m Trial 42 finished with value: 0.37966557181248134 and parameters: {'l2_leaf_reg': 6, 'scale_pos_weight': 0.9276179588518458, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.48845925015292274}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031668\ttest: 0.8318245\tbest: 0.8318245 (0)\ttotal: 45.7ms\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9744244\ttest: 0.9555635\tbest: 0.9556108 (298)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9769803\ttest: 0.9576249\tbest: 0.9576249 (600)\ttotal: 26.5s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9783891\ttest: 0.9586103\tbest: 0.9586103 (900)\ttotal: 39.8s\tremaining: 1m 32s\n",
      "bestTest = 0.9588854313\n",
      "bestIteration = 1045\n",
      "Shrink model to first 1046 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:04:55,375]\u001b[0m Trial 43 finished with value: 0.4000936576228525 and parameters: {'l2_leaf_reg': 3, 'scale_pos_weight': 0.9063436719401089, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9444774389996989}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 40.8ms\tremaining: 2m 2s\n",
      "300:\tlearn: 0.9718594\ttest: 0.9499253\tbest: 0.9499253 (300)\ttotal: 12.4s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9748358\ttest: 0.9543685\tbest: 0.9543685 (600)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9763868\ttest: 0.9555514\tbest: 0.9555514 (900)\ttotal: 37.1s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9772923\ttest: 0.9564668\tbest: 0.9564960 (1189)\ttotal: 49.6s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9779846\ttest: 0.9567901\tbest: 0.9568457 (1423)\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "bestTest = 0.9568456709\n",
      "bestIteration = 1423\n",
      "Shrink model to first 1424 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:06:02,228]\u001b[0m Trial 44 finished with value: 0.3953737789501145 and parameters: {'l2_leaf_reg': 3, 'scale_pos_weight': 0.9060720732034824, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9340816629748437}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 40.1ms\tremaining: 2m\n",
      "300:\tlearn: 0.9686305\ttest: 0.9433201\tbest: 0.9433201 (300)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "600:\tlearn: 0.9726603\ttest: 0.9498477\tbest: 0.9498477 (600)\ttotal: 22.9s\tremaining: 1m 31s\n",
      "900:\tlearn: 0.9742284\ttest: 0.9519725\tbest: 0.9519744 (899)\ttotal: 34.4s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9751942\ttest: 0.9527956\tbest: 0.9527962 (1198)\ttotal: 46s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.9758283\ttest: 0.9533050\tbest: 0.9533287 (1450)\ttotal: 57.4s\tremaining: 57.3s\n",
      "1800:\tlearn: 0.9763748\ttest: 0.9539039\tbest: 0.9539088 (1782)\ttotal: 1m 8s\tremaining: 45.9s\n",
      "2100:\tlearn: 0.9767956\ttest: 0.9543494\tbest: 0.9543494 (2100)\ttotal: 1m 20s\tremaining: 34.4s\n",
      "bestTest = 0.9543857872\n",
      "bestIteration = 2127\n",
      "Shrink model to first 2128 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:07:31,573]\u001b[0m Trial 45 finished with value: 0.3932505140989887 and parameters: {'l2_leaf_reg': 7, 'scale_pos_weight': 0.9582652003840286, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9309723484223692}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8818070\ttest: 0.7988023\tbest: 0.7988023 (0)\ttotal: 39.1ms\tremaining: 1m 57s\n",
      "300:\tlearn: 0.9538257\ttest: 0.9181370\tbest: 0.9181370 (300)\ttotal: 12s\tremaining: 1m 47s\n",
      "600:\tlearn: 0.9590169\ttest: 0.9259096\tbest: 0.9259210 (599)\ttotal: 23.9s\tremaining: 1m 35s\n",
      "900:\tlearn: 0.9620432\ttest: 0.9312397\tbest: 0.9312397 (900)\ttotal: 35.9s\tremaining: 1m 23s\n",
      "1200:\tlearn: 0.9635933\ttest: 0.9334068\tbest: 0.9334068 (1200)\ttotal: 48s\tremaining: 1m 11s\n",
      "1500:\tlearn: 0.9648915\ttest: 0.9354429\tbest: 0.9354429 (1500)\ttotal: 1m\tremaining: 1m\n",
      "1800:\tlearn: 0.9660380\ttest: 0.9369898\tbest: 0.9370225 (1778)\ttotal: 1m 12s\tremaining: 48.2s\n",
      "2100:\tlearn: 0.9668163\ttest: 0.9382371\tbest: 0.9382437 (2099)\ttotal: 1m 24s\tremaining: 36.1s\n",
      "2400:\tlearn: 0.9677294\ttest: 0.9400242\tbest: 0.9400285 (2399)\ttotal: 1m 36s\tremaining: 24.1s\n",
      "2700:\tlearn: 0.9682520\ttest: 0.9409259\tbest: 0.9409304 (2699)\ttotal: 1m 48s\tremaining: 12s\n",
      "2999:\tlearn: 0.9688214\ttest: 0.9416094\tbest: 0.9416094 (2999)\ttotal: 2m\tremaining: 0us\n",
      "bestTest = 0.9416093528\n",
      "bestIteration = 2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:09:36,300]\u001b[0m Trial 46 finished with value: 0.1984126984126984 and parameters: {'l2_leaf_reg': 28, 'scale_pos_weight': 0.32613614002141844, 'depth': 4, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.8894176065400083}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8416063\ttest: 0.6852033\tbest: 0.6852033 (0)\ttotal: 78.2ms\tremaining: 3m 54s\n",
      "bestTest = 0.9297709763\n",
      "bestIteration = 49\n",
      "Shrink model to first 50 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:09:49,919]\u001b[0m Trial 47 finished with value: 0.0010309809784009485 and parameters: {'l2_leaf_reg': 4, 'scale_pos_weight': 0.021045966988906484, 'depth': 11, 'bootstrap_type': 'Bernoulli', 'subsample': 0.8516845893016309}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9362343\ttest: 0.8847980\tbest: 0.8847980 (0)\ttotal: 55.4ms\tremaining: 2m 46s\n",
      "300:\tlearn: 0.9730535\ttest: 0.9500906\tbest: 0.9500906 (300)\ttotal: 16.7s\tremaining: 2m 29s\n",
      "600:\tlearn: 0.9752775\ttest: 0.9530715\tbest: 0.9530715 (600)\ttotal: 32.3s\tremaining: 2m 9s\n",
      "900:\tlearn: 0.9766948\ttest: 0.9546154\tbest: 0.9546389 (898)\ttotal: 48.9s\tremaining: 1m 53s\n",
      "1200:\tlearn: 0.9776418\ttest: 0.9556015\tbest: 0.9556015 (1200)\ttotal: 1m 4s\tremaining: 1m 37s\n",
      "bestTest = 0.9558785558\n",
      "bestIteration = 1266\n",
      "Shrink model to first 1267 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:11:07,988]\u001b[0m Trial 48 finished with value: 0.09978034303874375 and parameters: {'l2_leaf_reg': 12, 'scale_pos_weight': 0.12364035256225347, 'depth': 8, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9803100801062515}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8977554\ttest: 0.8524145\tbest: 0.8524145 (0)\ttotal: 45.7ms\tremaining: 2m 16s\n",
      "300:\tlearn: 0.9573283\ttest: 0.9235373\tbest: 0.9235381 (298)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9612657\ttest: 0.9293688\tbest: 0.9293688 (600)\ttotal: 25.2s\tremaining: 1m 40s\n",
      "900:\tlearn: 0.9636500\ttest: 0.9328597\tbest: 0.9328928 (897)\ttotal: 37.9s\tremaining: 1m 28s\n",
      "1200:\tlearn: 0.9658331\ttest: 0.9355671\tbest: 0.9355967 (1188)\ttotal: 50.8s\tremaining: 1m 16s\n",
      "1500:\tlearn: 0.9670745\ttest: 0.9377960\tbest: 0.9377960 (1500)\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "1800:\tlearn: 0.9679058\ttest: 0.9394138\tbest: 0.9394214 (1790)\ttotal: 1m 16s\tremaining: 50.9s\n",
      "2100:\tlearn: 0.9690158\ttest: 0.9411293\tbest: 0.9411361 (2094)\ttotal: 1m 29s\tremaining: 38.4s\n",
      "2400:\tlearn: 0.9702446\ttest: 0.9423236\tbest: 0.9423236 (2400)\ttotal: 1m 42s\tremaining: 25.6s\n",
      "2700:\tlearn: 0.9710617\ttest: 0.9439106\tbest: 0.9439221 (2697)\ttotal: 1m 55s\tremaining: 12.8s\n",
      "2999:\tlearn: 0.9717907\ttest: 0.9449902\tbest: 0.9450129 (2979)\ttotal: 2m 8s\tremaining: 0us\n",
      "bestTest = 0.9450128973\n",
      "bestIteration = 2979\n",
      "Shrink model to first 2980 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:13:20,539]\u001b[0m Trial 49 finished with value: 0.3646547486611647 and parameters: {'l2_leaf_reg': 9, 'scale_pos_weight': 0.8294757595344665, 'depth': 5, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.512926340724212}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9235290\ttest: 0.8729623\tbest: 0.8729623 (0)\ttotal: 50.6ms\tremaining: 2m 31s\n",
      "300:\tlearn: 0.9751712\ttest: 0.9530806\tbest: 0.9530980 (299)\ttotal: 14.4s\tremaining: 2m 9s\n",
      "600:\tlearn: 0.9776957\ttest: 0.9557438\tbest: 0.9557444 (593)\ttotal: 28.5s\tremaining: 1m 53s\n",
      "bestTest = 0.9561280012\n",
      "bestIteration = 686\n",
      "Shrink model to first 687 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:14:01,689]\u001b[0m Trial 50 finished with value: 0.3805693069306931 and parameters: {'l2_leaf_reg': 19, 'scale_pos_weight': 0.7209078146767627, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9976342870450038}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9126590\ttest: 0.8442071\tbest: 0.8442071 (0)\ttotal: 48.3ms\tremaining: 2m 24s\n",
      "300:\tlearn: 0.9742553\ttest: 0.9540207\tbest: 0.9540207 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9770101\ttest: 0.9569846\tbest: 0.9570742 (586)\ttotal: 26.8s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9783211\ttest: 0.9578910\tbest: 0.9578910 (900)\ttotal: 40s\tremaining: 1m 33s\n",
      "bestTest = 0.9580859542\n",
      "bestIteration = 1023\n",
      "Shrink model to first 1024 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:14:55,327]\u001b[0m Trial 51 finished with value: 0.39404869251578 and parameters: {'l2_leaf_reg': 1, 'scale_pos_weight': 0.7880075569243141, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.4242566569033805}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031668\ttest: 0.8318245\tbest: 0.8318245 (0)\ttotal: 46ms\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9744668\ttest: 0.9540381\tbest: 0.9540743 (296)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9770462\ttest: 0.9560096\tbest: 0.9561003 (585)\ttotal: 26.5s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9783386\ttest: 0.9567928\tbest: 0.9567940 (899)\ttotal: 39.8s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9793136\ttest: 0.9572567\tbest: 0.9572749 (1186)\ttotal: 53.1s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9801169\ttest: 0.9574711\tbest: 0.9574896 (1479)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "1800:\tlearn: 0.9808904\ttest: 0.9577799\tbest: 0.9577840 (1797)\ttotal: 1m 19s\tremaining: 53.1s\n",
      "bestTest = 0.9578051567\n",
      "bestIteration = 1812\n",
      "Shrink model to first 1813 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:16:24,076]\u001b[0m Trial 52 finished with value: 0.38350721824578426 and parameters: {'l2_leaf_reg': 2, 'scale_pos_weight': 0.8631355539589337, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6619810649012684}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 40.3ms\tremaining: 2m\n",
      "300:\tlearn: 0.9691012\ttest: 0.9463080\tbest: 0.9463080 (300)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "600:\tlearn: 0.9726427\ttest: 0.9514466\tbest: 0.9514559 (598)\ttotal: 22.9s\tremaining: 1m 31s\n",
      "900:\tlearn: 0.9744032\ttest: 0.9533229\tbest: 0.9533533 (892)\ttotal: 34.5s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9752676\ttest: 0.9539772\tbest: 0.9539772 (1200)\ttotal: 46.1s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.9760187\ttest: 0.9545747\tbest: 0.9546398 (1442)\ttotal: 57.7s\tremaining: 57.6s\n",
      "1800:\tlearn: 0.9765355\ttest: 0.9553410\tbest: 0.9553642 (1788)\ttotal: 1m 9s\tremaining: 46.1s\n",
      "2100:\tlearn: 0.9769788\ttest: 0.9554935\tbest: 0.9554935 (2100)\ttotal: 1m 20s\tremaining: 34.6s\n",
      "2400:\tlearn: 0.9773656\ttest: 0.9557627\tbest: 0.9557678 (2395)\ttotal: 1m 32s\tremaining: 23s\n",
      "bestTest = 0.9558359087\n",
      "bestIteration = 2517\n",
      "Shrink model to first 2518 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:18:08,765]\u001b[0m Trial 53 finished with value: 0.39357897127285113 and parameters: {'l2_leaf_reg': 4, 'scale_pos_weight': 0.9683941618667313, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.7315305102289144}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 42.6ms\tremaining: 2m 7s\n",
      "300:\tlearn: 0.9726887\ttest: 0.9508294\tbest: 0.9508387 (298)\ttotal: 12.5s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9752005\ttest: 0.9550800\tbest: 0.9550800 (600)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9764967\ttest: 0.9563939\tbest: 0.9564174 (864)\ttotal: 37.3s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9773038\ttest: 0.9571871\tbest: 0.9572004 (1169)\ttotal: 49.6s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9780114\ttest: 0.9578364\tbest: 0.9578387 (1498)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1800:\tlearn: 0.9785631\ttest: 0.9580591\tbest: 0.9580633 (1798)\ttotal: 1m 14s\tremaining: 49.6s\n",
      "2100:\tlearn: 0.9791185\ttest: 0.9583544\tbest: 0.9584495 (2002)\ttotal: 1m 26s\tremaining: 37.2s\n",
      "bestTest = 0.9584495127\n",
      "bestIteration = 2002\n",
      "Shrink model to first 2003 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:19:39,621]\u001b[0m Trial 54 finished with value: 0.40156794425087106 and parameters: {'l2_leaf_reg': 6, 'scale_pos_weight': 0.9125567636686751, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.553511807592026}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 38.7ms\tremaining: 1m 55s\n",
      "300:\tlearn: 0.9723896\ttest: 0.9509584\tbest: 0.9509584 (300)\ttotal: 12.4s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9749384\ttest: 0.9539059\tbest: 0.9539059 (600)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9762396\ttest: 0.9550233\tbest: 0.9550578 (882)\ttotal: 37.2s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9772332\ttest: 0.9559153\tbest: 0.9559410 (1165)\ttotal: 49.7s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9779502\ttest: 0.9569583\tbest: 0.9569629 (1499)\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "1800:\tlearn: 0.9784346\ttest: 0.9572023\tbest: 0.9572070 (1799)\ttotal: 1m 14s\tremaining: 49.9s\n",
      "2100:\tlearn: 0.9788836\ttest: 0.9576406\tbest: 0.9576618 (2078)\ttotal: 1m 27s\tremaining: 37.4s\n",
      "2400:\tlearn: 0.9793107\ttest: 0.9579835\tbest: 0.9580014 (2386)\ttotal: 1m 39s\tremaining: 24.9s\n",
      "2700:\tlearn: 0.9797167\ttest: 0.9582451\tbest: 0.9582620 (2609)\ttotal: 1m 52s\tremaining: 12.4s\n",
      "bestTest = 0.9582620263\n",
      "bestIteration = 2609\n",
      "Shrink model to first 2610 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:21:36,447]\u001b[0m Trial 55 finished with value: 0.4029574326475099 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9131729451434367, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.2888476586478748}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 45.9ms\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9721160\ttest: 0.9511660\tbest: 0.9511660 (300)\ttotal: 12.4s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9745872\ttest: 0.9545484\tbest: 0.9546058 (597)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9760629\ttest: 0.9559516\tbest: 0.9559516 (900)\ttotal: 37.1s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9769351\ttest: 0.9569374\tbest: 0.9569630 (1190)\ttotal: 49.7s\tremaining: 1m 14s\n",
      "bestTest = 0.9573870599\n",
      "bestIteration = 1395\n",
      "Shrink model to first 1396 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:22:42,792]\u001b[0m Trial 56 finished with value: 0.402955401916857 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.8319865685259543, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.2915142016254011}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 39ms\tremaining: 1m 57s\n",
      "300:\tlearn: 0.9680701\ttest: 0.9446489\tbest: 0.9446489 (300)\ttotal: 11s\tremaining: 1m 38s\n",
      "600:\tlearn: 0.9716770\ttest: 0.9496136\tbest: 0.9496449 (598)\ttotal: 22.4s\tremaining: 1m 29s\n",
      "900:\tlearn: 0.9729752\ttest: 0.9521376\tbest: 0.9521376 (900)\ttotal: 33.8s\tremaining: 1m 18s\n",
      "1200:\tlearn: 0.9741839\ttest: 0.9538154\tbest: 0.9538154 (1200)\ttotal: 45.1s\tremaining: 1m 7s\n",
      "1500:\tlearn: 0.9749159\ttest: 0.9542772\tbest: 0.9543261 (1471)\ttotal: 56.4s\tremaining: 56.3s\n",
      "1800:\tlearn: 0.9754509\ttest: 0.9553690\tbest: 0.9553966 (1782)\ttotal: 1m 7s\tremaining: 45s\n",
      "2100:\tlearn: 0.9758170\ttest: 0.9556850\tbest: 0.9557411 (2037)\ttotal: 1m 18s\tremaining: 33.8s\n",
      "bestTest = 0.9561297596\n",
      "bestIteration = 2259\n",
      "Shrink model to first 2260 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:24:15,720]\u001b[0m Trial 57 finished with value: 0.3951452330756618 and parameters: {'l2_leaf_reg': 14, 'scale_pos_weight': 0.8392488916514589, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.25557136326633056}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8922818\ttest: 0.8317626\tbest: 0.8317626 (0)\ttotal: 38.7ms\tremaining: 1m 56s\n",
      "300:\tlearn: 0.9515701\ttest: 0.9130679\tbest: 0.9131977 (277)\ttotal: 10.8s\tremaining: 1m 36s\n",
      "600:\tlearn: 0.9547032\ttest: 0.9183296\tbest: 0.9183792 (582)\ttotal: 21.8s\tremaining: 1m 27s\n",
      "900:\tlearn: 0.9571121\ttest: 0.9236591\tbest: 0.9236591 (899)\ttotal: 32.9s\tremaining: 1m 16s\n",
      "bestTest = 0.9238544703\n",
      "bestIteration = 910\n",
      "Shrink model to first 911 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:24:56,586]\u001b[0m Trial 58 finished with value: 0.3350459772874601 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9956848798301475, 'depth': 3, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.048474179797383}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8399295\ttest: 0.6869946\tbest: 0.6869946 (0)\ttotal: 38ms\tremaining: 1m 54s\n",
      "300:\tlearn: 0.9607416\ttest: 0.9315295\tbest: 0.9315606 (296)\ttotal: 10.5s\tremaining: 1m 34s\n",
      "600:\tlearn: 0.9667174\ttest: 0.9418316\tbest: 0.9418316 (600)\ttotal: 21.2s\tremaining: 1m 24s\n",
      "900:\tlearn: 0.9692225\ttest: 0.9450510\tbest: 0.9450510 (900)\ttotal: 32s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9707187\ttest: 0.9469303\tbest: 0.9469427 (1194)\ttotal: 42.8s\tremaining: 1m 4s\n",
      "1500:\tlearn: 0.9715580\ttest: 0.9480846\tbest: 0.9480925 (1475)\ttotal: 53.6s\tremaining: 53.5s\n",
      "1800:\tlearn: 0.9722326\ttest: 0.9489099\tbest: 0.9489138 (1799)\ttotal: 1m 4s\tremaining: 42.9s\n",
      "2100:\tlearn: 0.9729631\ttest: 0.9497558\tbest: 0.9498328 (2074)\ttotal: 1m 15s\tremaining: 32.1s\n",
      "2400:\tlearn: 0.9734081\ttest: 0.9502739\tbest: 0.9503282 (2350)\ttotal: 1m 26s\tremaining: 21.5s\n",
      "bestTest = 0.9503282309\n",
      "bestIteration = 2350\n",
      "Shrink model to first 2351 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:26:28,494]\u001b[0m Trial 59 finished with value: 0.3749218912726516 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.7577131433106707, 'depth': 2, 'bootstrap_type': 'Bernoulli', 'subsample': 0.29816922412765506}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8091967\ttest: 0.7391798\tbest: 0.7391798 (0)\ttotal: 28.5ms\tremaining: 1m 25s\n",
      "300:\tlearn: 0.9518926\ttest: 0.9081248\tbest: 0.9082766 (294)\ttotal: 8.56s\tremaining: 1m 16s\n",
      "600:\tlearn: 0.9542862\ttest: 0.9138976\tbest: 0.9139154 (589)\ttotal: 17.1s\tremaining: 1m 8s\n",
      "900:\tlearn: 0.9553777\ttest: 0.9163103\tbest: 0.9163103 (900)\ttotal: 25.7s\tremaining: 59.8s\n",
      "1200:\tlearn: 0.9568039\ttest: 0.9211833\tbest: 0.9212710 (1189)\ttotal: 34.4s\tremaining: 51.6s\n",
      "1500:\tlearn: 0.9578178\ttest: 0.9243392\tbest: 0.9243499 (1481)\ttotal: 43.2s\tremaining: 43.1s\n",
      "1800:\tlearn: 0.9581579\ttest: 0.9250999\tbest: 0.9251074 (1793)\ttotal: 52s\tremaining: 34.6s\n",
      "2100:\tlearn: 0.9587223\ttest: 0.9265446\tbest: 0.9265446 (2100)\ttotal: 1m\tremaining: 26.1s\n",
      "2400:\tlearn: 0.9594154\ttest: 0.9276764\tbest: 0.9276764 (2400)\ttotal: 1m 9s\tremaining: 17.4s\n",
      "2700:\tlearn: 0.9599511\ttest: 0.9286693\tbest: 0.9286704 (2693)\ttotal: 1m 18s\tremaining: 8.69s\n",
      "2999:\tlearn: 0.9600469\ttest: 0.9291423\tbest: 0.9291437 (2998)\ttotal: 1m 27s\tremaining: 0us\n",
      "bestTest = 0.9291437268\n",
      "bestIteration = 2998\n",
      "Shrink model to first 2999 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:27:59,694]\u001b[0m Trial 60 finished with value: 0.3118352760997193 and parameters: {'l2_leaf_reg': 16, 'scale_pos_weight': 0.8125200513489428, 'depth': 1, 'bootstrap_type': 'Bernoulli', 'subsample': 0.14214651575727058}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 40.5ms\tremaining: 2m 1s\n",
      "300:\tlearn: 0.9711972\ttest: 0.9498668\tbest: 0.9498668 (300)\ttotal: 11.2s\tremaining: 1m 40s\n",
      "600:\tlearn: 0.9736428\ttest: 0.9528915\tbest: 0.9529323 (599)\ttotal: 22.6s\tremaining: 1m 30s\n",
      "900:\tlearn: 0.9749887\ttest: 0.9543374\tbest: 0.9543374 (900)\ttotal: 34.2s\tremaining: 1m 19s\n",
      "1200:\tlearn: 0.9758182\ttest: 0.9549828\tbest: 0.9550048 (1165)\ttotal: 45.8s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.9764475\ttest: 0.9555571\tbest: 0.9555676 (1473)\ttotal: 57.2s\tremaining: 57.2s\n",
      "1800:\tlearn: 0.9768973\ttest: 0.9559039\tbest: 0.9559039 (1800)\ttotal: 1m 8s\tremaining: 45.8s\n",
      "2100:\tlearn: 0.9773699\ttest: 0.9565690\tbest: 0.9565730 (2097)\ttotal: 1m 20s\tremaining: 34.3s\n",
      "2400:\tlearn: 0.9778727\ttest: 0.9568408\tbest: 0.9568641 (2385)\ttotal: 1m 31s\tremaining: 22.9s\n",
      "bestTest = 0.9569293857\n",
      "bestIteration = 2499\n",
      "Shrink model to first 2500 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:29:43,249]\u001b[0m Trial 61 finished with value: 0.4004275850114119 and parameters: {'l2_leaf_reg': 13, 'scale_pos_weight': 0.9341113356029045, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.19940304501850786}. Best is trial 37 with value: 0.4035458732871751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 40ms\tremaining: 2m\n",
      "300:\tlearn: 0.9716436\ttest: 0.9496541\tbest: 0.9496541 (300)\ttotal: 11.8s\tremaining: 1m 45s\n",
      "600:\tlearn: 0.9740191\ttest: 0.9525420\tbest: 0.9525838 (598)\ttotal: 23.5s\tremaining: 1m 33s\n",
      "900:\tlearn: 0.9752805\ttest: 0.9549328\tbest: 0.9549328 (900)\ttotal: 35.2s\tremaining: 1m 22s\n",
      "1200:\tlearn: 0.9761682\ttest: 0.9561870\tbest: 0.9561897 (1199)\ttotal: 47.1s\tremaining: 1m 10s\n",
      "1500:\tlearn: 0.9768398\ttest: 0.9568648\tbest: 0.9568648 (1500)\ttotal: 59s\tremaining: 58.9s\n",
      "1800:\tlearn: 0.9773871\ttest: 0.9574220\tbest: 0.9574220 (1800)\ttotal: 1m 10s\tremaining: 47.1s\n",
      "2100:\tlearn: 0.9778942\ttest: 0.9578457\tbest: 0.9578494 (2063)\ttotal: 1m 22s\tremaining: 35.4s\n",
      "bestTest = 0.9579004347\n",
      "bestIteration = 2146\n",
      "Shrink model to first 2147 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:31:15,835]\u001b[0m Trial 62 finished with value: 0.40479134911276643 and parameters: {'l2_leaf_reg': 13, 'scale_pos_weight': 0.9406780584846045, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.22922161698463137}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 44.6ms\tremaining: 2m 13s\n",
      "300:\tlearn: 0.9721303\ttest: 0.9518550\tbest: 0.9518788 (298)\ttotal: 12.2s\tremaining: 1m 49s\n",
      "600:\tlearn: 0.9748081\ttest: 0.9548526\tbest: 0.9548680 (597)\ttotal: 24.6s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9763304\ttest: 0.9555670\tbest: 0.9556093 (898)\ttotal: 37s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9771384\ttest: 0.9562173\tbest: 0.9562209 (1198)\ttotal: 49.4s\tremaining: 1m 14s\n",
      "bestTest = 0.9563596249\n",
      "bestIteration = 1320\n",
      "Shrink model to first 1321 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:32:18,215]\u001b[0m Trial 63 finished with value: 0.4001112640178023 and parameters: {'l2_leaf_reg': 14, 'scale_pos_weight': 0.869494308583954, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3568768750562912}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 39.3ms\tremaining: 1m 57s\n",
      "300:\tlearn: 0.9708790\ttest: 0.9490451\tbest: 0.9490904 (298)\ttotal: 11.6s\tremaining: 1m 43s\n",
      "600:\tlearn: 0.9736475\ttest: 0.9522673\tbest: 0.9522730 (595)\ttotal: 23.2s\tremaining: 1m 32s\n",
      "900:\tlearn: 0.9750039\ttest: 0.9540878\tbest: 0.9540987 (892)\ttotal: 34.6s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9758056\ttest: 0.9551027\tbest: 0.9551241 (1185)\ttotal: 45.9s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.9764340\ttest: 0.9557112\tbest: 0.9557130 (1499)\ttotal: 57.3s\tremaining: 57.3s\n",
      "bestTest = 0.9559998214\n",
      "bestIteration = 1650\n",
      "Shrink model to first 1651 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:33:28,969]\u001b[0m Trial 64 finished with value: 0.3994319939262717 and parameters: {'l2_leaf_reg': 16, 'scale_pos_weight': 0.9632669037682801, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.19123375459517422}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 41.4ms\tremaining: 2m 4s\n",
      "300:\tlearn: 0.9689334\ttest: 0.9444166\tbest: 0.9444640 (299)\ttotal: 11.6s\tremaining: 1m 44s\n",
      "600:\tlearn: 0.9727400\ttest: 0.9501149\tbest: 0.9501245 (599)\ttotal: 23.2s\tremaining: 1m 32s\n",
      "900:\tlearn: 0.9742053\ttest: 0.9517429\tbest: 0.9517432 (898)\ttotal: 34.8s\tremaining: 1m 21s\n",
      "1200:\tlearn: 0.9751390\ttest: 0.9524184\tbest: 0.9524692 (1168)\ttotal: 46.4s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.9757586\ttest: 0.9527826\tbest: 0.9527943 (1497)\ttotal: 57.9s\tremaining: 57.8s\n",
      "1800:\tlearn: 0.9762893\ttest: 0.9533100\tbest: 0.9533469 (1784)\ttotal: 1m 9s\tremaining: 46.2s\n",
      "2100:\tlearn: 0.9767067\ttest: 0.9531415\tbest: 0.9535066 (2046)\ttotal: 1m 21s\tremaining: 34.7s\n",
      "bestTest = 0.9535065591\n",
      "bestIteration = 2046\n",
      "Shrink model to first 2047 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:34:55,654]\u001b[0m Trial 65 finished with value: 0.3715237096873651 and parameters: {'l2_leaf_reg': 11, 'scale_pos_weight': 0.897137985662151, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.2835250728063079}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 47.7ms\tremaining: 2m 23s\n",
      "300:\tlearn: 0.9744214\ttest: 0.9547085\tbest: 0.9547085 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9765528\ttest: 0.9567601\tbest: 0.9567611 (599)\ttotal: 26.4s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9777949\ttest: 0.9577124\tbest: 0.9577375 (891)\ttotal: 39.8s\tremaining: 1m 32s\n",
      "bestTest = 0.9578486085\n",
      "bestIteration = 1059\n",
      "Shrink model to first 1060 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:35:50,538]\u001b[0m Trial 66 finished with value: 0.4029775646717575 and parameters: {'l2_leaf_reg': 18, 'scale_pos_weight': 0.840317414261468, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.34156269120706145}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 47.3ms\tremaining: 2m 22s\n",
      "300:\tlearn: 0.9739952\ttest: 0.9533972\tbest: 0.9533972 (300)\ttotal: 13.4s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9764495\ttest: 0.9563113\tbest: 0.9563113 (600)\ttotal: 26.5s\tremaining: 1m 45s\n",
      "bestTest = 0.9572671056\n",
      "bestIteration = 781\n",
      "Shrink model to first 782 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:36:33,285]\u001b[0m Trial 67 finished with value: 0.40334900117508815 and parameters: {'l2_leaf_reg': 19, 'scale_pos_weight': 0.8411496872697333, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3177188863807054}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9235219\ttest: 0.8729598\tbest: 0.8729598 (0)\ttotal: 47.2ms\tremaining: 2m 21s\n",
      "300:\tlearn: 0.9750116\ttest: 0.9539302\tbest: 0.9539302 (300)\ttotal: 14.4s\tremaining: 2m 9s\n",
      "600:\tlearn: 0.9775461\ttest: 0.9568389\tbest: 0.9568510 (597)\ttotal: 28.6s\tremaining: 1m 54s\n",
      "bestTest = 0.9574445784\n",
      "bestIteration = 746\n",
      "Shrink model to first 747 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:37:17,155]\u001b[0m Trial 68 finished with value: 0.3943114703139571 and parameters: {'l2_leaf_reg': 20, 'scale_pos_weight': 0.6768953464420279, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.34409433190753813}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9125850\ttest: 0.8471319\tbest: 0.8471319 (0)\ttotal: 45ms\tremaining: 2m 15s\n",
      "300:\tlearn: 0.9724871\ttest: 0.9514713\tbest: 0.9514713 (300)\ttotal: 12.8s\tremaining: 1m 55s\n",
      "600:\tlearn: 0.9749267\ttest: 0.9543419\tbest: 0.9543419 (600)\ttotal: 25.7s\tremaining: 1m 42s\n",
      "900:\tlearn: 0.9764013\ttest: 0.9560716\tbest: 0.9560716 (900)\ttotal: 38.5s\tremaining: 1m 29s\n",
      "1200:\tlearn: 0.9773339\ttest: 0.9566674\tbest: 0.9566952 (1173)\ttotal: 51.5s\tremaining: 1m 17s\n",
      "1500:\tlearn: 0.9780418\ttest: 0.9572731\tbest: 0.9572845 (1494)\ttotal: 1m 4s\tremaining: 1m 4s\n",
      "1800:\tlearn: 0.9787031\ttest: 0.9577503\tbest: 0.9577503 (1800)\ttotal: 1m 17s\tremaining: 51.4s\n",
      "2100:\tlearn: 0.9792562\ttest: 0.9579382\tbest: 0.9579595 (2023)\ttotal: 1m 30s\tremaining: 38.6s\n",
      "2400:\tlearn: 0.9797750\ttest: 0.9582187\tbest: 0.9582257 (2391)\ttotal: 1m 42s\tremaining: 25.7s\n",
      "2700:\tlearn: 0.9802630\ttest: 0.9583808\tbest: 0.9584018 (2617)\ttotal: 1m 55s\tremaining: 12.8s\n",
      "2999:\tlearn: 0.9807264\ttest: 0.9588103\tbest: 0.9588334 (2984)\ttotal: 2m 8s\tremaining: 0us\n",
      "bestTest = 0.9588333666\n",
      "bestIteration = 2984\n",
      "Shrink model to first 2985 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:39:30,061]\u001b[0m Trial 69 finished with value: 0.382451654147355 and parameters: {'l2_leaf_reg': 22, 'scale_pos_weight': 0.7237729931861356, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.2475929604911316}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9231345\ttest: 0.8741489\tbest: 0.8741489 (0)\ttotal: 53.2ms\tremaining: 2m 39s\n",
      "300:\tlearn: 0.9768606\ttest: 0.9528003\tbest: 0.9528003 (300)\ttotal: 15.4s\tremaining: 2m 18s\n",
      "600:\tlearn: 0.9795706\ttest: 0.9559385\tbest: 0.9559415 (599)\ttotal: 30.8s\tremaining: 2m 2s\n",
      "900:\tlearn: 0.9810293\ttest: 0.9565111\tbest: 0.9565111 (900)\ttotal: 45.9s\tremaining: 1m 46s\n",
      "bestTest = 0.9566080868\n",
      "bestIteration = 968\n",
      "Shrink model to first 969 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:40:28,315]\u001b[0m Trial 70 finished with value: 0.37411800030025516 and parameters: {'l2_leaf_reg': 18, 'scale_pos_weight': 0.8396105956232204, 'depth': 7, 'bootstrap_type': 'Bernoulli', 'subsample': 0.4191240559096807}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 42.7ms\tremaining: 2m 8s\n",
      "300:\tlearn: 0.9741486\ttest: 0.9542454\tbest: 0.9542454 (300)\ttotal: 13.4s\tremaining: 2m\n",
      "600:\tlearn: 0.9764992\ttest: 0.9562329\tbest: 0.9562785 (572)\ttotal: 26.8s\tremaining: 1m 47s\n",
      "900:\tlearn: 0.9777969\ttest: 0.9570994\tbest: 0.9571048 (899)\ttotal: 40.1s\tremaining: 1m 33s\n",
      "1200:\tlearn: 0.9787447\ttest: 0.9578716\tbest: 0.9578732 (1198)\ttotal: 53.5s\tremaining: 1m 20s\n",
      "1500:\tlearn: 0.9794796\ttest: 0.9581148\tbest: 0.9581971 (1402)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "bestTest = 0.9581971169\n",
      "bestIteration = 1402\n",
      "Shrink model to first 1403 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:41:38,954]\u001b[0m Trial 71 finished with value: 0.39958865873365645 and parameters: {'l2_leaf_reg': 19, 'scale_pos_weight': 0.874124348391873, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5241095656106636}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 38.9ms\tremaining: 1m 56s\n",
      "300:\tlearn: 0.9723838\ttest: 0.9501105\tbest: 0.9501105 (300)\ttotal: 12.4s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9751418\ttest: 0.9544029\tbest: 0.9544029 (600)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9764258\ttest: 0.9552312\tbest: 0.9552351 (899)\ttotal: 37.2s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9772993\ttest: 0.9563626\tbest: 0.9564000 (1191)\ttotal: 49.6s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9779417\ttest: 0.9568059\tbest: 0.9568156 (1440)\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "1800:\tlearn: 0.9784659\ttest: 0.9572522\tbest: 0.9572522 (1800)\ttotal: 1m 14s\tremaining: 49.9s\n",
      "bestTest = 0.9575346708\n",
      "bestIteration = 1971\n",
      "Shrink model to first 1972 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:43:09,061]\u001b[0m Trial 72 finished with value: 0.4023285157146134 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9279064133474211, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3271729815932615}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 45.3ms\tremaining: 2m 15s\n",
      "300:\tlearn: 0.9744550\ttest: 0.9545741\tbest: 0.9545741 (300)\ttotal: 13.4s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9768154\ttest: 0.9570151\tbest: 0.9570151 (600)\ttotal: 26.6s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9782615\ttest: 0.9580475\tbest: 0.9580526 (873)\ttotal: 39.9s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9791333\ttest: 0.9584196\tbest: 0.9585216 (1115)\ttotal: 53.2s\tremaining: 1m 19s\n",
      "bestTest = 0.9585216343\n",
      "bestIteration = 1115\n",
      "Shrink model to first 1116 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:44:06,842]\u001b[0m Trial 73 finished with value: 0.39957710578148536 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9320462647983788, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3124195948091049}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9235303\ttest: 0.8727149\tbest: 0.8727149 (0)\ttotal: 49.7ms\tremaining: 2m 28s\n",
      "300:\tlearn: 0.9752391\ttest: 0.9537079\tbest: 0.9537079 (300)\ttotal: 14.4s\tremaining: 2m 9s\n",
      "600:\tlearn: 0.9777536\ttest: 0.9554892\tbest: 0.9557384 (591)\ttotal: 28.5s\tremaining: 1m 53s\n",
      "900:\tlearn: 0.9790049\ttest: 0.9567198\tbest: 0.9567233 (896)\ttotal: 42.6s\tremaining: 1m 39s\n",
      "1200:\tlearn: 0.9800651\ttest: 0.9573024\tbest: 0.9574994 (1127)\ttotal: 56.8s\tremaining: 1m 25s\n",
      "bestTest = 0.9574993551\n",
      "bestIteration = 1127\n",
      "Shrink model to first 1128 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:45:08,774]\u001b[0m Trial 74 finished with value: 0.3906770928047523 and parameters: {'l2_leaf_reg': 18, 'scale_pos_weight': 0.7878381787411868, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.330597362128244}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 39.3ms\tremaining: 1m 57s\n",
      "300:\tlearn: 0.9690614\ttest: 0.9467104\tbest: 0.9467104 (300)\ttotal: 11.3s\tremaining: 1m 41s\n",
      "600:\tlearn: 0.9726760\ttest: 0.9514563\tbest: 0.9514664 (599)\ttotal: 22.8s\tremaining: 1m 30s\n",
      "900:\tlearn: 0.9743330\ttest: 0.9532843\tbest: 0.9533004 (884)\ttotal: 34.2s\tremaining: 1m 19s\n",
      "1200:\tlearn: 0.9753241\ttest: 0.9542861\tbest: 0.9543570 (1190)\ttotal: 45.7s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.9759882\ttest: 0.9551740\tbest: 0.9551740 (1500)\ttotal: 57.3s\tremaining: 57.2s\n",
      "bestTest = 0.9551813602\n",
      "bestIteration = 1501\n",
      "Shrink model to first 1502 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:46:13,950]\u001b[0m Trial 75 finished with value: 0.39389579125044966 and parameters: {'l2_leaf_reg': 13, 'scale_pos_weight': 0.9724214550462246, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3918850390474703}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9188895\ttest: 0.8990623\tbest: 0.8990623 (0)\ttotal: 44.3ms\tremaining: 2m 12s\n",
      "300:\tlearn: 0.9688599\ttest: 0.9464017\tbest: 0.9464052 (299)\ttotal: 12.1s\tremaining: 1m 48s\n",
      "600:\tlearn: 0.9709872\ttest: 0.9491671\tbest: 0.9491865 (599)\ttotal: 24.2s\tremaining: 1m 36s\n",
      "900:\tlearn: 0.9723276\ttest: 0.9505312\tbest: 0.9505363 (896)\ttotal: 36.4s\tremaining: 1m 24s\n",
      "1200:\tlearn: 0.9731418\ttest: 0.9515541\tbest: 0.9515601 (1196)\ttotal: 48.7s\tremaining: 1m 13s\n",
      "1500:\tlearn: 0.9739937\ttest: 0.9523222\tbest: 0.9523222 (1500)\ttotal: 1m\tremaining: 1m\n",
      "1800:\tlearn: 0.9744383\ttest: 0.9527166\tbest: 0.9527166 (1800)\ttotal: 1m 13s\tremaining: 48.7s\n",
      "2100:\tlearn: 0.9748546\ttest: 0.9534814\tbest: 0.9534814 (2100)\ttotal: 1m 25s\tremaining: 36.5s\n",
      "bestTest = 0.9536783993\n",
      "bestIteration = 2153\n",
      "Shrink model to first 2154 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:47:49,390]\u001b[0m Trial 76 finished with value: 0.39448427708462713 and parameters: {'l2_leaf_reg': 21, 'scale_pos_weight': 0.849737265155298, 'depth': 4, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.09497348151747}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9019926\ttest: 0.8310854\tbest: 0.8310854 (0)\ttotal: 45.2ms\tremaining: 2m 15s\n",
      "300:\tlearn: 0.9739966\ttest: 0.9538389\tbest: 0.9538389 (300)\ttotal: 13.1s\tremaining: 1m 57s\n",
      "600:\tlearn: 0.9764091\ttest: 0.9568572\tbest: 0.9568586 (599)\ttotal: 26.4s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9776218\ttest: 0.9578230\tbest: 0.9579422 (821)\ttotal: 39.4s\tremaining: 1m 31s\n",
      "bestTest = 0.9579421878\n",
      "bestIteration = 821\n",
      "Shrink model to first 822 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:48:33,439]\u001b[0m Trial 77 finished with value: 0.39906103286384975 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.9425000940956939, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.2621066910882123}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9078657\ttest: 0.8416031\tbest: 0.8416031 (0)\ttotal: 37.4ms\tremaining: 1m 52s\n",
      "300:\tlearn: 0.9683245\ttest: 0.9461951\tbest: 0.9462506 (295)\ttotal: 10.8s\tremaining: 1m 36s\n",
      "600:\tlearn: 0.9713668\ttest: 0.9504388\tbest: 0.9504388 (600)\ttotal: 21.7s\tremaining: 1m 26s\n",
      "900:\tlearn: 0.9728577\ttest: 0.9520573\tbest: 0.9520580 (899)\ttotal: 32.7s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9737341\ttest: 0.9531716\tbest: 0.9531720 (1199)\ttotal: 43.8s\tremaining: 1m 5s\n",
      "1500:\tlearn: 0.9744197\ttest: 0.9545313\tbest: 0.9545951 (1487)\ttotal: 54.7s\tremaining: 54.6s\n",
      "1800:\tlearn: 0.9749244\ttest: 0.9550321\tbest: 0.9550397 (1791)\ttotal: 1m 5s\tremaining: 43.6s\n",
      "bestTest = 0.9551928937\n",
      "bestIteration = 1982\n",
      "Shrink model to first 1983 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:49:53,137]\u001b[0m Trial 78 finished with value: 0.39384438187867926 and parameters: {'l2_leaf_reg': 14, 'scale_pos_weight': 0.5517449336442224, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.16484989593888996}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 46.5ms\tremaining: 2m 19s\n",
      "300:\tlearn: 0.9740403\ttest: 0.9534518\tbest: 0.9534660 (299)\ttotal: 13.3s\tremaining: 1m 58s\n",
      "600:\tlearn: 0.9764435\ttest: 0.9561623\tbest: 0.9561623 (600)\ttotal: 26.4s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9777489\ttest: 0.9575036\tbest: 0.9575040 (899)\ttotal: 39.6s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9786184\ttest: 0.9579972\tbest: 0.9580072 (1170)\ttotal: 53.1s\tremaining: 1m 19s\n",
      "bestTest = 0.9582835138\n",
      "bestIteration = 1319\n",
      "Shrink model to first 1320 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:50:59,724]\u001b[0m Trial 79 finished with value: 0.3900443538719732 and parameters: {'l2_leaf_reg': 16, 'scale_pos_weight': 0.8102512221456707, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.3784875551033427}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9222146\ttest: 0.8690400\tbest: 0.8690400 (0)\ttotal: 45.5ms\tremaining: 2m 16s\n",
      "300:\tlearn: 0.9748151\ttest: 0.9522804\tbest: 0.9522847 (299)\ttotal: 13.5s\tremaining: 2m\n",
      "600:\tlearn: 0.9770707\ttest: 0.9555597\tbest: 0.9555620 (599)\ttotal: 26.7s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9785077\ttest: 0.9567299\tbest: 0.9567524 (893)\ttotal: 40.1s\tremaining: 1m 33s\n",
      "1200:\tlearn: 0.9795801\ttest: 0.9570352\tbest: 0.9574015 (1158)\ttotal: 53.3s\tremaining: 1m 19s\n",
      "bestTest = 0.9574015439\n",
      "bestIteration = 1158\n",
      "Shrink model to first 1159 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:51:59,476]\u001b[0m Trial 80 finished with value: 0.38379370524162004 and parameters: {'l2_leaf_reg': 19, 'scale_pos_weight': 0.8882358081647337, 'depth': 6, 'bootstrap_type': 'Bernoulli', 'subsample': 0.21758927543100298}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 42.2ms\tremaining: 2m 6s\n",
      "300:\tlearn: 0.9719392\ttest: 0.9504434\tbest: 0.9504434 (300)\ttotal: 12.4s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9748777\ttest: 0.9542104\tbest: 0.9542241 (597)\ttotal: 24.8s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9762004\ttest: 0.9552999\tbest: 0.9553160 (898)\ttotal: 37.4s\tremaining: 1m 27s\n",
      "1200:\tlearn: 0.9770590\ttest: 0.9563067\tbest: 0.9563084 (1198)\ttotal: 49.9s\tremaining: 1m 14s\n",
      "bestTest = 0.9565289617\n",
      "bestIteration = 1293\n",
      "Shrink model to first 1294 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:53:01,359]\u001b[0m Trial 81 finished with value: 0.40024345003477857 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9268309724717696, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5552109177439067}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 41.8ms\tremaining: 2m 5s\n",
      "300:\tlearn: 0.9722541\ttest: 0.9513266\tbest: 0.9513266 (300)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9749098\ttest: 0.9552493\tbest: 0.9552641 (598)\ttotal: 24.6s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9763422\ttest: 0.9560512\tbest: 0.9560514 (899)\ttotal: 37.1s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9772623\ttest: 0.9571005\tbest: 0.9571184 (1143)\ttotal: 49.4s\tremaining: 1m 14s\n",
      "bestTest = 0.9574050903\n",
      "bestIteration = 1305\n",
      "Shrink model to first 1306 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:54:03,096]\u001b[0m Trial 82 finished with value: 0.4024255788313121 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.9755400836454207, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6233495561183815}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 42ms\tremaining: 2m 5s\n",
      "300:\tlearn: 0.9725849\ttest: 0.9513376\tbest: 0.9513376 (300)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9749405\ttest: 0.9544666\tbest: 0.9544733 (597)\ttotal: 24.7s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9763757\ttest: 0.9563032\tbest: 0.9563103 (899)\ttotal: 37s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9771747\ttest: 0.9570293\tbest: 0.9570412 (1196)\ttotal: 49.3s\tremaining: 1m 13s\n",
      "1500:\tlearn: 0.9778866\ttest: 0.9577826\tbest: 0.9577870 (1495)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1800:\tlearn: 0.9783745\ttest: 0.9579002\tbest: 0.9579072 (1782)\ttotal: 1m 14s\tremaining: 49.4s\n",
      "bestTest = 0.9580860138\n",
      "bestIteration = 1977\n",
      "Shrink model to first 1978 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:55:32,920]\u001b[0m Trial 83 finished with value: 0.4004857836833834 and parameters: {'l2_leaf_reg': 26, 'scale_pos_weight': 0.9767334311752551, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.691902554152364}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 44.1ms\tremaining: 2m 12s\n",
      "300:\tlearn: 0.9728196\ttest: 0.9510404\tbest: 0.9510404 (300)\ttotal: 12.4s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9751517\ttest: 0.9537775\tbest: 0.9537775 (600)\ttotal: 24.9s\tremaining: 1m 39s\n",
      "900:\tlearn: 0.9765996\ttest: 0.9550542\tbest: 0.9551026 (892)\ttotal: 37.4s\tremaining: 1m 27s\n",
      "1200:\tlearn: 0.9774108\ttest: 0.9559313\tbest: 0.9559313 (1200)\ttotal: 49.7s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9780993\ttest: 0.9564723\tbest: 0.9565030 (1422)\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "bestTest = 0.9565030336\n",
      "bestIteration = 1422\n",
      "Shrink model to first 1423 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:56:39,790]\u001b[0m Trial 84 finished with value: 0.40011897342926755 and parameters: {'l2_leaf_reg': 12, 'scale_pos_weight': 0.9998576634660519, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6530346554834}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 38.9ms\tremaining: 1m 56s\n",
      "300:\tlearn: 0.9687245\ttest: 0.9434656\tbest: 0.9434674 (299)\ttotal: 11.4s\tremaining: 1m 41s\n",
      "600:\tlearn: 0.9726466\ttest: 0.9499054\tbest: 0.9499054 (600)\ttotal: 22.9s\tremaining: 1m 31s\n",
      "900:\tlearn: 0.9740384\ttest: 0.9520273\tbest: 0.9520490 (898)\ttotal: 34.3s\tremaining: 1m 19s\n",
      "1200:\tlearn: 0.9750047\ttest: 0.9531291\tbest: 0.9531291 (1200)\ttotal: 45.9s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.9756961\ttest: 0.9537472\tbest: 0.9537487 (1497)\ttotal: 57.5s\tremaining: 57.5s\n",
      "bestTest = 0.9541952908\n",
      "bestIteration = 1666\n",
      "Shrink model to first 1667 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:57:51,341]\u001b[0m Trial 85 finished with value: 0.38933317299019904 and parameters: {'l2_leaf_reg': 18, 'scale_pos_weight': 0.8849461338025354, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6135632387677296}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 42.6ms\tremaining: 2m 7s\n",
      "300:\tlearn: 0.9743627\ttest: 0.9534593\tbest: 0.9534593 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9766421\ttest: 0.9561345\tbest: 0.9561345 (600)\ttotal: 26.8s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9780192\ttest: 0.9575076\tbest: 0.9575519 (889)\ttotal: 40s\tremaining: 1m 33s\n",
      "1200:\tlearn: 0.9788975\ttest: 0.9579056\tbest: 0.9579093 (1195)\ttotal: 53.4s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9796471\ttest: 0.9582528\tbest: 0.9582528 (1500)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "1800:\tlearn: 0.9802844\ttest: 0.9584627\tbest: 0.9584649 (1792)\ttotal: 1m 19s\tremaining: 53.2s\n",
      "bestTest = 0.9584954381\n",
      "bestIteration = 1826\n",
      "Shrink model to first 1827 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 19:59:20,696]\u001b[0m Trial 86 finished with value: 0.3946942736978324 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.9477489177518253, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.2810771465999278}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 43ms\tremaining: 2m 8s\n",
      "300:\tlearn: 0.9741843\ttest: 0.9547404\tbest: 0.9547404 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9764939\ttest: 0.9567367\tbest: 0.9567476 (592)\ttotal: 26.4s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9778067\ttest: 0.9580805\tbest: 0.9580895 (899)\ttotal: 39.6s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9786466\ttest: 0.9584810\tbest: 0.9585299 (1113)\ttotal: 52.8s\tremaining: 1m 19s\n",
      "bestTest = 0.9585299194\n",
      "bestIteration = 1113\n",
      "Shrink model to first 1114 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:00:17,948]\u001b[0m Trial 87 finished with value: 0.4005807235341175 and parameters: {'l2_leaf_reg': 16, 'scale_pos_weight': 0.826053631730474, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.320447162715965}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9078657\ttest: 0.8416031\tbest: 0.8416031 (0)\ttotal: 43.7ms\tremaining: 2m 10s\n",
      "300:\tlearn: 0.9720359\ttest: 0.9503879\tbest: 0.9503879 (300)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9746724\ttest: 0.9543098\tbest: 0.9543098 (600)\ttotal: 24.6s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9760534\ttest: 0.9559755\tbest: 0.9559755 (900)\ttotal: 37s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9769744\ttest: 0.9566761\tbest: 0.9566887 (1184)\ttotal: 49.3s\tremaining: 1m 13s\n",
      "1500:\tlearn: 0.9775652\ttest: 0.9571063\tbest: 0.9571141 (1491)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1800:\tlearn: 0.9780585\ttest: 0.9574189\tbest: 0.9574223 (1797)\ttotal: 1m 14s\tremaining: 49.3s\n",
      "2100:\tlearn: 0.9784805\ttest: 0.9576451\tbest: 0.9576562 (2077)\ttotal: 1m 26s\tremaining: 37s\n",
      "bestTest = 0.9577741027\n",
      "bestIteration = 2271\n",
      "Shrink model to first 2272 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:01:59,557]\u001b[0m Trial 88 finished with value: 0.3961352657004831 and parameters: {'l2_leaf_reg': 14, 'scale_pos_weight': 0.7597535005817825, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5858664258253194}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n",
      "Inconsistent parameter values for distribution with name \"bagging_temperature\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.0, 'high': 10.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8673334\ttest: 0.8050867\tbest: 0.8050867 (0)\ttotal: 38.3ms\tremaining: 1m 54s\n",
      "300:\tlearn: 0.9465312\ttest: 0.9021155\tbest: 0.9021162 (298)\ttotal: 10.6s\tremaining: 1m 35s\n",
      "600:\tlearn: 0.9509190\ttest: 0.9084516\tbest: 0.9085060 (594)\ttotal: 21.6s\tremaining: 1m 26s\n",
      "900:\tlearn: 0.9540715\ttest: 0.9139073\tbest: 0.9139838 (896)\ttotal: 33s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9555363\ttest: 0.9154820\tbest: 0.9158722 (1108)\ttotal: 44.6s\tremaining: 1m 6s\n",
      "bestTest = 0.9158722162\n",
      "bestIteration = 1108\n",
      "Shrink model to first 1109 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:02:48,322]\u001b[0m Trial 89 finished with value: 0.3241503219044767 and parameters: {'l2_leaf_reg': 18, 'scale_pos_weight': 0.8562382954733115, 'depth': 3, 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.993001827412513}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8399295\ttest: 0.6869946\tbest: 0.6869946 (0)\ttotal: 34.1ms\tremaining: 1m 42s\n",
      "300:\tlearn: 0.9583987\ttest: 0.9232926\tbest: 0.9232933 (299)\ttotal: 10.3s\tremaining: 1m 32s\n",
      "600:\tlearn: 0.9650360\ttest: 0.9355253\tbest: 0.9355253 (600)\ttotal: 21s\tremaining: 1m 23s\n",
      "900:\tlearn: 0.9677618\ttest: 0.9400723\tbest: 0.9400723 (900)\ttotal: 31.7s\tremaining: 1m 13s\n",
      "1200:\tlearn: 0.9693602\ttest: 0.9429361\tbest: 0.9429627 (1196)\ttotal: 42.3s\tremaining: 1m 3s\n",
      "1500:\tlearn: 0.9701642\ttest: 0.9439940\tbest: 0.9440402 (1486)\ttotal: 53s\tremaining: 53s\n",
      "1800:\tlearn: 0.9708773\ttest: 0.9444798\tbest: 0.9445114 (1779)\ttotal: 1m 3s\tremaining: 42.5s\n",
      "2100:\tlearn: 0.9714775\ttest: 0.9455592\tbest: 0.9455611 (2095)\ttotal: 1m 14s\tremaining: 31.9s\n",
      "2400:\tlearn: 0.9719928\ttest: 0.9462025\tbest: 0.9462025 (2400)\ttotal: 1m 25s\tremaining: 21.3s\n",
      "bestTest = 0.9462426901\n",
      "bestIteration = 2443\n",
      "Shrink model to first 2444 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:04:22,791]\u001b[0m Trial 90 finished with value: 0.22547801338838339 and parameters: {'l2_leaf_reg': 12, 'scale_pos_weight': 0.3933378636974355, 'depth': 2, 'bootstrap_type': 'Bernoulli', 'subsample': 0.6307315994503406}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 42.4ms\tremaining: 2m 7s\n",
      "300:\tlearn: 0.9713048\ttest: 0.9499268\tbest: 0.9499314 (295)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9744600\ttest: 0.9539020\tbest: 0.9539534 (598)\ttotal: 24.7s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9758776\ttest: 0.9552794\tbest: 0.9552887 (897)\ttotal: 37s\tremaining: 1m 26s\n",
      "1200:\tlearn: 0.9768479\ttest: 0.9565447\tbest: 0.9565832 (1176)\ttotal: 49.5s\tremaining: 1m 14s\n",
      "1500:\tlearn: 0.9775520\ttest: 0.9570059\tbest: 0.9570093 (1449)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1800:\tlearn: 0.9781314\ttest: 0.9575472\tbest: 0.9575472 (1800)\ttotal: 1m 14s\tremaining: 49.5s\n",
      "bestTest = 0.9576166868\n",
      "bestIteration = 1824\n",
      "Shrink model to first 1825 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:05:46,158]\u001b[0m Trial 91 finished with value: 0.40356108610258906 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9119041301665876, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5109835199229612}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 39.6ms\tremaining: 1m 58s\n",
      "300:\tlearn: 0.9721170\ttest: 0.9507456\tbest: 0.9507503 (297)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9748668\ttest: 0.9538271\tbest: 0.9539307 (596)\ttotal: 24.6s\tremaining: 1m 38s\n",
      "900:\tlearn: 0.9762728\ttest: 0.9554715\tbest: 0.9554848 (881)\ttotal: 36.9s\tremaining: 1m 25s\n",
      "1200:\tlearn: 0.9771416\ttest: 0.9559233\tbest: 0.9560078 (1158)\ttotal: 49.3s\tremaining: 1m 13s\n",
      "1500:\tlearn: 0.9778266\ttest: 0.9563119\tbest: 0.9564145 (1480)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1800:\tlearn: 0.9783620\ttest: 0.9566408\tbest: 0.9567080 (1772)\ttotal: 1m 14s\tremaining: 49.5s\n",
      "bestTest = 0.9567079544\n",
      "bestIteration = 1772\n",
      "Shrink model to first 1773 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:07:07,370]\u001b[0m Trial 92 finished with value: 0.402710635359116 and parameters: {'l2_leaf_reg': 15, 'scale_pos_weight': 0.9154828048779301, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.45146652605193993}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8861952\ttest: 0.8257741\tbest: 0.8257741 (0)\ttotal: 42.7ms\tremaining: 2m 8s\n",
      "300:\tlearn: 0.9723980\ttest: 0.9504626\tbest: 0.9504797 (299)\ttotal: 12.3s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.9750457\ttest: 0.9544739\tbest: 0.9544778 (598)\ttotal: 24.8s\tremaining: 1m 39s\n",
      "900:\tlearn: 0.9764576\ttest: 0.9559466\tbest: 0.9562176 (882)\ttotal: 37.1s\tremaining: 1m 26s\n",
      "bestTest = 0.956217587\n",
      "bestIteration = 882\n",
      "Shrink model to first 883 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:07:51,603]\u001b[0m Trial 93 finished with value: 0.4001894048097343 and parameters: {'l2_leaf_reg': 13, 'scale_pos_weight': 0.8999216620411107, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5014359154997304}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031663\ttest: 0.8337291\tbest: 0.8337291 (0)\ttotal: 43ms\tremaining: 2m 9s\n",
      "300:\tlearn: 0.9746352\ttest: 0.9540952\tbest: 0.9540952 (300)\ttotal: 13.3s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9768461\ttest: 0.9563806\tbest: 0.9564109 (598)\ttotal: 26.5s\tremaining: 1m 45s\n",
      "900:\tlearn: 0.9781438\ttest: 0.9574191\tbest: 0.9574236 (898)\ttotal: 39.7s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9789811\ttest: 0.9580346\tbest: 0.9580494 (1176)\ttotal: 53.2s\tremaining: 1m 19s\n",
      "bestTest = 0.9580493569\n",
      "bestIteration = 1176\n",
      "Shrink model to first 1177 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:08:52,109]\u001b[0m Trial 94 finished with value: 0.4005002700321195 and parameters: {'l2_leaf_reg': 21, 'scale_pos_weight': 0.9698391923897923, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.4374477668275186}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 41.8ms\tremaining: 2m 5s\n",
      "300:\tlearn: 0.9685294\ttest: 0.9458531\tbest: 0.9458531 (300)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "600:\tlearn: 0.9724728\ttest: 0.9515366\tbest: 0.9515366 (600)\ttotal: 23s\tremaining: 1m 31s\n",
      "900:\tlearn: 0.9741819\ttest: 0.9533379\tbest: 0.9533737 (881)\ttotal: 34.5s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9752080\ttest: 0.9540420\tbest: 0.9540697 (1181)\ttotal: 46s\tremaining: 1m 8s\n",
      "1500:\tlearn: 0.9758892\ttest: 0.9548348\tbest: 0.9548406 (1499)\ttotal: 57.5s\tremaining: 57.4s\n",
      "1800:\tlearn: 0.9763153\ttest: 0.9550900\tbest: 0.9550941 (1796)\ttotal: 1m 9s\tremaining: 46s\n",
      "bestTest = 0.9550941288\n",
      "bestIteration = 1796\n",
      "Shrink model to first 1797 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:10:08,752]\u001b[0m Trial 95 finished with value: 0.3915748210430633 and parameters: {'l2_leaf_reg': 16, 'scale_pos_weight': 0.9106624038508678, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.4460422678480994}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9031664\ttest: 0.8337107\tbest: 0.8337107 (0)\ttotal: 44.9ms\tremaining: 2m 14s\n",
      "300:\tlearn: 0.9741997\ttest: 0.9545837\tbest: 0.9545862 (298)\ttotal: 13.4s\tremaining: 1m 59s\n",
      "600:\tlearn: 0.9766113\ttest: 0.9566555\tbest: 0.9566605 (599)\ttotal: 26.6s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9778975\ttest: 0.9576074\tbest: 0.9576080 (894)\ttotal: 39.9s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9787225\ttest: 0.9583623\tbest: 0.9583706 (1185)\ttotal: 53.2s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9794729\ttest: 0.9586385\tbest: 0.9586391 (1491)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "1800:\tlearn: 0.9800658\ttest: 0.9588016\tbest: 0.9588016 (1800)\ttotal: 1m 19s\tremaining: 53s\n",
      "bestTest = 0.9588019252\n",
      "bestIteration = 1803\n",
      "Shrink model to first 1804 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:11:36,827]\u001b[0m Trial 96 finished with value: 0.39438682487969634 and parameters: {'l2_leaf_reg': 19, 'scale_pos_weight': 0.8798298085491375, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.39536672378092774}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9078657\ttest: 0.8416031\tbest: 0.8416031 (0)\ttotal: 41.5ms\tremaining: 2m 4s\n",
      "300:\tlearn: 0.9707667\ttest: 0.9484898\tbest: 0.9484898 (300)\ttotal: 11.9s\tremaining: 1m 46s\n",
      "600:\tlearn: 0.9739525\ttest: 0.9527943\tbest: 0.9527943 (600)\ttotal: 23.7s\tremaining: 1m 34s\n",
      "900:\tlearn: 0.9753402\ttest: 0.9558425\tbest: 0.9558486 (897)\ttotal: 35.7s\tremaining: 1m 23s\n",
      "1200:\tlearn: 0.9761219\ttest: 0.9565615\tbest: 0.9565615 (1200)\ttotal: 47.6s\tremaining: 1m 11s\n",
      "1500:\tlearn: 0.9766908\ttest: 0.9568809\tbest: 0.9568917 (1494)\ttotal: 59.9s\tremaining: 59.8s\n",
      "bestTest = 0.9568916559\n",
      "bestIteration = 1494\n",
      "Shrink model to first 1495 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:12:44,606]\u001b[0m Trial 97 finished with value: 0.3996501967643201 and parameters: {'l2_leaf_reg': 17, 'scale_pos_weight': 0.8278795776010792, 'depth': 4, 'bootstrap_type': 'Bernoulli', 'subsample': 0.23864730052519656}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8653128\ttest: 0.7697708\tbest: 0.7697708 (0)\ttotal: 38.4ms\tremaining: 1m 55s\n",
      "300:\tlearn: 0.9687667\ttest: 0.9454540\tbest: 0.9454540 (300)\ttotal: 11.5s\tremaining: 1m 43s\n",
      "600:\tlearn: 0.9726552\ttest: 0.9508897\tbest: 0.9508982 (599)\ttotal: 23.1s\tremaining: 1m 32s\n",
      "900:\tlearn: 0.9743174\ttest: 0.9531433\tbest: 0.9531456 (899)\ttotal: 34.6s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9751512\ttest: 0.9539185\tbest: 0.9539185 (1200)\ttotal: 46.2s\tremaining: 1m 9s\n",
      "1500:\tlearn: 0.9757817\ttest: 0.9548837\tbest: 0.9549586 (1471)\ttotal: 57.7s\tremaining: 57.7s\n",
      "bestTest = 0.9549964964\n",
      "bestIteration = 1524\n",
      "Shrink model to first 1525 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:13:50,952]\u001b[0m Trial 98 finished with value: 0.39371832711477417 and parameters: {'l2_leaf_reg': 14, 'scale_pos_weight': 0.9457819930734019, 'depth': 3, 'bootstrap_type': 'Bernoulli', 'subsample': 0.4767037497866655}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9019926\ttest: 0.8310690\tbest: 0.8310690 (0)\ttotal: 45ms\tremaining: 2m 14s\n",
      "300:\tlearn: 0.9744598\ttest: 0.9535827\tbest: 0.9535827 (300)\ttotal: 13.2s\tremaining: 1m 58s\n",
      "600:\tlearn: 0.9770108\ttest: 0.9563830\tbest: 0.9564210 (589)\ttotal: 26.6s\tremaining: 1m 46s\n",
      "900:\tlearn: 0.9783281\ttest: 0.9569825\tbest: 0.9571455 (886)\ttotal: 39.9s\tremaining: 1m 32s\n",
      "1200:\tlearn: 0.9792295\ttest: 0.9575978\tbest: 0.9576258 (1161)\ttotal: 53.1s\tremaining: 1m 19s\n",
      "1500:\tlearn: 0.9799551\ttest: 0.9579301\tbest: 0.9579301 (1500)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "1800:\tlearn: 0.9806251\ttest: 0.9582959\tbest: 0.9583170 (1787)\ttotal: 1m 19s\tremaining: 52.9s\n",
      "bestTest = 0.9583170116\n",
      "bestIteration = 1787\n",
      "Shrink model to first 1788 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-05 20:15:18,216]\u001b[0m Trial 99 finished with value: 0.39335253320794633 and parameters: {'l2_leaf_reg': 10, 'scale_pos_weight': 0.9815988929419098, 'depth': 5, 'bootstrap_type': 'Bernoulli', 'subsample': 0.5264597404384356}. Best is trial 62 with value: 0.40479134911276643.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna  \n",
    "from catboost import CatBoostClassifier\n",
    "def objective(trial, X_train, y_train,X_test,y_test):\n",
    "    param = {\n",
    "         'l2_leaf_reg': trial.suggest_int('l2_leaf_reg',1, 30,step=1),\n",
    "         'scale_pos_weight':trial.suggest_float('scale_pos_weight',0.01, 1.0,),\n",
    "        #\"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"]),\n",
    "        \"learning_rate\":0.1,\n",
    "            'task_type':\"GPU\",\n",
    "              'random_seed':43,\n",
    "            'iterations':3000,\n",
    "        'eval_metric':'AUC',\n",
    "    }\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature',0.0, 1.0)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=300,early_stopping_rounds=100)\n",
    "    #score= roc_auc_score(y_test, preds)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    _,score,_= lgb_f2_score(y_test, preds)\n",
    "    return score '''\n",
    "'''study = optuna.create_study(direction=\"maximize\", study_name=\"Cat Classifier\")\n",
    "func = lambda trial: objective(trial, X_train, y_train,X_valid,y_valid)\n",
    "study.optimize(func, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (rmse): 0.40479\n",
      "\tBest params:\n",
      "\t\tl2_leaf_reg: 13\n",
      "\t\tscale_pos_weight: 0.9406780584846045\n",
      "\t\tdepth: 4\n",
      "\t\tbootstrap_type: Bernoulli\n",
      "\t\tsubsample: 0.22922161698463137\n"
     ]
    }
   ],
   "source": [
    "'''print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")'''\n",
    "    \n",
    "'''Best value (rmse): 0.40479\n",
    "\tBest params:\n",
    "\t\tl2_leaf_reg: 13\n",
    "\t\tscale_pos_weight: 0.9406780584846045\n",
    "\t\tdepth: 4\n",
    "\t\tbootstrap_type: Bernoulli\n",
    "\t\tsubsample: 0.22922161698463137'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## eval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb.plot_importance(clf.booster_,max_num_features=20)\n",
    "booster = clf.booster_\n",
    "importance = booster.feature_importance(importance_type='split')\n",
    "feature_name = clf.booster_.feature_name()\n",
    "feature_importance = pd.DataFrame({'feature_name':feature_name,'importance':importance} )\n",
    "feature_importance = feature_importance.sort_values(by='importance',ascending=False).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "def lgb_f2_score(y_true, y_hat):\n",
    "    y_hat = [1 if i >=0.072 else 0 for i in y_hat ]\n",
    "    precision = precision_score(y_true,y_hat,zero_division=1)\n",
    "    recall = recall_score(y_true,y_hat)\n",
    "    f2 = 5*recall*precision/(4*precision+recall)\n",
    "    return 'f2',f2,True\n",
    "seed0=42\n",
    "params_cat = {'iterations':1500,\n",
    "                     'learning_rate':0.01,\n",
    "                     'eval_metric':'AUC',\n",
    "                     'l2_leaf_reg':0.1,}\n",
    "\n",
    "params_cat2 = {\"learning_rate\":0.1,\n",
    "            'task_type':\"GPU\",\n",
    "              'random_seed':356,\n",
    "            'iterations':3000,\n",
    "        'eval_metric':'AUC',\n",
    "        'l2_leaf_reg': 13,\n",
    "        'scale_pos_weight': 0.9406780584846045,\n",
    "        'depth': 4,\n",
    "        'bootstrap_type':'Bernoulli',\n",
    "        'subsample':0.22922161698463137}\n",
    "params_xgb = {'n_estimators':540,\n",
    "                     'learning_rate':0.01,\n",
    "                     'verbose':-1,\n",
    "                     'metrics':['auc'],\n",
    "                     'reg_alpha':0.1,\n",
    "                     'reg_lambda':0.1,\n",
    "                     'min_child_weight':30,\n",
    "                     'n_jobs':20}\n",
    "params_xgb2 = {'n_estimators':450,\n",
    "                     'learning_rate':0.1,\n",
    "              'seed':42,\n",
    "               'max_depth':5,\n",
    "               'reg_alpha':16,\n",
    "               'reg_lambda':0.8516218313773746,\n",
    "               'colsample_bytree':0.7962234301287214,\n",
    "               'gamma':5.524732779962722,\n",
    "               'metrics':['auc'],\n",
    "               'min_child_weight':6\n",
    "              }\n",
    "\n",
    "params_lgb = {'num_leaves':128,\n",
    "                     'n_estimators':550,\n",
    "                     'learning_rate':0.01,\n",
    "                     'verbose':-1,\n",
    "                     'metric':'auc',\n",
    "                     'feature_fraction':0.8, \n",
    "                     'bagging_fraction':0.8,\n",
    "                     'lambda_l1':0.1,\n",
    "                     'lambda_l2':0.1,\n",
    "                     'min_child_weight':30,\n",
    "                     'n_jobs':20,\n",
    "                     'random_state':356} # 42, 128, 356\n",
    "params_lgb2 = {'n_estimators': 500, \n",
    "           'learning_rate': 0.04223859360499718, \n",
    "           'num_leaves': 96, \n",
    "           'max_depth': 6,\n",
    "           'metric':'auc',\n",
    "           'min_data_in_leaf': 1300,\n",
    "           'lambda_l1': 0,\n",
    "           'lambda_l2': 7, \n",
    "           'min_gain_to_split': 0.28816893721038017,\n",
    "           'bagging_fraction': 0.5,\n",
    "           'bagging_freq': 1,\n",
    "           'feature_fraction': 0.8,\n",
    "            'random_state':356}\n",
    "def fold_5_clf(clf_name,params,threshold):\n",
    "    fold = 0\n",
    "    f2_scores = 0\n",
    "    k = 5\n",
    "    dataloader.setSample(0)\n",
    "    tst_data = dataloader.get_test()\n",
    "    dataloader.reset_pre()\n",
    "    feature_imp = None\n",
    "    for x_trn, x_val, y_trn, y_val in dataloader.get_k_fold_train_val_data(k=k):\n",
    "        fold += 1\n",
    "        print(f'{fold} starting ....')\n",
    "        if clf_name=='lgbm':\n",
    "            clf1 = LGBMClassifier(**params)\n",
    "            clf1.fit(x_trn, y_trn,verbose=0)#,early_stopping_rounds=100,eval_set=[(x_val, y_val)],eval_metric=[lgb_f2_score])\n",
    "        elif clf_name=='xgb':\n",
    "            clf1 = XGBClassifier(tree_method='gpu_hist', gpu_id=0,**params)\n",
    "            clf1.fit(x_trn, y_trn,eval_set=[(x_val, y_val)],eval_metric='auc',verbose=100,early_stopping_rounds=100)\n",
    "        elif clf_name=='cat':\n",
    "            clf1 = CatBoostClassifier(**params)\n",
    "            clf1.fit(x_trn, y_trn,eval_set=[(x_val, y_val)],verbose=600,early_stopping_rounds=100)\n",
    "        pred = clf1.predict_proba(x_val)[:, 1]\n",
    "        score = f2_score(y_val, pred)[0]\n",
    "        f2_scores += score\n",
    "        # weight = (tst_data['a2'] != 2).astype(int)\n",
    "        weight = None\n",
    "        dataloader.set_pre(clf1.predict_proba(tst_data)[:, 1], weight, k=k)\n",
    "        print('{} fold, auc: {}'.format(fold, roc_auc_score(y_val, pred)))\n",
    "        #metrics_detail(y_val, pred, x_val['a2'].values, 0.03)\n",
    "        if clf_name=='lgbm':\n",
    "            booster = clf1.booster_\n",
    "            importance = booster.feature_importance(importance_type='split')\n",
    "            feature_name = clf1.booster_.feature_name()\n",
    "            feature_importance = pd.DataFrame({'feature_name':feature_name,'importance{}'.format(fold):importance})\n",
    "            if feature_imp is None:\n",
    "                feature_imp = feature_importance\n",
    "            else:\n",
    "                feature_imp = feature_imp.merge(feature_importance,how='left',on='feature_name')\n",
    "            \n",
    "    print('the mean f2 score is: ', f2_scores / k)\n",
    "    dataloader.save_res(f'lgb_{k}_fold', 0.03,threshold) #0.977  976 977  977 978\n",
    "    return feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 starting ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.86945\n",
      "[100]\tvalidation_0-auc:0.97333\n",
      "[200]\tvalidation_0-auc:0.97564\n",
      "[275]\tvalidation_0-auc:0.97564\n",
      "1 fold, auc: 0.9756353656857146\n",
      "2 starting ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.92944\n",
      "[100]\tvalidation_0-auc:0.97304\n",
      "[200]\tvalidation_0-auc:0.97524\n",
      "[273]\tvalidation_0-auc:0.97524\n",
      "2 fold, auc: 0.9752355030893397\n",
      "3 starting ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.92234\n",
      "[100]\tvalidation_0-auc:0.97261\n",
      "[200]\tvalidation_0-auc:0.97484\n",
      "[275]\tvalidation_0-auc:0.97484\n",
      "3 fold, auc: 0.9748410423974453\n",
      "4 starting ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:36:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.92411\n",
      "[100]\tvalidation_0-auc:0.97188\n",
      "[200]\tvalidation_0-auc:0.97428\n",
      "[275]\tvalidation_0-auc:0.97428\n",
      "4 fold, auc: 0.9742819721593504\n",
      "5 starting ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:36:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.92241\n",
      "[100]\tvalidation_0-auc:0.97182\n",
      "[200]\tvalidation_0-auc:0.97413\n",
      "[272]\tvalidation_0-auc:0.97413\n",
      "5 fold, auc: 0.9741289431965885\n",
      "the mean f2 score is:  0.46356623247244794\n",
      "     count      mean   sum\n",
      "a2                        \n",
      "1   232455  0.033254  7730\n",
      "2   183505  0.003079   565\n",
      "3    46174  0.110625  5108\n",
      "4   124951  0.030324  3789\n",
      "0.02928366420535357\n",
      "save to  ./result/lgb_5_fold_2022-02-05.csv\n",
      "1 starting ....\n",
      "0:\tlearn: 0.8930647\ttest: 0.8958920\tbest: 0.8958920 (0)\ttotal: 52.7ms\tremaining: 2m 38s\n",
      "100:\tlearn: 0.9616638\ttest: 0.9623079\tbest: 0.9623079 (100)\ttotal: 3.81s\tremaining: 1m 49s\n",
      "200:\tlearn: 0.9670295\ttest: 0.9672514\tbest: 0.9672514 (200)\ttotal: 7.46s\tremaining: 1m 43s\n",
      "300:\tlearn: 0.9689795\ttest: 0.9690337\tbest: 0.9690337 (300)\ttotal: 11.1s\tremaining: 1m 39s\n",
      "400:\tlearn: 0.9703575\ttest: 0.9703439\tbest: 0.9703440 (399)\ttotal: 14.9s\tremaining: 1m 36s\n",
      "500:\tlearn: 0.9713139\ttest: 0.9712384\tbest: 0.9712384 (500)\ttotal: 18.5s\tremaining: 1m 32s\n",
      "600:\tlearn: 0.9718061\ttest: 0.9716048\tbest: 0.9716048 (600)\ttotal: 22.2s\tremaining: 1m 28s\n",
      "700:\tlearn: 0.9725362\ttest: 0.9722438\tbest: 0.9722438 (700)\ttotal: 26s\tremaining: 1m 25s\n",
      "800:\tlearn: 0.9729795\ttest: 0.9725847\tbest: 0.9725847 (800)\ttotal: 29.7s\tremaining: 1m 21s\n",
      "900:\tlearn: 0.9734595\ttest: 0.9729877\tbest: 0.9729877 (900)\ttotal: 33.5s\tremaining: 1m 18s\n",
      "1000:\tlearn: 0.9738046\ttest: 0.9731926\tbest: 0.9731926 (1000)\ttotal: 37.2s\tremaining: 1m 14s\n",
      "1100:\tlearn: 0.9740867\ttest: 0.9733762\tbest: 0.9733762 (1100)\ttotal: 41s\tremaining: 1m 10s\n",
      "1200:\tlearn: 0.9743537\ttest: 0.9735660\tbest: 0.9735660 (1200)\ttotal: 44.7s\tremaining: 1m 7s\n",
      "1300:\tlearn: 0.9746127\ttest: 0.9737343\tbest: 0.9737353 (1299)\ttotal: 48.6s\tremaining: 1m 3s\n",
      "1400:\tlearn: 0.9748420\ttest: 0.9738391\tbest: 0.9738398 (1399)\ttotal: 52.3s\tremaining: 59.7s\n",
      "1500:\tlearn: 0.9751114\ttest: 0.9740144\tbest: 0.9740144 (1500)\ttotal: 56.1s\tremaining: 56s\n",
      "1600:\tlearn: 0.9753773\ttest: 0.9742090\tbest: 0.9742090 (1600)\ttotal: 59.8s\tremaining: 52.3s\n",
      "1700:\tlearn: 0.9755529\ttest: 0.9742649\tbest: 0.9742683 (1697)\ttotal: 1m 3s\tremaining: 48.5s\n",
      "1800:\tlearn: 0.9757313\ttest: 0.9743559\tbest: 0.9743569 (1798)\ttotal: 1m 7s\tremaining: 44.9s\n",
      "1900:\tlearn: 0.9758859\ttest: 0.9744217\tbest: 0.9744219 (1896)\ttotal: 1m 11s\tremaining: 41.1s\n",
      "2000:\tlearn: 0.9760895\ttest: 0.9745280\tbest: 0.9745296 (1997)\ttotal: 1m 14s\tremaining: 37.4s\n",
      "2100:\tlearn: 0.9762518\ttest: 0.9745876\tbest: 0.9745925 (2094)\ttotal: 1m 18s\tremaining: 33.7s\n",
      "2200:\tlearn: 0.9764206\ttest: 0.9746627\tbest: 0.9746649 (2194)\ttotal: 1m 22s\tremaining: 30s\n",
      "2300:\tlearn: 0.9766180\ttest: 0.9747977\tbest: 0.9747977 (2300)\ttotal: 1m 26s\tremaining: 26.4s\n",
      "2400:\tlearn: 0.9768023\ttest: 0.9748878\tbest: 0.9748878 (2400)\ttotal: 1m 30s\tremaining: 22.6s\n",
      "2500:\tlearn: 0.9769429\ttest: 0.9749629\tbest: 0.9749629 (2500)\ttotal: 1m 34s\tremaining: 18.9s\n",
      "2600:\tlearn: 0.9770917\ttest: 0.9750252\tbest: 0.9750252 (2600)\ttotal: 1m 38s\tremaining: 15.1s\n",
      "2700:\tlearn: 0.9772232\ttest: 0.9750569\tbest: 0.9750596 (2689)\ttotal: 1m 42s\tremaining: 11.3s\n",
      "2800:\tlearn: 0.9773835\ttest: 0.9751197\tbest: 0.9751197 (2800)\ttotal: 1m 46s\tremaining: 7.54s\n",
      "2900:\tlearn: 0.9775425\ttest: 0.9752191\tbest: 0.9752191 (2900)\ttotal: 1m 50s\tremaining: 3.76s\n",
      "2999:\tlearn: 0.9776441\ttest: 0.9752262\tbest: 0.9752273 (2979)\ttotal: 1m 53s\tremaining: 0us\n",
      "bestTest = 0.9752272964\n",
      "bestIteration = 2979\n",
      "Shrink model to first 2980 iterations.\n",
      "1 fold, auc: 0.9752272855483785\n",
      "2 starting ....\n",
      "0:\tlearn: 0.8938188\ttest: 0.8928758\tbest: 0.8928758 (0)\ttotal: 39.7ms\tremaining: 1m 58s\n",
      "100:\tlearn: 0.9615022\ttest: 0.9615913\tbest: 0.9615913 (100)\ttotal: 3.81s\tremaining: 1m 49s\n",
      "200:\tlearn: 0.9672971\ttest: 0.9672137\tbest: 0.9672137 (200)\ttotal: 7.56s\tremaining: 1m 45s\n",
      "300:\tlearn: 0.9695032\ttest: 0.9693397\tbest: 0.9693397 (300)\ttotal: 11.3s\tremaining: 1m 41s\n",
      "400:\tlearn: 0.9707096\ttest: 0.9703860\tbest: 0.9703892 (399)\ttotal: 15.1s\tremaining: 1m 38s\n",
      "500:\tlearn: 0.9716541\ttest: 0.9711290\tbest: 0.9711329 (499)\ttotal: 19s\tremaining: 1m 34s\n",
      "600:\tlearn: 0.9722608\ttest: 0.9716310\tbest: 0.9716310 (600)\ttotal: 22.8s\tremaining: 1m 31s\n",
      "700:\tlearn: 0.9727941\ttest: 0.9720520\tbest: 0.9720520 (700)\ttotal: 26.7s\tremaining: 1m 27s\n",
      "800:\tlearn: 0.9732626\ttest: 0.9723932\tbest: 0.9723932 (800)\ttotal: 30.5s\tremaining: 1m 23s\n",
      "900:\tlearn: 0.9736839\ttest: 0.9726934\tbest: 0.9726944 (899)\ttotal: 34.3s\tremaining: 1m 19s\n",
      "1000:\tlearn: 0.9740064\ttest: 0.9729166\tbest: 0.9729166 (1000)\ttotal: 38.2s\tremaining: 1m 16s\n",
      "1100:\tlearn: 0.9743655\ttest: 0.9731213\tbest: 0.9731213 (1100)\ttotal: 42s\tremaining: 1m 12s\n",
      "1200:\tlearn: 0.9745806\ttest: 0.9732293\tbest: 0.9732293 (1200)\ttotal: 45.9s\tremaining: 1m 8s\n",
      "1300:\tlearn: 0.9748351\ttest: 0.9733832\tbest: 0.9733832 (1300)\ttotal: 49.8s\tremaining: 1m 5s\n",
      "1400:\tlearn: 0.9750395\ttest: 0.9734778\tbest: 0.9734778 (1400)\ttotal: 53.6s\tremaining: 1m 1s\n",
      "1500:\tlearn: 0.9752727\ttest: 0.9735903\tbest: 0.9735903 (1500)\ttotal: 57.5s\tremaining: 57.4s\n",
      "1600:\tlearn: 0.9754858\ttest: 0.9737069\tbest: 0.9737069 (1600)\ttotal: 1m 1s\tremaining: 53.7s\n",
      "1700:\tlearn: 0.9757225\ttest: 0.9738633\tbest: 0.9738643 (1699)\ttotal: 1m 5s\tremaining: 49.9s\n",
      "1800:\tlearn: 0.9759036\ttest: 0.9739579\tbest: 0.9739588 (1798)\ttotal: 1m 9s\tremaining: 46.1s\n",
      "1900:\tlearn: 0.9760814\ttest: 0.9740195\tbest: 0.9740199 (1898)\ttotal: 1m 13s\tremaining: 42.2s\n",
      "2000:\tlearn: 0.9762402\ttest: 0.9740929\tbest: 0.9740934 (1999)\ttotal: 1m 17s\tremaining: 38.5s\n",
      "2100:\tlearn: 0.9764181\ttest: 0.9741714\tbest: 0.9741721 (2099)\ttotal: 1m 21s\tremaining: 34.7s\n",
      "2200:\tlearn: 0.9765688\ttest: 0.9742184\tbest: 0.9742187 (2194)\ttotal: 1m 25s\tremaining: 30.9s\n",
      "2300:\tlearn: 0.9767189\ttest: 0.9742643\tbest: 0.9742659 (2297)\ttotal: 1m 28s\tremaining: 27s\n",
      "2400:\tlearn: 0.9768420\ttest: 0.9743086\tbest: 0.9743104 (2398)\ttotal: 1m 32s\tremaining: 23.2s\n",
      "2500:\tlearn: 0.9770005\ttest: 0.9743673\tbest: 0.9743685 (2491)\ttotal: 1m 36s\tremaining: 19.3s\n",
      "2600:\tlearn: 0.9771377\ttest: 0.9744202\tbest: 0.9744202 (2600)\ttotal: 1m 40s\tremaining: 15.5s\n",
      "2700:\tlearn: 0.9772574\ttest: 0.9744627\tbest: 0.9744627 (2700)\ttotal: 1m 44s\tremaining: 11.6s\n",
      "2800:\tlearn: 0.9773990\ttest: 0.9745160\tbest: 0.9745164 (2787)\ttotal: 1m 48s\tremaining: 7.71s\n",
      "2900:\tlearn: 0.9775317\ttest: 0.9745589\tbest: 0.9745608 (2897)\ttotal: 1m 52s\tremaining: 3.83s\n",
      "2999:\tlearn: 0.9776636\ttest: 0.9746030\tbest: 0.9746031 (2992)\ttotal: 1m 56s\tremaining: 0us\n",
      "bestTest = 0.9746031165\n",
      "bestIteration = 2992\n",
      "Shrink model to first 2993 iterations.\n",
      "2 fold, auc: 0.974603063218887\n",
      "3 starting ....\n",
      "0:\tlearn: 0.8937759\ttest: 0.8932511\tbest: 0.8932511 (0)\ttotal: 37.6ms\tremaining: 1m 52s\n",
      "100:\tlearn: 0.9602653\ttest: 0.9599478\tbest: 0.9599478 (100)\ttotal: 3.81s\tremaining: 1m 49s\n",
      "200:\tlearn: 0.9667504\ttest: 0.9667141\tbest: 0.9667141 (200)\ttotal: 7.7s\tremaining: 1m 47s\n",
      "300:\tlearn: 0.9691312\ttest: 0.9688793\tbest: 0.9688793 (300)\ttotal: 11.5s\tremaining: 1m 43s\n",
      "400:\tlearn: 0.9706852\ttest: 0.9703079\tbest: 0.9703079 (400)\ttotal: 15.4s\tremaining: 1m 39s\n",
      "500:\tlearn: 0.9716028\ttest: 0.9710424\tbest: 0.9710424 (500)\ttotal: 19.3s\tremaining: 1m 36s\n",
      "600:\tlearn: 0.9723258\ttest: 0.9715477\tbest: 0.9715477 (600)\ttotal: 23.3s\tremaining: 1m 32s\n",
      "700:\tlearn: 0.9728181\ttest: 0.9718839\tbest: 0.9718839 (700)\ttotal: 27.4s\tremaining: 1m 29s\n",
      "800:\tlearn: 0.9733159\ttest: 0.9721911\tbest: 0.9721915 (798)\ttotal: 31.7s\tremaining: 1m 27s\n",
      "900:\tlearn: 0.9737922\ttest: 0.9725074\tbest: 0.9725077 (899)\ttotal: 35.6s\tremaining: 1m 22s\n",
      "1000:\tlearn: 0.9741121\ttest: 0.9726793\tbest: 0.9726793 (1000)\ttotal: 39.9s\tremaining: 1m 19s\n",
      "1100:\tlearn: 0.9743746\ttest: 0.9728346\tbest: 0.9728373 (1091)\ttotal: 44.2s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9746334\ttest: 0.9729618\tbest: 0.9729618 (1200)\ttotal: 48.5s\tremaining: 1m 12s\n",
      "1300:\tlearn: 0.9748654\ttest: 0.9730846\tbest: 0.9730937 (1295)\ttotal: 52.8s\tremaining: 1m 8s\n",
      "1400:\tlearn: 0.9750488\ttest: 0.9731676\tbest: 0.9731678 (1389)\ttotal: 57s\tremaining: 1m 5s\n",
      "1500:\tlearn: 0.9752923\ttest: 0.9732979\tbest: 0.9732979 (1500)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1600:\tlearn: 0.9754778\ttest: 0.9733798\tbest: 0.9733798 (1600)\ttotal: 1m 5s\tremaining: 57.1s\n",
      "1700:\tlearn: 0.9756772\ttest: 0.9734771\tbest: 0.9734771 (1700)\ttotal: 1m 10s\tremaining: 54.1s\n",
      "1800:\tlearn: 0.9758655\ttest: 0.9735687\tbest: 0.9735687 (1800)\ttotal: 1m 16s\tremaining: 50.9s\n",
      "1900:\tlearn: 0.9760275\ttest: 0.9736252\tbest: 0.9736262 (1892)\ttotal: 1m 21s\tremaining: 47.1s\n",
      "2000:\tlearn: 0.9761839\ttest: 0.9736732\tbest: 0.9736732 (2000)\ttotal: 1m 25s\tremaining: 42.8s\n",
      "2100:\tlearn: 0.9763650\ttest: 0.9737421\tbest: 0.9737426 (2086)\ttotal: 1m 29s\tremaining: 38.5s\n",
      "2200:\tlearn: 0.9764931\ttest: 0.9737944\tbest: 0.9737966 (2199)\ttotal: 1m 34s\tremaining: 34.2s\n",
      "2300:\tlearn: 0.9766881\ttest: 0.9738928\tbest: 0.9738934 (2299)\ttotal: 1m 38s\tremaining: 29.9s\n",
      "2400:\tlearn: 0.9768602\ttest: 0.9739698\tbest: 0.9739700 (2399)\ttotal: 1m 42s\tremaining: 25.6s\n",
      "2500:\tlearn: 0.9770212\ttest: 0.9740216\tbest: 0.9740233 (2497)\ttotal: 1m 46s\tremaining: 21.3s\n",
      "2600:\tlearn: 0.9771820\ttest: 0.9740715\tbest: 0.9740722 (2599)\ttotal: 1m 50s\tremaining: 17s\n",
      "2700:\tlearn: 0.9773115\ttest: 0.9741045\tbest: 0.9741047 (2699)\ttotal: 1m 54s\tremaining: 12.7s\n",
      "2800:\tlearn: 0.9774522\ttest: 0.9741635\tbest: 0.9741635 (2800)\ttotal: 1m 59s\tremaining: 8.46s\n",
      "2900:\tlearn: 0.9775923\ttest: 0.9741996\tbest: 0.9742019 (2889)\ttotal: 2m 3s\tremaining: 4.22s\n",
      "2999:\tlearn: 0.9777427\ttest: 0.9742453\tbest: 0.9742469 (2994)\ttotal: 2m 7s\tremaining: 0us\n",
      "bestTest = 0.974246949\n",
      "bestIteration = 2994\n",
      "Shrink model to first 2995 iterations.\n",
      "3 fold, auc: 0.9742469765886199\n",
      "4 starting ....\n",
      "0:\tlearn: 0.8934309\ttest: 0.8944220\tbest: 0.8944220 (0)\ttotal: 40.4ms\tremaining: 2m 1s\n",
      "100:\tlearn: 0.9618229\ttest: 0.9611504\tbest: 0.9611504 (100)\ttotal: 3.97s\tremaining: 1m 54s\n",
      "200:\tlearn: 0.9676366\ttest: 0.9662372\tbest: 0.9662372 (200)\ttotal: 8.58s\tremaining: 1m 59s\n",
      "300:\tlearn: 0.9698533\ttest: 0.9681901\tbest: 0.9681901 (300)\ttotal: 12.6s\tremaining: 1m 52s\n",
      "400:\tlearn: 0.9711022\ttest: 0.9692467\tbest: 0.9692467 (400)\ttotal: 16.6s\tremaining: 1m 47s\n",
      "500:\tlearn: 0.9718324\ttest: 0.9697988\tbest: 0.9697988 (500)\ttotal: 20.8s\tremaining: 1m 43s\n",
      "600:\tlearn: 0.9725572\ttest: 0.9703589\tbest: 0.9703593 (599)\ttotal: 25.2s\tremaining: 1m 40s\n",
      "700:\tlearn: 0.9731181\ttest: 0.9707670\tbest: 0.9707703 (698)\ttotal: 29.5s\tremaining: 1m 36s\n",
      "800:\tlearn: 0.9735917\ttest: 0.9710990\tbest: 0.9711022 (799)\ttotal: 34.1s\tremaining: 1m 33s\n",
      "900:\tlearn: 0.9739612\ttest: 0.9713352\tbest: 0.9713352 (900)\ttotal: 38.3s\tremaining: 1m 29s\n",
      "1000:\tlearn: 0.9743159\ttest: 0.9715907\tbest: 0.9715907 (1000)\ttotal: 42.4s\tremaining: 1m 24s\n",
      "1100:\tlearn: 0.9746277\ttest: 0.9717655\tbest: 0.9717655 (1100)\ttotal: 46.6s\tremaining: 1m 20s\n",
      "1200:\tlearn: 0.9748662\ttest: 0.9718856\tbest: 0.9718856 (1200)\ttotal: 50.7s\tremaining: 1m 15s\n",
      "1300:\tlearn: 0.9751409\ttest: 0.9720408\tbest: 0.9720419 (1297)\ttotal: 55s\tremaining: 1m 11s\n",
      "1400:\tlearn: 0.9753740\ttest: 0.9721617\tbest: 0.9721635 (1397)\ttotal: 59.2s\tremaining: 1m 7s\n",
      "1500:\tlearn: 0.9755615\ttest: 0.9722600\tbest: 0.9722603 (1499)\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "1600:\tlearn: 0.9757871\ttest: 0.9723645\tbest: 0.9723653 (1599)\ttotal: 1m 7s\tremaining: 59s\n",
      "1700:\tlearn: 0.9760255\ttest: 0.9725339\tbest: 0.9725339 (1700)\ttotal: 1m 11s\tremaining: 54.9s\n",
      "1800:\tlearn: 0.9762047\ttest: 0.9726161\tbest: 0.9726162 (1799)\ttotal: 1m 15s\tremaining: 50.6s\n",
      "1900:\tlearn: 0.9763697\ttest: 0.9726795\tbest: 0.9726795 (1900)\ttotal: 1m 20s\tremaining: 46.3s\n",
      "2000:\tlearn: 0.9765233\ttest: 0.9727407\tbest: 0.9727436 (1984)\ttotal: 1m 24s\tremaining: 42s\n",
      "2100:\tlearn: 0.9766966\ttest: 0.9728286\tbest: 0.9728369 (2088)\ttotal: 1m 28s\tremaining: 37.7s\n",
      "2200:\tlearn: 0.9768436\ttest: 0.9728757\tbest: 0.9728819 (2198)\ttotal: 1m 32s\tremaining: 33.5s\n",
      "2300:\tlearn: 0.9770064\ttest: 0.9729375\tbest: 0.9729375 (2300)\ttotal: 1m 36s\tremaining: 29.2s\n",
      "2400:\tlearn: 0.9771597\ttest: 0.9729702\tbest: 0.9729740 (2373)\ttotal: 1m 41s\tremaining: 25.2s\n",
      "2500:\tlearn: 0.9772994\ttest: 0.9730108\tbest: 0.9730161 (2488)\ttotal: 1m 45s\tremaining: 21.1s\n",
      "2600:\tlearn: 0.9774511\ttest: 0.9730746\tbest: 0.9730771 (2592)\ttotal: 1m 49s\tremaining: 16.8s\n",
      "2700:\tlearn: 0.9776083\ttest: 0.9731531\tbest: 0.9731531 (2700)\ttotal: 1m 53s\tremaining: 12.6s\n",
      "2800:\tlearn: 0.9777208\ttest: 0.9731827\tbest: 0.9731827 (2800)\ttotal: 1m 59s\tremaining: 8.46s\n",
      "2900:\tlearn: 0.9778535\ttest: 0.9732375\tbest: 0.9732390 (2876)\ttotal: 2m 3s\tremaining: 4.22s\n",
      "2999:\tlearn: 0.9779655\ttest: 0.9732781\tbest: 0.9732795 (2995)\ttotal: 2m 7s\tremaining: 0us\n",
      "bestTest = 0.973279506\n",
      "bestIteration = 2995\n",
      "Shrink model to first 2996 iterations.\n",
      "4 fold, auc: 0.9732794244106152\n",
      "5 starting ....\n",
      "0:\tlearn: 0.8941707\ttest: 0.8916710\tbest: 0.8916710 (0)\ttotal: 40.3ms\tremaining: 2m\n",
      "100:\tlearn: 0.9599961\ttest: 0.9589470\tbest: 0.9589470 (100)\ttotal: 3.86s\tremaining: 1m 50s\n",
      "200:\tlearn: 0.9660598\ttest: 0.9647081\tbest: 0.9647081 (200)\ttotal: 8.2s\tremaining: 1m 54s\n",
      "300:\tlearn: 0.9693584\ttest: 0.9678400\tbest: 0.9678400 (300)\ttotal: 12.2s\tremaining: 1m 49s\n",
      "400:\tlearn: 0.9706416\ttest: 0.9689538\tbest: 0.9689538 (400)\ttotal: 16.2s\tremaining: 1m 44s\n",
      "500:\tlearn: 0.9716566\ttest: 0.9698410\tbest: 0.9698410 (500)\ttotal: 20.1s\tremaining: 1m 40s\n",
      "600:\tlearn: 0.9723501\ttest: 0.9704054\tbest: 0.9704057 (597)\ttotal: 24.1s\tremaining: 1m 36s\n",
      "700:\tlearn: 0.9728694\ttest: 0.9708137\tbest: 0.9708137 (700)\ttotal: 28.3s\tremaining: 1m 32s\n",
      "800:\tlearn: 0.9733649\ttest: 0.9711144\tbest: 0.9711144 (800)\ttotal: 32.5s\tremaining: 1m 29s\n",
      "900:\tlearn: 0.9736687\ttest: 0.9712848\tbest: 0.9712888 (888)\ttotal: 36.5s\tremaining: 1m 24s\n",
      "1000:\tlearn: 0.9740361\ttest: 0.9715458\tbest: 0.9715472 (997)\ttotal: 40.7s\tremaining: 1m 21s\n",
      "1100:\tlearn: 0.9743861\ttest: 0.9717754\tbest: 0.9717754 (1097)\ttotal: 45s\tremaining: 1m 17s\n",
      "1200:\tlearn: 0.9746422\ttest: 0.9719333\tbest: 0.9719359 (1199)\ttotal: 49.2s\tremaining: 1m 13s\n",
      "1300:\tlearn: 0.9749259\ttest: 0.9721289\tbest: 0.9721289 (1300)\ttotal: 53.3s\tremaining: 1m 9s\n",
      "1400:\tlearn: 0.9751548\ttest: 0.9722702\tbest: 0.9722714 (1397)\ttotal: 57.5s\tremaining: 1m 5s\n",
      "1500:\tlearn: 0.9753956\ttest: 0.9724297\tbest: 0.9724297 (1500)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1600:\tlearn: 0.9756262\ttest: 0.9725710\tbest: 0.9725710 (1600)\ttotal: 1m 5s\tremaining: 57.7s\n",
      "1700:\tlearn: 0.9758338\ttest: 0.9726513\tbest: 0.9726513 (1700)\ttotal: 1m 9s\tremaining: 53.5s\n",
      "1800:\tlearn: 0.9760495\ttest: 0.9727280\tbest: 0.9727280 (1800)\ttotal: 1m 14s\tremaining: 49.3s\n",
      "1900:\tlearn: 0.9762227\ttest: 0.9728010\tbest: 0.9728010 (1900)\ttotal: 1m 18s\tremaining: 45.2s\n",
      "2000:\tlearn: 0.9764148\ttest: 0.9729072\tbest: 0.9729072 (2000)\ttotal: 1m 22s\tremaining: 41s\n",
      "2100:\tlearn: 0.9765698\ttest: 0.9729635\tbest: 0.9729636 (2099)\ttotal: 1m 26s\tremaining: 36.8s\n",
      "2200:\tlearn: 0.9767182\ttest: 0.9730380\tbest: 0.9730399 (2199)\ttotal: 1m 30s\tremaining: 32.7s\n",
      "2300:\tlearn: 0.9768796\ttest: 0.9731052\tbest: 0.9731058 (2298)\ttotal: 1m 34s\tremaining: 28.6s\n",
      "2400:\tlearn: 0.9770402\ttest: 0.9731831\tbest: 0.9731831 (2400)\ttotal: 1m 38s\tremaining: 24.5s\n",
      "2500:\tlearn: 0.9771723\ttest: 0.9732180\tbest: 0.9732212 (2488)\ttotal: 1m 42s\tremaining: 20.4s\n",
      "2600:\tlearn: 0.9773185\ttest: 0.9732702\tbest: 0.9732713 (2598)\ttotal: 1m 46s\tremaining: 16.4s\n",
      "2700:\tlearn: 0.9774385\ttest: 0.9733279\tbest: 0.9733292 (2681)\ttotal: 1m 50s\tremaining: 12.2s\n",
      "2800:\tlearn: 0.9775695\ttest: 0.9733747\tbest: 0.9733747 (2792)\ttotal: 1m 54s\tremaining: 8.14s\n",
      "2900:\tlearn: 0.9776921\ttest: 0.9734170\tbest: 0.9734170 (2900)\ttotal: 1m 58s\tremaining: 4.05s\n",
      "2999:\tlearn: 0.9777952\ttest: 0.9734383\tbest: 0.9734400 (2953)\ttotal: 2m 2s\tremaining: 0us\n",
      "bestTest = 0.9734399617\n",
      "bestIteration = 2953\n",
      "Shrink model to first 2954 iterations.\n",
      "5 fold, auc: 0.9734398935867984\n",
      "the mean f2 score is:  0.4650198943398511\n",
      "     count      mean   sum\n",
      "a2                        \n",
      "1   232455  0.029937  6959\n",
      "2   183505  0.003531   648\n",
      "3    46174  0.087538  4042\n",
      "4   124951  0.025362  3169\n",
      "0.025239956735396068\n",
      "save to  ./result/lgb_5_fold_2022-02-05.csv\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "pred_df['id'] = dataloader.rs['id']\n",
    "dataloader.feature_columns= feature+pool\n",
    "with timer('lgb'):\n",
    "    fold_5_clf('lgbm',params_lgb2,0.072)\n",
    "pred_df['lgb'] = dataloader.rs.loc[:,'prediction'].copy()\n",
    "with timer('cat'):\n",
    "    fold_5_clf('cat',params_cat2,0.072)\n",
    "pred_df['cat'] = dataloader.rs.loc[:,'prediction'].copy()\n",
    "dataloader.feature_columns= feature + pool_xgb\n",
    "for i in ['min_profit_rate_amax_a2_diff','min_profit_rate_mean_a2_diff','f14']:\n",
    "    dataloader.feature_columns.remove(i)\n",
    "with timer('xgb'):\n",
    "    fold_5_clf('xgb',params_xgb2,0.072)\n",
    "pred_df['xgb'] = dataloader.rs.loc[:,'prediction'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['y'] = (pred_df['lgb'] + pred_df['xgb']+pred_df['cat'])/3\n",
    "pred_df['y'] = [1 if i>=0.072 else 0 for i in pred_df['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569893\n",
       "1     17192\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_df = pred_df[['id','y']]\n",
    "re_df.to_csv('rrr.csv',index=False)\n",
    "pred_df.y.value_counts()   #########记得保存csv先！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
